# SAA-C03 덤프 61~90

게시일: Wed, 02 Jul 2025 13:31:12 GMT
링크: https://velog.io/@agline/SAA-C03-%EB%8D%A4%ED%94%84-6190

---

<h1 id="61">61</h1>
<p>한 회사가 AWS 에서 2 계층 웹 애플리케이션을 개발하고 있습니다. 회사 개발자는 백엔드 Amazon RDS 데이터베이스에 직접 연결되는 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. 회사는 애플리케이션에 데이터베이스 자격 증명을 하드코딩해서는 안 됩니다. 또한 회사는 정기적으로 데이터베이스 자격 증명을 자동으로 교체하는 솔루션을 구현해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?</p>
<p><strong>C. 데이터베이스 자격 증명을 AWS Secrets Manager 에 암호로 저장합니다. 보안 비밀에 대한 자동 순환을 켭니다. EC2 역할에 필요한 권한을 연결하여 보안 암호에 대한 액세스 권한을 부여합니다.</strong></p>
<ul>
<li><strong>자격 증명 하드코딩 방지</strong>: <strong>AWS Secrets Manager</strong>는 데이터베이스 자격 증명, API 키 등 민감한 정보를 안전하게 저장하고 관리하기 위해 특별히 설계된 서비스입니다. 애플리케이션은 런타임에 API 호출을 통해 Secrets Manager에서 직접 자격 증명을 검색하므로, 코드에 하드코딩할 필요가 없습니다.</li>
<li><strong>자동으로 자격 증명 교체 (Rotation)</strong>: Secrets Manager의 핵심 기능 중 하나는 <strong>자동 순환(Automatic Rotation)</strong> 기능입니다. Amazon RDS와 같은 지원되는 서비스에 대해 이 기능을 활성화하면, Secrets Manager가 사용자가 지정한 일정(예: 30일마다)에 따라 자동으로 데이터베이스의 암호를 교체하고 저장된 보안 암호(Secret)도 업데이트합니다. 이 과정은 AWS가 관리하는 Lambda 함수를 통해 자동으로 처리됩니다.</li>
<li><strong>최소한의 운영 오버헤드</strong>: 자동 순환 기능은 몇 번의 클릭만으로 설정할 수 있습니다. 자격 증명 교체를 위해 별도의 Lambda 함수를 개발하거나 스케줄링을 직접 관리할 필요가 없으므로 운영 오버헤드가 거의 없습니다. 또한 EC2 인스턴스에 <strong>IAM 역할(IAM Role)</strong>을 부여하여 Secrets Manager에 접근 권한을 주는 방식은 AWS의 모범 사례이며, 액세스 키를 관리할 필요가 없어 안전하고 편리합니다.</li>
</ul>
<p><strong>A. 인스턴스 메타데이터에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 인스턴스 메타데이터를 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다.</strong></p>
<ul>
<li><strong>인스턴스 메타데이터에 저장</strong>: 인스턴스 메타데이터는 인스턴스 ID, AMI ID 등 인스턴스 자체에 대한 정보를 제공하는 곳이며, 데이터베이스 자격 증명과 같은 민감한 정보를 저장하는 용도로 설계되지 않았습니다. 보안상 매우 취약한 방법입니다.</li>
</ul>
<p><strong>B. 암호화된 Amazon S3 버킷의 구성 파일에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 구성 파일의 자격 증명을 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다. S3 버전 관리를 사용하여 이전 값으로 폴백하는 기능을 보장합니다.</strong></p>
<ul>
<li><strong>암호화된 S3 버킷에 저장</strong>: S3 버킷을 암호화하여 파일을 저장하는 것은 가능하지만, Secrets Manager처럼 자격 증명을 관리하고 <strong>자동으로 순환하는 기능</strong>이 내장되어 있지 않습니다. 자동 순환을 구현하려면 직접 Lambda 함수를 개발하고 EventBridge로 스케줄링해야 하므로, &quot;최소한의 운영 오버헤드&quot; 요구사항을 충족하지 못합니다.</li>
</ul>
<p><strong>D. 데이터베이스 자격 증명을 AWS Systems Manager Parameter Store 에 암호화된 파라미터로 저장합니다. 암호화된 매개변수에 대해 자동 회전을 켭니다. EC2 역할에 필요한 권한을 연결하여 암호화된 파라미터에 대한 액세스 권한을 부여합니다.</strong></p>
<ul>
<li><strong>AWS Systems Manager Parameter Store에 저장</strong>: Parameter Store 또한 <code>SecureString</code> 파라미터 타입을 사용하여 암호화된 데이터를 저장할 수 있어 Secrets Manager와 자주 비교됩니다. 하지만 결정적인 차이점은 <strong>Parameter Store에는 Secrets Manager와 같은 내장된 자동 순환 기능이 없다</strong>는 것입니다. 자격 증명을 자동으로 순환하려면 옵션 B와 마찬가지로 사용자가 직접 Lambda 함수와 EventBridge를 구성해야 하므로 운영 오버헤드가 더 많이 발생합니다.</li>
</ul>
<h1 id="62">62</h1>
<p>회사에서 AWS 에 새로운 공개 웹 애플리케이션을 배포하고 있습니다. 애플리케이션은 ALB(Application Load Balancer) 뒤에서 실행됩니다. 애플리케이션은 외부 CA(인증 기관)에서 발급한 SSL/TLS 인증서를 사용하여 에지에서 암호화해야 합니다. 인증서가 만료되기 전에 매년 인증서를 교체해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?</p>
<p><strong>D. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 가져옵니다. 인증서를 ALB에 적용합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 인증서가 만료될 때 알림을 보냅니다. 인증서를 수동으로 교체합니다.</strong></p>
<p>이 선택지가 정답인 이유는 문제의 핵심 요구사항인 <strong>&quot;외부 CA(인증 기관)에서 발급한 SSL/TLS 인증서&quot;</strong>를 사용해야 한다는 점을 정확히 충족시키기 때문입니다.</p>
<ul>
<li><strong>&quot;AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 가져옵니다.&quot;</strong>:<ul>
<li>이미 외부 CA(예: GoDaddy, Sectigo 등)에서 발급받은 인증서가 있으므로, 이 인증서를 AWS 환경에서 사용하려면 ACM으로 <strong>가져와야(Import)</strong> 합니다. <code>인증서 가져오기</code>는 외부에서 생성된 인증서와 개인 키를 ACM에 업로드하는 기능입니다.</li>
</ul>
</li>
<li><strong>&quot;인증서를 ALB에 적용합니다.&quot;</strong>:<ul>
<li>ACM으로 가져온 인증서는 ALB, CloudFront 등 AWS의 여러 서비스와 손쉽게 통합하여 적용할 수 있습니다. 이는 에지에서의 암호화(encryption at the edge) 요구사항을 충족합니다.</li>
</ul>
</li>
<li><strong>&quot;Amazon EventBridge...를 사용하여 알림을 보내고... 수동으로 교체합니다.&quot;</strong>:<ul>
<li>이것이 핵심입니다. ACM은 <strong>ACM을 통해 직접 발급한 퍼블릭 인증서에 대해서만 자동 갱신(Managed Renewal)을 지원</strong>합니다.</li>
<li>외부에서 가져온 인증서는 ACM이 자동으로 갱신해 줄 수 없습니다. 따라서 인증서 소유자가 만료일 전에 직접 외부 CA에서 인증서를 갱신하고, 새로 갱신된 인증서를 다시 ACM으로 가져와(Import) 기존 인증서를 교체해야 합니다.</li>
<li>이러한 수동 작업을 잊지 않도록, Amazon EventBridge(구 CloudWatch Events)를 사용하여 ACM 인증서 만료 이벤트를 감지하고, 담당자에게 이메일이나 SNS 알림을 보내도록 구성하는 것이 모범 사례입니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, C가 적절하지 않은 이유</strong></p>
<p><strong>A. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서를 ALB 에 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 교체합니다.</strong></p>
<p><strong>B. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서에서 키 자료를 가져옵니다. AL 에 인증서 적용 관리되는 갱신 기능을 사용하여 인증서를 자동으로 교체합니다.</strong></p>
<ul>
<li>이 선택지는 &quot;외부 CA에서 발급한 인증서&quot;를 사용하라는 요구사항을 위반합니다. 이 방법은 ACM을 <strong>공인된 CA로 사용하여</strong> 새로운 인증서를 <strong>발급(Issue)</strong>하는 경우에 해당합니다. 물론 이 방법은 무료이고 자동 갱신되어 매우 편리하지만, 문제에서 제시한 제약 조건과는 맞지 않습니다.</li>
</ul>
<p><strong>C. AWS Certificate Manager(ACM) 사설 인증 기관을 사용하여 루트 CA 에서 SSL/TLS 인증서를 발급합니다. 인증서를 ALB 에 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 교체합니다.</strong></p>
<ul>
<li>문제에서는 <strong>&quot;공개 웹 애플리케이션(Public Web Application)&quot;</strong>을 배포한다고 명시했습니다. <code>ACM Private Certificate Authority(사설 인증 기관)</code>에서 발급한 인증서는 인터넷의 일반 사용자가 신뢰하지 않는 사설 인증서입니다. 이 인증서를 공개 웹 애플리케이션에 사용하면, 사용자들의 브라우저에서 &quot;신뢰할 수 없는 인증서&quot;라는 보안 경고가 발생합니다. 사설 인증서는 내부 시스템 간의 통신, API 호출 등 신뢰 관계가 미리 설정된 환경에서만 사용해야 합니다.</li>
</ul>
<h1 id="63">63</h1>
<p>회사는 AWS 에서 인프라를 실행하고 문서 관리 애플리케이션에 대해 700,000 명의 등록 기반을 보유하고 있습니다. 회사는 큰 .pdf 파일을 .jpg 이미지 파일로 변환하는 제품을 만들려고 합니다. .pdf 파일의 크기는 평균 5MB 입니다. 회사는 원본 파일과 변환 파일을 보관해야 합니다. 솔루션 설계자는 시간이 지남에 따라 빠르게 증가할 수요를 수용할 수 있는 확장 가능한 솔루션을 설계해야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?</p>
<p><strong>A. .pdf 파일을 Amazon S3 에 저장합니다. AWS Lambda 함수를 호출하여 파일을 .jpg 형식으로 변환하고 Amazon S3에 다시 저장하도록 S3 PUT 이벤트를 구성합니다.</strong></p>
<ul>
<li><strong>뛰어난 확장성 (Scalability)</strong><ul>
<li><strong>Amazon S3</strong>: S3는 사실상 무한한 확장이 가능한 객체 스토리지입니다. 70만 명의 사용자가 얼마나 많은 파일을 업로드하더라도 저장 공간 부족을 걱정할 필요가 없습니다. 데이터가 증가함에 따라 자동으로 확장됩니다.</li>
<li><strong>AWS Lambda</strong>: Lambda는 이벤트 기반으로 코드를 실행하는 컴퓨팅 서비스입니다. S3에 파일이 업로드될 때마다(<code>PUT</code> 이벤트) Lambda 함수가 트리거되어 실행됩니다. 수요가 급증하여 동시에 수천 개의 파일이 업로드되더라도, AWS는 그 수에 맞춰 Lambda 함수를 동시에 실행시켜 줍니다(Concurrent Executions). 따라서 사용자가 직접 서버 수를 조절하는 오토 스케일링을 구성할 필요 없이 완벽하게 수요에 대응할 수 있습니다.</li>
</ul>
</li>
<li><strong>높은 비용 효율성 (Cost-Effectiveness)</strong><ul>
<li>이 아키텍처는 사용한 만큼만 비용을 지불하는 <strong>Pay-as-you-go</strong> 모델을 극대화합니다.</li>
<li><strong>S3</strong>: 파일을 저장하는 용량과 요청 수에 대해서만 비용을 지불합니다.</li>
<li><strong>Lambda</strong>: 함수가 호출된 횟수와 실행된 시간(밀리초 단위)에 대해서만 비용을 지불합니다. 즉, 파일 변환 작업이 없을 때는 <strong>단 1원의 비용도 발생하지 않습니다.</strong> 이는 24시간 내내 서버를 켜둬야 하는 EC2 방식에 비해 압도적으로 저렴합니다.</li>
</ul>
</li>
<li><strong>관리 용이성 (Ease of Management)</strong><ul>
<li>서버를 프로비저닝하거나 관리할 필요가 전혀 없습니다. 운영체제 업데이트, 보안 패치 등 인프라 관리에 대한 부담이 사라져 개발자는 오직 파일 변환 로직(Lambda 함수 코드)에만 집중할 수 있습니다.</li>
</ul>
</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. .pdf 파일을 Amazon DynamoD 에 저장 DynamoDB 스트림 기능을 사용하여 AWS Lambda 함수를 호출하여 파일을 .jpg 형식으로 변환하고 DynamoDB에 다시 저장합니다.</strong></p>
<ul>
<li><strong>근본적인 설계 오류</strong>: Amazon DynamoDB는 Key-Value 형태의 NoSQL 데이터베이스로, 주로 작은 크기의 데이터(JSON, 사용자 프로필, 메타데이터 등)를 매우 빠른 속도로 처리하기 위해 설계되었습니다.</li>
<li><strong>파일 크기 제한</strong>: DynamoDB의 항목(Item) 당 최대 크기는 <strong>400KB</strong>입니다. 문제에서 주어진 <code>.pdf</code> 파일의 평균 크기는 <strong>5MB</strong>이므로 DynamoDB에 직접 저장하는 것 자체가 불가능합니다. 따라서 이 선택지는 기술적으로 실행 불가능한 방안입니다.</li>
</ul>
<p><strong>C. Amazon EC2 인스턴스, Amazon Elastic Block Store(Amazon EBS) 스토리지 및 Auto Scaling 그룹이 포함된 AWS Elastic Beanstalk 애플리케이션에 .pdf 파일을 업로드합니다. EC2 인스턴스의 프로그램을 사용하여 파일을 .jpg 형식으로 변환합니다. .pdf 파일과 .jpg 파일을 EBS 스토어에 저장합니다.</strong></p>
<ul>
<li><strong>스토리지 문제 (단일 장애점)</strong>: Amazon EBS(Elastic Block Store)는 특정 EC2 인스턴스에 연결되는 블록 스토리지입니다. Auto Scaling 그룹 내의 다른 EC2 인스턴스는 특정 인스턴스에 연결된 EBS 볼륨에 직접 접근할 수 없습니다. 이는 다음과 같은 심각한 문제를 야기합니다.<ul>
<li>파일을 처리한 EC2 인스턴스가 장애로 종료되거나 오토 스케일링 정책에 따라 축소되면 해당 EBS 볼륨에 저장된 파일은 유실될 위험이 있습니다 (종료 시 삭제 옵션이 활성화된 경우).</li>
<li>확장성을 위해 여러 EC2 인스턴스가 실행되더라도, 파일이 각 인스턴스에 종속되어 있어 상태를 공유할 수 없는 <strong>상태 저장(Stateful) 아키텍처</strong>가 되어버립니다. 이는 확장 가능한 애플리케이션 설계의 안티 패턴입니다.</li>
</ul>
</li>
<li><strong>비용 비효율성</strong>: 파일 변환 요청이 없을 때도 EC2 인스턴스는 계속 실행되어야 하므로 유휴 시간에 대한 비용이 지속적으로 발생합니다. Lambda에 비해 훨씬 비효율적입니다.</li>
</ul>
<p><strong>D. .pdf 파일을 Amazon EC2 인스턴스, Amazon Elastic File System(Amazon EFS) 스토리지 및 Auto Scaling 그룹이 포함된 AWS Elastic Beanstalk 애플리케이션에 업로드합니다. EC2 인스턴스의 프로그램을 사용하여 파일을 .jpg 형식으로 변환합니다. .pdf 파일과 .jpg 파일을 EBS 스토어에 저장합니다.</strong></p>
<ul>
<li><strong>비용 문제</strong>: 하지만 이 솔루션은 <strong>가장 비용 효율적인</strong> 방안이 아닙니다.<ul>
<li><strong>EFS 비용</strong>: EFS는 고성능 공유 파일 시스템인 만큼, 단순 객체 저장소인 S3에 비해 스토리지 비용이 훨씬 비쌉니다. 단순히 원본과 변환 파일을 보관하는 용도로는 과도한 비용이 발생합니다.</li>
<li><strong>EC2 비용</strong>: C와 마찬가지로, 유휴 시간에도 EC2 인스턴스를 유지해야 하므로 Lambda 방식보다 비용이 많이 듭니다.</li>
</ul>
</li>
<li><strong>관리 복잡성</strong>: 여전히 EC2 인스턴스, 오토 스케일링 그룹, EFS 파일 시스템 등 관리해야 할 요소가 많아 서버리스 방식인 A에 비해 운영 부담이 큽니다.</li>
</ul>
<h1 id="64">64</h1>
<p>회사는 온프레미스에서 실행되는 Windows 파일 서버에 5TB 이상의 파일 데이터를 가지고 있습니다. 사용자와 애플리케이션은 매일 데이터와 상호 작용합니다. 이 회사는 Windows 워크로드를 AWS 로 이전하고 있습니다. 회사가 이 프로세스를 계속함에 따라 회사는 최소 지연 시간으로 AWS 및 온프레미스 파일 스토리지에 액세스할 수 있어야 합니다. 회사는 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 크게 변경할 필요가 없는 솔루션이 필요합니다. 회사는 AWS 연결을 위해 AWS Site-to-Site VPN 연결을 사용합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?</p>
<p><strong>D. AWS 에서 Windows 파일 서버용 Amazon FSx 를 배포 및 구성합니다. 온프레미스에 Amazon FSx 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 FSx 파일 게이트웨이로 이동합니다. AWS 의 Windows 파일 서버용 FSx 를 사용하도록 클라우드 워크로드를 구성합니다. FSx 파일 게이트웨이를 사용하도록 온프레미스 워크로드를 구성합니다.</strong></p>
<ul>
<li><strong>최소 지연 시간 (Low Latency):</strong><ul>
<li><strong>온프레미스 사용자:</strong> <strong>Amazon FSx 파일 게이트웨이</strong>는 온프레미스 데이터 센터에 배포됩니다. 이 게이트웨이는 자주 액세스하는 데이터를 로컬에 <strong>캐싱(caching)</strong>합니다. 따라서 온프레미스 사용자와 애플리케이션은 로컬 네트워크 속도로 파일에 접근할 수 있어 지연 시간이 최소화됩니다.</li>
<li><strong>AWS의 워크로드:</strong> AWS 내에서 실행되는 워크로드는 클라우드에 있는 <strong>Amazon FSx for Windows File Server</strong>에 직접 액세스합니다. 동일한 AWS 리전 내에서의 통신이므로 매우 낮은 지연 시간으로 파일에 접근할 수 있습니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, C가 적절하지 않은 이유</strong></p>
<p><strong>A. AWS에서 Windows 파일 서버용 Amazon FSx를 배포 및 구성합니다. 온-프레미스 파일 데이터를 Windows 파일 서버용 FSx로 이동합니다. AWS에서 Windows 파일 서버용 FSx를 사용하도록 워크로드를 재구성합니다.</strong></p>
<ul>
<li>이 방법은 데이터를 AWS로 완전히 이전하는 <strong>'리프트 앤 시프트(Lift and Shift)'</strong> 방식입니다. 이렇게 되면 <strong>온프레미스 사용자는 모든 파일에 접근할 때마다 Site-to-Site VPN을 거쳐야 합니다.</strong> 이는 로컬 파일 서버에 접근하는 것에 비해 <strong>심각한 지연 시간(latency)</strong>을 유발하며, &quot;최소 지연 시간으로... 온프레미스 파일 스토리지에 액세스할 수 있어야 한다&quot;는 핵심 요구사항을 위반합니다.</li>
</ul>
<h1 id="65">65</h1>
<p>병원은 최근 Amazon API Gateway 및 AWS Lambda와 함께 RESTful API를 배포했습니다. 병원은 API Gateway 및 Lambda 를 사용하여 PDF 형식 및 JPEG 형식의 보고서를 업로드합니다. 병원은 보고서에서 보호되는 건강 정보(PHI)를 식별하기 위해 Lambda 코드를 수정해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?</p>
<p><strong>C. Amazon Textract 를 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical 을 사용하여 추출된 텍스트에서 PHI를 식별합니다.</strong></p>
<ul>
<li><strong>Amazon Textract</strong>:<ul>
<li><strong>역할</strong>: PDF 및 JPEG와 같은 문서 이미지에서 텍스트, 필기, 양식 데이터 및 표를 자동으로 추출하는 서비스입니다.</li>
<li><strong>장점</strong>: 병원 보고서가 PDF 및 JPEG 형식이므로, Textract를 사용하면 복잡한 OCR(광학 문자 인식) 엔진을 직접 구축하거나 관리할 필요 없이 간단한 API 호출만으로 보고서의 모든 텍스트를 정확하게 추출할 수 있습니다. 이는 &quot;최소한의 운영 오버헤드&quot;라는 요구사항을 완벽하게 만족시킵니다.</li>
</ul>
</li>
<li><strong>Amazon Comprehend Medical</strong>:<ul>
<li><strong>역할</strong>: 의료 텍스트에서 PHI(보호 대상 건강 정보), 의료 상태, 약물, 치료법 등과 같은 주요 의료 정보를 식별하는 HIPAA 적격 자연어 처리(NLP) 서비스입니다.</li>
<li><strong>장점</strong>: 이 서비스는 의료 분야에 특화되어 있고 이미 방대한 의료 데이터로 사전 훈련되어 있습니다. 따라서 개발팀이 직접 머신러닝 모델을 훈련시키거나 복잡한 규칙 기반 시스템을 만들 필요가 없습니다. Textract로 추출된 텍스트를 Comprehend Medical API로 전달하기만 하면 매우 높은 정확도로 PHI를 식별하고 분류할 수 있습니다. 이 또한 &quot;최소한의 운영 오버헤드&quot; 요구사항에 부합합니다</li>
</ul>
</li>
</ul>
<p><strong>A, B, D가 적절하지 않은 이유</strong></p>
<p><strong>A. 기존 Python 라이브러리를 사용하여 보고서에서 텍스트를 추출하고 추출된 텍스트에서 PHI 를 식별합니다.</strong></p>
<p><strong>B. Amazon Textract 를 사용하여 보고서에서 텍스트를 추출합니다. Amazon SageMaker 를 사용하여 추출된 텍스트에서 PHI를 식별합니다.</strong></p>
<ul>
<li><strong>운영 오버헤드가 매우 높습니다</strong>.</li>
</ul>
<p><strong>D. Amazon Rekognition 을 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical 을 사용하여 추출된 텍스트에서 PHI를 식별합니다.</strong></p>
<ul>
<li>Amazon Rekognition은 이미지 및 비디오 분석 서비스로, 이미지 속 객체, 사람, 장면, 텍스트 등을 감지할 수 있습니다. <code>DetectText</code> API를 통해 텍스트를 추출할 수는 있지만, 이는 일반적인 이미지 속 텍스트 감지에 더 중점을 둡니다</li>
</ul>
<h1 id="66">66</h1>
<p>회사에 각각 크기가 약 5MB 인 많은 수의 파일을 생성하는 응용 프로그램이 있습니다. 파일은 Amazon S3에 저장됩니다. 회사 정책에 따라 파일을 삭제하려면 4년 동안 보관해야 합니다. 파일에는 재생산하기 쉽지 않은 중요한 비즈니스 데이터가 포함되어 있으므로 즉각적인 액세스가 항상 필요합니다. 파일은 객체 생성 후 처음 30 일 동안 자주 액세스되지만 처음 30일 후에는 거의 액세스되지 않습니다. 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?</p>
<p><strong>C. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 삭제합니다.</strong></p>
<h1 id="67">67</h1>
<p>회사는 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 애플리케이션은 Amazon SQS 대기열의 메시지를 처리하고 Amazon RDS 테이블에 쓰고 대기열에서 메시지를 삭제합니다. RDS 테이블에서 가끔 중복 레코드가 발견됩니다. SQS 대기열에는 중복 메시지가 없습니다. 메시지가 한 번만 처리되도록 솔루션 설계자는 무엇을 해야 합니까?</p>
<p><strong>D. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘립니다.</strong></p>
<ul>
<li>이 문제를 해결하려면 <strong>메시지 처리 시간보다 가시성 제한 시간을 충분히 길게 설정</strong>해야 합니다. <code>ChangeMessageVisibility</code> API를 사용하면 이미 수신한 특정 메시지의 가시성 제한 시간을 동적으로 늘릴 수 있습니다. 또는 대기열 자체의 기본 가시성 제한 시간을 늘리는 방법도 있습니다. 이렇게 하면 소비자가 작업을 완료하고 <code>DeleteMessage</code>를 호출할 충분한 시간을 확보하여 메시지가 다시 대기열에 나타나는 것을 방지할 수 있습니다.</li>
</ul>
<p><strong>A, B, C가 정답이 아닌 이유</strong></p>
<p><strong>B. AddPermission API 호출을 사용하여 적절한 권한을 추가합니다.</strong></p>
<ul>
<li>권한(Permission) 문제는 보통 &quot;Access Denied&quot;와 같은 명시적인 오류를 발생시킵니다. 문제 설명에 따르면 애플리케이션은 메시지를 처리하고 RDS에 데이터를 쓰고 있으므로, 기본적인 권한은 이미 설정되어 있는 상태입니다. 권한 부족은 작업 실패의 원인이 될 수는 있지만, <strong>간헐적인 중복 처리</strong>의 원인이 되지는 않습니다.</li>
</ul>
<p><strong>C. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다.</strong></p>
<ul>
<li>롱 폴링은 <strong>메시지를 수신하기 전</strong>의 대기 시간에 관한 것이고, 가시성 제한 시간은 <strong>메시지를 수신한 후</strong>의 처리 시간에 관한 것입니다. 따라서 롱 폴링 설정은 중복 처리 문제와 직접적인 관련이 없습니다.</li>
</ul>
<h1 id="68">68</h1>
<p>솔루션 설계자는 회사의 온프레미스 인프라를 AWS 로 확장하기 위해 새로운 하이브리드 아키텍처를 설계하고 있습니다. 이 회사는 AWS 리전에 대해 일관되게 짧은 지연 시간과 고가용성 연결이 필요합니다. 회사는 비용을 최소화해야 하며 기본 연결이 실패할 경우 더 느린 트래픽을 기꺼이 받아들입니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<p><strong>A. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 연결이 실패하는 경우 백업으로 VPN 연결을 프로비저닝합니다.</strong> </p>
<ul>
<li><strong>고성능 연결</strong> : <strong>AWS Direct Connect(DX)</strong>는 온프레미스 데이터 센터와 AWS 간의 전용 프라이빗 네트워크 연결을 제공합니다. 인터넷을 거치지 않으므로 일관되고 짧은 지연 시간을 보장할 수 있어 핵심 요구사항을 완벽하게 만족시킵니다.</li>
<li><strong>비용 최소화 및 장애 조치</strong> : 기본 DX 연결에 장애가 발생했을 때를 대비한 백업으로 <strong>IPSec VPN 연결</strong>을 구성합니다.<ul>
<li>VPN은 인터넷을 통해 연결되므로 DX보다 저렴하게 구성할 수 있습니다. 이는 <strong>비용 최소화</strong> 요구사항을 만족시킵니다.</li>
<li>VPN은 DX보다 지연 시간이 길고 성능이 일관적이지 않을 수 있지만, 문제에서 '<strong>더 느린 트래픽을 기꺼이 받아들인다'</strong>고 명시했기 때문에 백업 솔루션으로 매우 적합합니다.</li>
</ul>
</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. 개인 연결을 위해 지역에 VPN 터널 연결을 프로비저닝합니다. 기본 VPN 연결이 실패할 경우 개인 연결 및 백업으로 두 번째 VPN 터널을 프로비저닝합니다.</strong></p>
<ul>
<li>VPN은 공용 인터넷을 통해 데이터를 전송하므로 네트워크 혼잡 등 외부 요인에 따라 성능이 변동될 수 있습니다. 따라서 <strong>'일관되게 짧은 지연 시간'</strong>이라는 핵심 요구사항을 기본 연결부터 만족시키지 못합니다.</li>
</ul>
<p><strong>C. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 연결이 실패하는 경우 백업과 동일한 지역에 두 번째 Direct Connect 연결을 프로비저닝합니다.</strong> </p>
<ul>
<li>이 구성은 최고의 가용성과 성능을 제공하지만(Active-Active 또는 Active-Passive DX), <strong>'비용을 최소화해야 한다'</strong>는 요구사항에 위배됩니다. Direct Connect 회선을 두 개 프로비저닝하는 것은 VPN을 백업으로 사용하는 것보다 훨씬 비쌉니다. 문제에서 더 느린 백업을 허용한다고 했으므로, 이렇게까지 구성할 필요가 없습니다.</li>
</ul>
<p><strong>D. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. AWS CLI 에서 Direct Connect 장애 조치 속성을 사용하여 기본 Direct Connect 연결이 실패할 경우 백업 연결을 자동으로 생성합니다.</strong></p>
<ul>
<li>이 설명은 기술적으로 올바르지 않습니다. AWS에는 <strong>'실패 시 백업 연결을 자동으로 생성하는' 기능이 없습니다.</strong> 장애 조치를 위해서는 백업 연결(VPN 또는 다른 DX 회선)을 <strong>미리 프로비저닝하고 구성</strong>해 두어야 합니다.
즉, 장애 발생 시점에 연결을 '생성'하는 것이 아니라, 미리 만들어 둔 연결로 '전환'하는 것입니다.</li>
</ul>
<h1 id="69">69</h1>
<p>회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 비즈니스 크리티컬 웹 애플리케이션을 실행하고 있습니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. 애플리케이션은 단일 가용 영역에 배포된 Amazon Aurora PostgreSQL 데이터베이스를 사용합니다. 회사는 다운타임과 데이터 손실을 최소화하면서 애플리케이션의 고가용성을 원합니다. 최소한의 운영 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>B. 여러 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스를 다중 AZ로 구성합니다. 데이터베이스에 대한 Amazon RDS 프록시 인스턴스를 구성합니다.</strong> </p>
<ul>
<li><strong>여러 가용 영역(Multi-AZ)을 사용하도록 Auto Scaling 그룹 구성</strong>:<ul>
<li><strong>고가용성 확보</strong>: 하나의 가용 영역(AZ)에 장애가 발생하더라도 다른 AZ에 있는 EC2 인스턴스들이 계속해서 트래픽을 처리할 수 있습니다. Application Load Balancer가 자동으로 장애가 발생한 AZ를 감지하고 정상 AZ로만 트래픽을 라우팅하여 서비스 중단을 방지합니다.</li>
<li><strong>최소한의 운영 노력</strong>: Auto Scaling 그룹이 자동으로 인스턴스 수를 관리해주므로 운영 부담이 적습니다.</li>
</ul>
</li>
<li><strong>데이터베이스를 다중 AZ(Multi-AZ)로 구성</strong>:<ul>
<li><strong>데이터 손실 및 다운타임 최소화</strong>: 현재 구성의 가장 큰 약점은 단일 AZ에 있는 데이터베이스입니다. Aurora 데이터베이스를 다중 AZ로 구성하면 다른 AZ에 동기식(Synchronous) 스탠바이 복제본이 생성됩니다. 주 데이터베이스에 장애가 발생하면 AWS가 자동으로, 보통 1분 이내에 스탠바이 복제본으로 장애 조치(Failover)를 수행합니다. 동기식 복제이므로 데이터 손실이 거의 없습니다.</li>
<li><strong>최소한의 운영 노력</strong>: 장애 조치 과정이 자동으로 이루어지므로 관리자가 직접 개입할 필요가 없습니다.</li>
</ul>
</li>
<li><strong>Amazon RDS 프록시 인스턴스 구성</strong>:<ul>
<li><strong>다운타임 최소화 (연결 관리)</strong>: 데이터베이스 장애 조치 시, 애플리케이션은 데이터베이스 연결을 끊고 새로 승격된 데이터베이스에 다시 연결해야 합니다. 이 과정에서 지연이 발생할 수 있습니다. RDS 프록시는 애플리케이션과 데이터베이스 사이에서 연결 풀을 관리하여, 장애 조치가 발생하더라도 애플리케이션의 연결을 유지하면서 새 데이터베이스로 신속하게 요청을 전달합니다. 이를 통해 장애 조치 시간을 더욱 단축하고 애플리케이션의 복원력을 높입니다.</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지 않은 이유</strong></p>
<p><strong>A. EC2 인스턴스를 다른 AWS 리전에 배치합니다. Amazon Route 53 상태 확인을 사용하여 트래픽을 리디렉션합니다. Aurora PostgreSQL 교차 리전 복제를 사용합니다.</strong> </p>
<ul>
<li>이 구성은 <strong>고가용성(High Availability)</strong>이 아닌 <strong>재해 복구(Disaster Recovery)</strong>에 가깝습니다.<ul>
<li><strong>과도한 복잡성</strong>: 여러 리전을 관리하는 것은 단일 리전 내 여러 AZ를 관리하는 것보다 훨씬 복잡하고 운영 부담이 큽니다.</li>
<li><strong>데이터 손실 가능성</strong>: 교차 리전 복제(Cross-Region Replication)는 일반적으로 비동기식(Asynchronous)으로 작동합니다. 따라서 장애 발생 시 마지막으로 복제된 시점 이후의 데이터는 유실될 수 있습니다. 이는 '데이터 손실 최소화' 요구사항에 부합하지 않습니다.</li>
<li><strong>비용</strong>: 여러 리전에 걸쳐 인프라를 유지하는 것은 비용이 더 많이 듭니다.</li>
</ul>
</li>
</ul>
<p><strong>C. 하나의 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스의 시간별 스냅샷을 생성합니다. 장애가 발생한 경우 스냅샷에서 데이터베이스를 복구합니다.</strong> </p>
<ul>
<li>이 방법은 고가용성 전략이 아니라 기본적인 백업 및 복구 절차입니다.<ul>
<li><strong>긴 다운타임</strong>: 스냅샷에서 데이터베이스를 복구하는 데는 수십 분에서 몇 시간이 걸릴 수 있습니다. 이는 '다운타임 최소화' 요구사항을 전혀 만족시키지 못합니다.</li>
<li><strong>큰 데이터 손실</strong>: 시간별 스냅샷을 사용하므로 장애 발생 시 최대 1시간 분량의 데이터가 손실될 수 있습니다.</li>
<li><strong>단일 장애 지점</strong>: 애플리케이션과 데이터베이스가 모두 단일 AZ에 있어 해당 AZ에 장애가 발생하면 전체 서비스가 중단됩니다.</li>
</ul>
</li>
</ul>
<p><strong>D. 여러 AWS 리전을 사용하도록 Auto Scaling 그룹을 구성합니다. 애플리케이션의 데이터를 Amazon S3에 씁니다. S3 이벤트 알림을 사용하여 AWS Lambda 함수를 시작하여 데이터베이스에 데이터를 씁니다.</strong></p>
<ul>
<li>불필요하게 아키텍처를 복잡하게 만듭니다.</li>
</ul>
<h1 id="70">70</h1>
<p>회사의 HTTP 애플리케이션은 NLB(Network Load Balancer) 뒤에 있습니다. NLB 의 대상 그룹은 웹 서비스를 실행하는 여러 EC2 인스턴스와 함께 Amazon EC2 Auto Scaling 그룹을 사용하도록 구성됩니다. 회사는 NLB 가 애플리케이션에 대한 HTTP 오류를 감지하지 못한다는 것을 알게 되었습니다. 이러한 오류는 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 다시 시작해야 합니다. 회사는 사용자 정의 스크립트나 코드를 작성하지 않고 애플리케이션의 가용성을 개선해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<p><strong>C. NLB를 Application Load Balancer 로 교체합니다. 회사 애플리케이션의 URL을 제공하여 HTTP 상태 확인을 활성화합니다. 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 구성합니다.</strong> </p>
<p><strong>문제의 핵심 파악: Layer 4 vs Layer 7</strong></p>
<ul>
<li><strong>NLB(Network Load Balancer)</strong>는 OSI 모델의 <strong>Layer 4(전송 계층)</strong>에서 작동합니다. 주로 TCP/UDP 트래픽을 처리하며, 매우 빠르고 고성능입니다. NLB의 기본 상태 확인은 대상(EC2 인스턴스)의 특정 포트가 열려 있고 TCP 연결에 응답하는지만 확인합니다. 애플리케이션이 <code>HTTP 500 (서버 내부 오류)</code> 같은 오류 코드를 반환하더라도, 서버 자체는 살아있고 포트가 열려 있다면 NLB는 해당 인스턴스를 '정상'으로 판단합니다. 이것이 바로 문제에서 &quot;NLB가 애플리케이션에 대한 HTTP 오류를 감지하지 못한다&quot;고 한 이유입니다.</li>
<li><strong>ALB(Application Load Balancer)</strong>는 OSI 모델의 <strong>Layer 7(애플리케이션 계층)</strong>에서 작동합니다. HTTP/HTTPS 트래픽의 내용(헤더, 경로 등)을 이해하고 이를 기반으로 라우팅할 수 있습니다. ALB의 상태 확인은 특정 URL 경로(<code>healthcheck.html</code> 등)를 호출하고, <code>HTTP 200 OK</code> 와 같은 <strong>특정 HTTP 응답 코드를 받았는지</strong>를 확인할 수 있습니다.</li>
<li>문제의 근본 원인인 'HTTP 오류 감지 불가'를 해결하기 위해 Layer 7에서 작동하는 ALB로 교체합니다.</li>
</ul>
<h1 id="71">71</h1>
<p>한 회사는 Amazon DynamoDB 를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 실행합니다. 데이터 손상의 경우 솔루션 설계자는 15분의 RPO(복구 시점 목표)와 1시간의 RTO(복구 시간 목표)를 충족하는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? </p>
<p><strong>B. DynamoDB 지정 시간 복구를 구성합니다. RPO 복구의 경우 원하는 시점으로 복원합니다.</strong> </p>
<ul>
<li><strong>지정 시간 복구(Point-in-Time Recovery, PITR)</strong>는 DynamoDB 테이블의 데이터를 지속적으로 백업하여 지난 35일 동안의 특정 시점(초 단위까지 정확하게)으로 테이블을 복원할 수 있게 해주는 기능입니다.<ol>
<li><strong>RPO (복구 시점 목표) 15분 충족</strong>:<ul>
<li>PITR은 데이터를 거의 실시간으로 계속 백업합니다. 만약 데이터가 손상되면 손상 발생 직전의 특정 초 단위 시점으로 테이블을 복원할 수 있습니다.</li>
<li>문제에서 요구하는 RPO는 15분인데, PITR을 사용하면 데이터 손실을 거의 0에 가깝게 (몇 초 이내로) 줄일 수 있으므로 <strong>15분 RPO 요구사항을 충분히 만족</strong>합니다.</li>
</ul>
</li>
<li><strong>RTO (복구 시간 목표) 1시간 충족</strong>:<ul>
<li>PITR을 사용하여 테이블을 복원하면, AWS는 지정된 시점의 데이터를 가진 <strong>새로운 테이블</strong>을 생성합니다.</li>
<li>테이블의 크기에 따라 복원 시간이 달라지지만, 일반적인 경우 이 과정은 수 분에서 한 시간 내에 완료됩니다. 복원이 완료되면 애플리케이션의 엔드포인트를 새 테이블로 변경하기만 하면 됩니다.</li>
<li>따라서 <strong>1시간 RTO 요구사항을 현실적으로 충족</strong>할 수 있습니다.</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><strong>A. DynamoDB 전역 테이블을 구성합니다. RPO 복구의 경우 애플리케이션이 다른 AWS 리전을 가리키도록 합니다.</strong> </p>
<ul>
<li>전역 테이블의 주 목적은 <strong>고가용성</strong>과 <strong>전 세계 사용자에게 낮은 지연 시간</strong>을 제공하는 것입니다. 한 리전에서 발생한 변경 사항(쓰기 작업)이 다른 모든 리전으로 수 초 내에 자동으로 복제됩니다.</li>
<li>만약 한 리전에서 데이터가 <strong>손상</strong>(예: 실수로 아이템 삭제 또는 잘못된 데이터로 업데이트)되면, 이 <strong>손상된 데이터가 즉시 다른 모든 리전으로 복제</strong>됩니다. 따라서 다른 리전으로 장애 조치(failover)해도 손상된 데이터를 그대로 보게 되므로, 데이터 손상 시나리오의 해결책이 될 수 없습니다. 이것은 리전 장애 상황에 대한 해결책이지, 데이터 자체의 논리적 오류를 복구하는 해결책이 아닙니다.</li>
</ul>
<p><strong>C. DynamoDB 데이터를 매일 Amazon S3 Glacier 로 내보냅니다. RPO 복구의 경우 S3 Glacier 에서 DynamoDB 로 데이터를 가져옵니다.</strong> </p>
<ul>
<li><strong>(RPO 위반)</strong>: &quot;매일&quot; 백업을 수행하므로, 최대 <strong>24시간</strong>의 데이터가 손실될 수 있습니다. 이는 <strong>15분의 RPO 요구사항을 크게 위반</strong>합니다.</li>
<li><strong>(RTO 위반)</strong>: S3 Glacier는 장기 보관용 아카이브 스토리지로, 데이터 검색(retrieval)에 수 분에서 수 시간이 걸립니다. 데이터를 검색한 후에도 다시 DynamoDB로 가져오는(import) 시간이 추가로 필요합니다. 전체 과정이 수 시간이 걸릴 수 있으므로 <strong>1시간 RTO 요구사항을 절대 만족할 수 없습니다.</strong></li>
</ul>
<p><strong>D. DynamoDB 테이블에 대한 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 15 분마다 예약합니다. RPO 복구의 경우 EBS 스냅샷을 사용하여 DynamoDB 테이블을 복원합니다.</strong></p>
<ul>
<li>Amazon EBS는 EC2 인스턴스에 연결하여 사용하는 블록 스토리지입니다. 따라서 <strong>DynamoDB 테이블에 대해 EBS 스냅샷을 직접 생성할 수 없습니다.</strong> 두 서비스는 완전히 분리되어 있으며 이러한 방식의 연동은 지원되지 않습니다.</li>
</ul>
<h1 id="72">72</h1>
<p>회사는 동일한 AWS 리전에 있는 Amazon S3 버킷에서 사진을 자주 업로드 및 다운로드해야 하는 사진 처리 애플리케이션을 실행합니다. 솔루션 설계자는 데이터 전송 비용이 증가한다는 사실을 알게 되었고 이러한 비용을 줄이기 위한 솔루션을 구현해야 합니다. 솔루션 설계자는 이 요구 사항을 어떻게 충족할 수 있습니까? </p>
<p><strong>D. S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 정책을 연결합니다.</strong></p>
<ul>
<li>VPC 내에 있는 EC2 인스턴스와 같은 리소스가 S3 버킷에 액세스할 때, 기본적으로는 <strong>인터넷을 통해 S3의 퍼블릭 엔드포인트에 연결</strong>됩니다. 이 과정에서 데이터 전송 비용이 발생하게 됩니다.<ul>
<li><strong>프라이빗 서브넷의 경우:</strong> 인스턴스가 직접 인터넷에 연결할 수 없으므로, <strong>NAT 게이트웨이</strong>를 통해 S3에 접속합니다. 이 경우 NAT 게이트웨이 처리 비용과 데이터 전송 비용이 함께 발생하여 비용 증가의 주된 원인이 됩니다.</li>
<li><strong>퍼블릭 서브넷의 경우:</strong> <strong>인터넷 게이트웨이</strong>를 통해 S3에 접속하며, 이때도 데이터 전송 비용이 발생합니다.</li>
</ul>
</li>
<li><strong>S3 게이트웨이 엔드포인트(Gateway Endpoint)</strong>는 이러한 문제를 해결하기 위해 만들어졌습니다.<ol>
<li><strong>프라이빗 연결:</strong> VPC와 S3 서비스 간의 <strong>프라이빗 경로</strong>를 제공합니다. 즉, VPC 내의 리소스가 인터넷 게이트웨이나 NAT 게이트웨이를 거치지 않고 AWS 내부 네트워크를 통해 직접 S3에 안전하게 액세스할 수 있습니다.</li>
<li><strong>비용 절감:</strong> 동일 리전 내에서 게이트웨이 엔드포인트를 통해 EC2와 S3 간에 전송되는 데이터에 대해서는 <strong>데이터 전송 요금이 부과되지 않습니다.</strong> 이것이 비용을 절감하는 가장 핵심적인 이유입니다.</li>
<li><strong>보안 강화:</strong> 엔드포인트 정책을 사용하여 VPC에서 액세스할 수 있는 S3 버킷이나 특정 API 작업(예: <code>GetObject</code>, <code>PutObject</code>)을 제어할 수 있어 보안이 향상됩니다.</li>
</ol>
</li>
</ul>
<p><strong>A, B, C는 적절하지 않은 이유</strong></p>
<p><strong>A. Amazon API Gateway 를 퍼블릭 서브넷에 배포하고 이를 통해 S3 호출을 라우팅하도록 라우팅 테이블을 조정합니다.</strong> </p>
<ul>
<li>API Gateway는 RESTful API를 생성, 게시, 유지 관리하는 서비스입니다. S3와 연동하여 API를 만들 수는 있지만, 근본적인 데이터 전송 경로를 바꾸지는 못합니다. VPC 내의 애플리케이션이 이 API Gateway 엔드포인트를 호출하려면 여전히 인터넷을 경유해야 하므로 데이터 전송 비용 절감 효과가 없습니다. 오히려 API Gateway 사용에 따른 추가 비용이 발생할 수 있습니다.</li>
</ul>
<p><strong>B. NAT 게이트웨이를 퍼블릭 서브넷에 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 정책을 연결합니다.</strong> </p>
<ul>
<li>NAT 게이트웨이는 프라이빗 서브넷의 리소스가 외부 인터넷(S3 퍼블릭 엔드포인트 포함)과 통신하기 위해 사용하는 구성 요소이며, 바로 이 NAT 게이트웨이를 경유하는 트래픽 때문에 데이터 전송 비용이 발생합니다. 또한, 엔드포인트 정책은 VPC 엔드포인트에 연결하는 것이지, NAT 게이트웨이에 연결하는 기능이 아닙니다. 기술적으로도 틀린 설명입니다.</li>
</ul>
<p><strong>C. 애플리케이션을 퍼블릭 서브넷에 배포하고 S3 버킷에 액세스하기 위해 인터넷 게이트웨이를 통해 라우팅하도록 허용합니다.</strong> </p>
<ul>
<li>애플리케이션을 퍼블릭 서브넷에 두면 인터넷 게이트웨이를 통해 S3에 직접 접근할 수 있습니다. 하지만 이 역시 <strong>공용 인터넷 경로</strong>를 사용하는 것이므로 데이터 전송 비용이 발생합니다. 비용 절감 효과가 없을 뿐만 아니라, 애플리케이션 서버를 외부 공격에 직접 노출시키는 퍼블릭 서브넷에 배치하는 것은 보안상 매우 취약한 아키텍처이므로 AWS 모범 사례에 어긋납니다.</li>
</ul>
<h1 id="73">73</h1>
<p>한 회사는 최근 프라이빗 서브넷의 Amazon EC2 에서 Linux 기반 애플리케이션 인스턴스를 시작하고 VPC 의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에서 Linux 기반 배스천 호스트를 시작했습니다. 솔루션 설계자는 사내 네트워크에서 회사의 인터넷 연결을 통해 배스천 호스트 및 애플리케이션 서버에 연결해야 합니다. 솔루션 설계자는 모든 EC2 인스턴스의 보안 그룹이 해당 액세스를 허용하는지 확인해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까?</p>
<p><strong>C. 배스천 호스트의 현재 보안 그룹을 회사의 외부 IP 범위에서만 인바운드 액세스를 허용하는 보안 그룹으로 교체합니다.</strong> </p>
<ul>
<li><strong>이유:</strong> 배스천 호스트는 외부 인터넷으로부터의 첫 번째 관문입니다. 솔루션 설계자는 '사내 네트워크'에서 '인터넷 연결을 통해' 배스천 호스트에 접속해야 합니다. 이때 출발지 IP 주소는 회사의 <strong>외부(공인) IP 주소</strong>가 됩니다.</li>
<li>보안을 위해, 불특정 다수의 접근을 막고 오직 회사의 공인 IP 대역에서 오는 SSH(포트 22) 트래픽만 허용하도록 배스천 호스트의 보안 그룹(Inbound 규칙)을 설정해야 합니다. 따라서 이 설명은 정확합니다.</li>
</ul>
<p><strong>D. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 개인 IP 주소에서만 인바운드 SSH 액세스를 허용하는 보안 그룹으로 교체합니다.</strong> </p>
<ul>
<li><strong>이유:</strong> 애플리케이션 인스턴스는 프라이빗 서브넷에 있어 외부에서 직접 접근할 수 없습니다. 유일한 SSH 접근 경로는 배스천 호스트를 통하는 것입니다.</li>
<li>배스천 호스트와 애플리케이션 인스턴스는 같은 VPC 내에 있으므로, 둘 사이의 통신은 <strong>개인(프라이빗) IP 주소</strong>를 통해 이루어집니다.</li>
<li>따라서 애플리케이션 인스턴스의 보안 그룹(Inbound 규칙)은 출발지(Source)를 <strong>배스천 호스트의 프라이빗 IP 주소</strong> 또는 <strong>배스천 호스트의 보안 그룹 ID</strong>로 지정하여 SSH 접근을 허용해야 합니다. 이 보기에서는 프라이빗 IP 주소를 명시했으므로 정확한 설명입니다.</li>
</ul>
<p><strong>A, B, E 가 적절하지않은이유</strong></p>
<p><strong>A. 배스천 호스트의 현재 보안 그룹을 애플리케이션 인스턴스의 인바운드 액세스만 허용하는 보안 그룹으로 교체합니다.</strong> </p>
<ul>
<li>접속 흐름의 방향이 완전히 반대입니다. 접속은 <code>외부 -&gt; 배스천 -&gt; 애플리케이션</code> 순서로 이루어집니다. 애플리케이션 인스턴스에서 배스천 호스트로 들어오는 인바운드 트래픽을 허용할 이유가 없습니다.</li>
<li>배스천 호스트의 보안 그룹을 애플리케이션 인스턴스 접근만 허용하도록 바꾼다</li>
</ul>
<p><strong>B. 배스천 호스트의 현재 보안 그룹을 회사의 내부 IP 범위에서만 인바운드 액세스를 허용하는 보안 그룹으로 교체합니다.</strong> </p>
<ul>
<li>'내부 IP 범위'(예: 192.168.x.x, 10.x.x.x)는 사설 네트워크에서만 유효합니다. 인터넷을 통해 AWS VPC의 배스천 호스트에 접속할 때, AWS가 보는 출발지 IP는 회사의 <strong>외부(공인) IP 주소</strong>이지, 내부 사설 IP 주소가 아닙니다. 따라서 이 규칙을 설정하면 회사에서 접속할 수 없습니다.</li>
<li>배스천 호스트의 보안 그룹을 회사의 내부 IP에서만 SSH 허용</li>
</ul>
<p><strong>E. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 공용 IP 주소에서만 인바운드 SSH 액세스를 허용하는 보안 그룹으로 교체합니다.</strong></p>
<ul>
<li><strong>VPC 내부의 인스턴스 간 통신은 항상 프라이빗 IP를 사용</strong>합니다. 배스천 호스트가 애플리케이션 인스턴스에 접속을 시도할 때, 출발지 IP는 배스천 호스트의 <strong>프라이빗 IP</strong>가 됩니다. 공용 IP는 VPC 외부와 통신할 때 인터넷 게이트웨이를 통해 변환되는 주소이므로 내부 통신에는 사용되지 않습니다. 따라서 이 규칙은 작동하지 않습니다.</li>
</ul>
<h1 id="74">74</h1>
<p>솔루션 설계자는 2 계층 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 퍼블릭 서브넷의 Amazon EC2에서 호스팅되는 퍼블릭 웹 티어로 구성됩니다. 데이터베이스 계층은 프라이빗 서브넷의 Amazon EC2에서 실행되는 Microsoft SQL Server로 구성됩니다. 보안은 회사의 최우선 과제입니다. 이 상황에서 보안 그룹을 어떻게 구성해야 합니까?</p>
<p><strong>A. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다.</strong> </p>
<ul>
<li><strong>웹 계층(Web Tier)</strong>은 퍼블릭 서브넷에 위치하며, 인터넷상의 불특정 다수 사용자에게 웹 서비스를 제공해야 합니다.</li>
<li><code>0.0.0.0/0</code>은 &quot;모든 IP 주소&quot;를 의미합니다. 즉, 전 세계 어디에서나 접속을 허용하겠다는 뜻입니다.</li>
<li><code>포트 443</code>은 <strong>HTTPS</strong> 통신을 위한 표준 포트입니다. 보안이 최우선 과제라고 했으므로, 암호화된 통신인 HTTPS를 사용하는 것이 당연합니다.</li>
<li>따라서 이 규칙은 <strong>&quot;인터넷상의 모든 사용자가 HTTPS(443)를 통해 웹 서버에 접속하는 것을 허용한다&quot;</strong>는 의미입니다. 이는 퍼블릭 웹 애플리케이션의 가장 기본적인 요구사항이므로 올바른 설정입니다.</li>
</ul>
<p><strong>C. 웹 계층에 대한 보안 그룹에서 포트 1433 의 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다.</strong> </p>
<ul>
<li><strong>데이터베이스 계층(Database Tier)</strong>은 프라이빗 서브넷에 위치하며, 오직 웹 계층의 EC2 인스턴스하고만 통신해야 합니다. 인터넷에서 직접 접근할 수 있으면 안 됩니다.</li>
<li><code>포트 1433</code>은 <strong>Microsoft SQL Server</strong>의 기본 포트입니다. 웹 애플리케이션이 데이터베이스에 쿼리를 보내려면 이 포트로 접근해야 합니다.</li>
<li>이 규칙의 핵심은 소스(Source)를 IP 주소(<code>0.0.0.0/0</code> 등)가 아닌 <strong>&quot;웹 계층의 보안 그룹&quot;</strong>으로 지정한 것입니다. 이는 AWS의 모범 사례이며 보안을 크게 향상시킵니다.<ul>
<li><strong>왜 더 안전한가?</strong> 웹 계층의 EC2 인스턴스 IP 주소가 바뀌더라도(예: Auto Scaling으로 인스턴스가 추가/삭제될 때) 보안 그룹 규칙을 수정할 필요가 없습니다. 또한, 오직 웹 계층 보안 그룹에 속한 인스턴스만 데이터베이스에 접근할 수 있도록 논리적으로 완벽하게 격리할 수 있습니다.</li>
</ul>
</li>
<li>결론적으로 이 규칙은 <strong>&quot;오직 웹 계층의 EC2 인스턴스들만 MS SQL Server(1433)에 접속하는 것을 허용한다&quot;</strong>는 의미이며, 이는 최소 권한 원칙(Principle of Least Privilege)을 완벽하게 준수하는 설정입니다.</li>
</ul>
<p><strong>B, D, E가 부적절한 이유</strong></p>
<p><strong>B. 0.0.0.0/0 에서 포트 443 의 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다.</strong> </p>
<ul>
<li><strong>보안 그룹은 상태 저장(Stateful) 방화벽입니다.</strong> 이는 인바운드 규칙에 의해 허용된 트래픽에 대한 <strong>응답 트래픽(Return Traffic)은 아웃바운드 규칙과 상관없이 자동으로 허용된다</strong>는 의미입니다.</li>
<li>A에서 사용자가 웹 서버로 들어오는 인바운드 443 트래픽을 허용했으므로, 웹 서버가 사용자에게 다시 응답하는 아웃바운드 트래픽은 별도의 규칙 없이 자동으로 허용됩니다. 따라서 이 규칙은 불필요합니다.</li>
<li>기본적으로 보안 그룹의 아웃바운드 규칙은 모든 트래픽(<code>0.0.0.0/0</code> on all ports)을 허용하도록 설정되어 있으므로, 특별한 이유가 없다면 굳이 이 규칙을 추가할 필요가 없습니다.</li>
</ul>
<p><strong>D. 데이터베이스 계층의 보안 그룹을 구성하여 포트 443 및 1433 의 아웃바운드 트래픽을 웹 계층의 보안 그룹으로 보냅니다.</strong> </p>
<ul>
<li><strong>상태 저장(Stateful) 특성:</strong> 위와 같은 이유로, 웹 계층에서 데이터베이스로 요청(Inbound to DB on 1433)을 보내면, 데이터베이스가 웹 계층으로 보내는 응답(Outbound from DB)은 아웃바운드 규칙 없이 자동으로 허용됩니다.</li>
<li><strong>잘못된 통신 방향 및 포트:</strong> 데이터베이스 서버는 웹 서버의 요청에 응답할 뿐, 먼저 웹 서버의 443 포트(HTTPS)나 1433 포트로 연결을 시작할 이유가 전혀 없습니다. 통신 흐름에 대한 이해가 잘못된 규칙입니다.</li>
</ul>
<p><strong>E. 웹 계층에 대한 보안 그룹의 포트 443 및 1433 에서 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다.</strong></p>
<ul>
<li><strong>최소 권한 원칙 위반:</strong> 데이터베이스 서버(MS SQL Server)는 데이터베이스 연결을 위해 1433 포트만 사용합니다. 웹 서버와 HTTPS 통신(443)을 할 이유가 없습니다.</li>
<li>불필요한 포트(<code>443</code>)를 열어두는 것은 잠재적인 공격 경로를 만들어주는 것이므로 보안상 좋지 않습니다. 항상 필요한 최소한의 포트만 열어야 합니다. 이 규칙은 <strong>&quot;최소 권한의 원칙”</strong>을 위배합니다.</li>
</ul>
<h1 id="75">75</h1>
<p>한 회사에서 애플리케이션의 성능을 개선하기 위해 다계층 애플리케이션을 온프레미스에서 AWS 클라우드로 이동하려고 합니다. 애플리케이션은 RESTful 서비스를 통해 서로 통신하는 애플리케이션 계층으로 구성됩니다. 한 계층이 오버로드되면 트랜잭션이 삭제됩니다. 솔루션 설계자는 이러한 문제를 해결하고 애플리케이션을 현대화하는 솔루션을 설계해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? </p>
<p><strong>A. Amazon API Gateway 를 사용하고 애플리케이션 계층으로 AWS Lambda 함수에 트랜잭션을 전달합니다. Amazon Simple Queue Service(Amazon SQS)를 애플리케이션 서비스 간의 통신 계층으로 사용합니다.</strong> </p>
<ul>
<li><strong>트랜잭션 삭제 문제 해결 (디커플링)</strong><ul>
<li><strong>Amazon SQS</strong>: 애플리케이션 계층 사이에 SQS 대기열(Queue)을 두면, 앞 계층(Producer)과 뒷 계층(Consumer)이 분리(Decouple)됩니다.</li>
<li>만약 뒷 계층의 서비스가 과부하 상태가 되어 메시지를 즉시 처리할 수 없더라도, 메시지는 삭제되지 않고 SQS 대기열에 안전하게 보관됩니다. 뒷 계층의 서비스는 자신의 처리 능력에 맞춰 대기열에서 메시지를 순차적으로 가져와 처리할 수 있습니다. 이는 <strong>&quot;트랜잭션 삭제&quot;</strong>라는 핵심 문제를 완벽하게 해결합니다.</li>
</ul>
</li>
<li><strong>애플리케이션 현대화 (서버리스 아키텍처)</strong><ul>
<li><strong>API Gateway + AWS Lambda</strong>: 이 조합은 대표적인 서버리스(Serverless) 아키텍처입니다.<ul>
<li><strong>API Gateway</strong>: RESTful API의 엔드포인트 역할을 하며, 트래픽 관리, 인증, 모니터링 등을 처리하는 완전 관리형 서비스입니다.</li>
<li><strong>AWS Lambda</strong>: EC2 인스턴스와 같은 서버를 프로비저닝하거나 관리할 필요 없이 코드를 실행할 수 있습니다. 요청이 있을 때만 코드가 실행되고 사용한 만큼만 비용을 지불합니다.</li>
</ul>
</li>
<li>서버리스 아셔츠로 전환함으로써 애플리케이션을 매우 현대적인 구조로 개선할 수 있습니다.</li>
</ul>
</li>
<li><strong>운영 효율성 극대화</strong><ul>
<li>API Gateway, Lambda, SQS는 모두 <strong>완전 관리형(Fully Managed) 서비스</strong>입니다. 따라서 서버 OS 패치, 소프트웨어 설치, 인프라 확장/축소 등에 대한 운영 부담이 거의 없습니다.</li>
<li>트래픽에 따라 자동으로 확장/축소되므로, 개발자는 비즈니스 로직에만 집중할 수 있어 운영 효율성이 극대화됩니다.</li>
</ul>
</li>
</ul>
<p><strong>B, C, D가 적절하지 않은이유</strong></p>
<p><strong>B. Amazon CloudWatch 지표를 사용하여 애플리케이션 성능 기록을 분석하여 성능 장애 동안 서버의 최대 사용률을 결정합니다. 최대 요구 사항을 충족하도록 애플리케이션 서버의 Amazon EC2 인스턴스 크기를 늘립니다.</strong> </p>
<ul>
<li><strong>근본적인 문제 미해결</strong>: 이것은 <strong>수직 확장(Vertical Scaling)</strong> 방식입니다. 단순히 EC2 인스턴스의 사양을 높이는 것은 예측하지 못한 트래픽 급증(Spike)에 대응하기 어렵습니다. 인스턴스가 아무리 커도 그 처리 용량을 넘어서는 요청이 들어오면 여전히 트랜잭션은 삭제될 수 있습니다.</li>
<li><strong>비효율적인 비용</strong>: 트래픽이 적을 때도 항상 최대 사양의 인스턴스 비용을 지불해야 하므로 비용 효율성이 떨어집니다.</li>
<li><strong>현대화와 거리감</strong>: 기존의 방식을 그대로 유지하는 것으로, 클라우드의 장점인 탄력성을 제대로 활용하지 못하며 현대화 요구사항을 충족시키지 못합니다.</li>
</ul>
<p><strong>C. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Auto Scaling 그룹의 Amazon EC2 에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch 를 사용하여 SNS 대기열 길이를 모니터링하고 필요에 따라 확장 및 축소합니다.</strong> </p>
<p><strong>D. Amazon Simple Queue Service(Amazon SQS)를 사용하여 Auto Scaling 그룹의 Amazon EC2 에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch 를 사용하여 SQS 대기열 길이를 모니터링하고 통신 오류가 감지되면 확장합니다.</strong></p>
<ul>
<li><strong>좋은 해결책이지만 최선은 아님</strong>: 이 아키텍처는 SQS를 사용하여 트랜잭션 삭제 문제를 해결하고, Auto Scaling을 통해 탄력성을 확보하므로 B나 C보다 훨씬 나은 해결책입니다. 실제로 많은 시스템이 이런 구조를 사용합니다.</li>
<li><strong>운영 효율성 및 현대화 부족</strong>: 하지만 A와 비교했을 때, 이 솔루션은 여전히 <strong>EC2 인스턴스를 기반</strong>으로 합니다. 이는 운영체제 관리, 보안 패치, AMI(Amazon Machine Image) 관리 등 서버 관리에 대한 운영 부담이 남아있음을 의미합니다.</li>
<li><strong>A와의 비교</strong>: A의 Lambda 기반 서버리스 아키텍처는 이러한 서버 관리 부담이 전혀 없으므로, <strong>&quot;운영상 가장 효율적</strong>&quot;이고 <strong>&quot;애플리케이션을 현대화&quot;</strong>하는 요구사항을 D보다 더 잘 충족시킵니다.</li>
</ul>
<h1 id="76">76</h1>
<p>회사는 단일 공장에 있는 여러 기계에서 매일 10TB의 계측 데이터를 수신합니다. 데이터는 공장 내에 위치한 온프레미스 데이터 센터의 SAN(Storage Area Network)에 저장된 JSON 파일로 구성됩니다. 회사는 이 데이터를 Amazon S3 로 전송하여 중요한 실시간에 가까운 분석을 제공하는 여러 추가 시스템에서 액세스할 수 있기를 원합니다. 데이터가 민감한 것으로 간주되기 때문에 안전한 전송이 중요합니다. 가장 안정적인 데이터 전송을 제공하는 솔루션은 무엇입니까?</p>
<p><strong>B. AWS Direct Connect 를 통한 AWS DataSync</strong> </p>
<ul>
<li>문제의 핵심 요구사항 분석<ol>
<li><strong>데이터 소스:</strong> 온프레미스 SAN에 저장된 <strong>JSON 파일</strong></li>
<li><strong>데이터 양:</strong> 매일 <strong>10TB</strong> (대용량)</li>
<li><strong>데이터 대상:</strong> <strong>Amazon S3</strong></li>
<li><strong>목적:</strong> 실시간에 가까운 분석</li>
<li><strong>중요 제약 조건:</strong><ul>
<li><strong>안전한 전송</strong> (민감한 데이터)</li>
<li><strong>가장 안정적인</strong> 데이터 전송</li>
</ul>
</li>
</ol>
</li>
<li><strong>올바른 서비스 선택: AWS DataSync</strong><ul>
<li><strong>파일 기반 데이터 전송에 최적화:</strong> <code>AWS DataSync</code>는 온프레미스 스토리지(NFS, SMB, HDFS, SAN/NAS 등)와 AWS 스토리지 서비스(Amazon S3, EFS, FSx) 간의 <strong>파일 및 객체 데이터 전송을 가속화하고 자동화하도록 특별히 설계된 서비스</strong>입니다. 문제에서 주어진 데이터는 'JSON 파일'이므로, 파일 기반 전송에 최적화된 DataSync가 가장 적합한 도구입니다.</li>
<li><strong>대용량 데이터에 효율적:</strong> DataSync는 병렬 전송, 데이터 압축 등 내장된 최적화 기술을 통해 대용량 데이터(매일 10TB)를 빠르고 효율적으로 전송할 수 있습니다.</li>
<li><strong>자동화 및 안정성 기능:</strong> 전송 스케줄링, 데이터 무결성 검증, 자동 재시도 등의 기능을 제공하여 안정적인 데이터 파이프라인 구축을 지원합니다.</li>
</ul>
</li>
<li><strong>가장 안정적이고 안전한 네트워크 연결: AWS Direct Connect</strong><ul>
<li><strong>최고 수준의 안정성:</strong> <code>AWS Direct Connect(DX)</code>는 온프레미스 데이터 센터와 AWS 간에 <strong>전용 사설 네트워크 연결</strong>을 설정하는 서비스입니다. 공용 인터넷을 경유하지 않으므로 네트워크 혼잡이나 성능 변동의 영향을 받지 않습니다. 이는 &quot;가장 안정적인&quot; 전송이라는 요구사항을 완벽하게 만족시킵니다.</li>
<li><strong>강화된 보안:</strong> 데이터가 공용 인터넷을 통과하지 않고 사설 회선을 통해 전송되므로, 민감한 데이터를 다루는 데 있어 매우 안전한 방법입니다. 여기에 DataSync 자체의 전송 중 암호화(TLS)가 더해져 보안성이 극대화됩니다.</li>
</ul>
</li>
</ul>
<h1 id="77">77</h1>
<p>회사는 애플리케이션에 대한 실시간 데이터 수집 아키텍처를 구성해야 합니다. 회사에는 데이터가 스트리밍될 때 데이터를 변환하는 프로세스인 API 와 데이터를 위한 스토리지 솔루션이 필요합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>C. Amazon Kinesis 데이터 스트림으로 데이터를 보내도록 Amazon API Gateway API 를 구성합니다. Kinesis 데이터 스트림을 데이터 원본으로 사용하는 Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. Kinesis Data Firehose 전송 스트림을 사용하여 데이터를 Amazon S3로 보냅니다.</strong> </p>
<ul>
<li><strong>API (Amazon API Gateway):</strong> 서버를 직접 프로비저닝하거나 관리할 필요가 없는 완전 관리형 서비스입니다. AWS가 트래픽에 따라 자동으로 확장 및 축소하며, 사용자는 API 엔드포인트와 로직에만 집중하면 됩니다. EC2를 사용하는 것에 비해 운영 부담이 거의 없습니다.</li>
<li><strong>데이터 수집 (Amazon Kinesis Data Streams):</strong> 실시간 스트리밍 데이터를 안정적으로 수집하고 버퍼링하는 완전 관리형 서비스입니다. 데이터 생산자(API Gateway)와 소비자(Firehose)를 분리(decoupling)하여 시스템의 안정성과 확장성을 높입니다.</li>
<li><strong>데이터 변환 및 전송 (Amazon Kinesis Data Firehose + AWS Lambda):</strong><ul>
<li><strong>Kinesis Data Firehose:</strong> 스트리밍 데이터를 S3, Redshift, Elasticsearch 등 다른 AWS 서비스로 안정적으로 전송하는 완전 관리형 서비스입니다. 데이터를 버퍼링하고, 일괄 처리(batching)하며, 압축 및 암호화까지 자동으로 처리해주어 운영 오버헤드가 매우 적습니다.</li>
<li><strong>AWS Lambda:</strong> Firehose가 데이터를 전송하는 중간에 Lambda 함수를 트리거하여 실시간으로 데이터를 변환할 수 있습니다. Lambda 역시 서버리스 컴퓨팅 서비스로, 코드를 실행하는 동안에만 비용이 발생하며 서버 관리가 전혀 필요 없습니다.</li>
</ul>
</li>
<li><strong>스토리지 (Amazon S3):</strong> 내구성이 매우 높고 확장성이 뛰어난 객체 스토리지 서비스입니다. 용량 계획이나 인프라 관리가 필요 없어 운영 오버헤드가 거의 없습니다.</li>
</ul>
<p><strong>A. Amazon EC2 인스턴스를 배포하여 Amazon Kinesis 데이터 스트림으로 데이터를 전송하는 API를 호스팅합니다. Kinesis 데이터 스트림을 데이터 원본으로 사용하는 Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. Kinesis Data Firehose 전송 스트림을 사용하여 데이터를 Amazon S3 로 보냅니다.</strong> </p>
<ul>
<li><strong>&quot;Amazon EC2 인스턴스를 배포하여... API를 호스팅합니다.&quot;</strong><ul>
<li>이 부분이 가장 큰 문제입니다. EC2 인스턴스를 사용하면 운영체제(OS) 설치, 보안 패치, 소프트웨어 업데이트, 오토 스케일링 그룹 구성, 로드 밸런서 설정 등 <strong>상당한 운영 오버헤드가 발생</strong>합니다. 이는 '최소한의 운영 오버헤드'라는 핵심 요구사항에 정면으로 위배됩니다. 서버리스인 API Gateway를 사용하는 것이 훨씬 효율적입니다.</li>
</ul>
</li>
</ul>
<p><strong>B. Amazon EC2 인스턴스를 배포하여 AWS Glue에 데이터를 전송하는 API를 호스팅합니다. EC2 인스턴스에서 소스/대상 확인을 중지합니다. AWS Glue를 사용하여 데이터를 변환하고 데이터를 Amazon S3로 보냅니다.</strong> </p>
<p><strong>D. 데이터를 AWS Glue로 보내도록 Amazon API Gateway API를 구성합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. AWS Glue 를 사용하여 데이터를 Amazon S3 로 보냅니다.</strong></p>
<ul>
<li><strong>&quot;AWS Glue에 데이터를 전송하는 API&quot;</strong><ul>
<li>AWS Glue는 주로 <strong>배치(Batch)성 ETL(Extract, Transform, Load) 작업</strong>을 위한 서비스입니다. 실시간으로 들어오는 개별 레코드들을 처리하기 위한 서비스가 아닙니다. API를 통해 들어오는 실시간 스트리밍 데이터를 처리하는 데는 Kinesis가 훨씬 적합합니다. 아키텍처의 목적과 서비스의 용도가 맞지 않습니다.</li>
</ul>
</li>
</ul>
<h1 id="78">78</h1>
<p>회사는 사용자 트랜잭션 데이터를 Amazon DynamoDB 테이블에 보관해야 합니다. 회사는 데이터를 7년간 보관해야 합니다. 이러한 요구 사항을 충족하는 가장 운영 효율성이 높은 솔루션은 무엇입니까?</p>
<p><strong>B. AWS Backup 을 사용하여 테이블에 대한 백업 일정 및 보존 정책을 생성합니다.</strong> </p>
<p><strong>AWS Backup</strong>은 AWS 서비스 전반의 데이터 보호를 중앙에서 관리하고 자동화하기 위해 특별히 설계된 <strong>완전 관리형 서비스</strong>입니다. 이것이 '가장 운영 효율적'이라는 평가를 받는 핵심 이유입니다.</p>
<ul>
<li><strong>중앙 집중식 관리</strong>: AWS Backup을 사용하면 DynamoDB뿐만 아니라 RDS, EBS, EFS 등 다른 AWS 서비스의 백업도 단일 콘솔에서 관리할 수 있습니다. 이는 관리의 복잡성을 크게 줄여줍니다.</li>
<li><strong>자동화된 백업 수명 주기 관리</strong>:<ul>
<li><em>백업 계획(Backup Plan)*</em>을 생성하여 백업 빈도(예: 매일), 백업 시간대, 그리고 가장 중요한 <strong>보존 기간(Retention period)</strong>을 설정할 수 있습니다. 문제의 요구사항인 '7년 보관'은 보존 정책에 <code>7년</code>으로 설정하기만 하면 자동으로 해결됩니다.</li>
<li>백업 데이터를 비용 효율적인 콜드 스토리지(Amazon S3 Glacier 또는 Glacier Deep Archive)로 자동으로 이동시키는 <strong>수명 주기 규칙</strong>을 설정할 수 있습니다. 7년 동안 보관되는 데이터는 대부분 접근 빈도가 낮으므로, 콜드 스토리지로 이동시켜 비용을 크게 절감할 수 있습니다.</li>
</ul>
</li>
<li><strong>간편한 설정 및 유지보수 불필요</strong>: 몇 번의 클릭만으로 백업 정책을 설정하고 리소스(DynamoDB 테이블)에 적용하면 그 이후로는 어떠한 수동 개입이나 코드 관리도 필요 없습니다. 이것이 바로 <strong>운영 효율성</strong>의 극대화입니다.</li>
<li><strong>규정 준수 및 감사</strong>: AWS Backup은 백업 활동에 대한 모니터링 및 보고 기능을 제공하여 규정 준수 요구사항을 충족하는 데 도움을 줍니다.</li>
</ul>
<p><strong>A. DynamoDB 지정 시간 복구를 사용하여 테이블을 지속적으로 백업합니다.</strong> </p>
<ul>
<li>PITR(Point-in-Time Recovery)은 테이블을 <strong>최대 35일</strong>까지의 특정 시점으로 복구할 수 있게 해주는 기능입니다. 7년이라는 장기 보관 요구사항을 전혀 충족시키지 못합니다.</li>
</ul>
<p><strong>C. DynamoDB 콘솔을 사용하여 테이블의 주문형 백업을 생성합니다. 백업을 Amazon S3 버킷에 저장합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다.</strong> </p>
<ul>
<li>&quot;주문형 백업(On-demand backup)&quot;은 <strong>수동으로 직접 실행</strong>해야 하는 백업입니다. 매번 백업이 필요할 때마다 관리자가 직접 콘솔에 접속하거나 CLI 명령을 실행해야 합니다.</li>
</ul>
<p><strong>D. AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. 테이블을 백업하고 Amazon S3 버킷에 백업을 저장하도록 Lambda 함수를 구성합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다.</strong></p>
<ul>
<li>AWS Backup이라는 완전 관리형 서비스가 동일한 기능을 더 간단하고 안정적으로 제공하므로, 굳이 복잡하게 직접 솔루션을 구축할 이유가 없습니다.</li>
</ul>
<h1 id="79">79</h1>
<p>회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 최적화에 대해 우려하고 있습니다. 대부분의 아침에는 테이블을 사용하지 않습니다. 저녁에는 읽기 및 쓰기 트래픽이 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다. 솔루션 아키텍트는 무엇을 추천해야 합니까? </p>
<p><strong>A. 온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다.</strong> </p>
<ul>
<li><strong>비용 효율성</strong>: 온디맨드 모드는 '사용한 만큼 지불(Pay-per-request)'하는 방식입니다. 테이블에 대한 읽기/쓰기 요청이 발생할 때만 비용을 지불합니다. 따라서 트래픽이 거의 없는 아침 시간에는 비용이 거의 발생하지 않아 비용을 최적화할 수 있습니다.</li>
<li><strong>즉각적인 확장성</strong>: 트래픽이 예측할 수 없이 급증할 때, 온디맨드 모드는 별도의 설정이나 지연 시간 없이 DynamoDB가 자동으로 용량을 조절하여 모든 요청을 처리합니다. 프로비저닝된 용량을 미리 계산하거나 Auto Scaling이 반응하기를 기다릴 필요가 없습니다. 이는 &quot;트래픽 급증이 발생하면 매우 빠르게 발생합니다&quot;라는 요구사항에 가장 적합한 특징입니다.</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. 글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다.</strong> </p>
<ul>
<li>글로벌 보조 인덱스(GSI)는 기본 테이블과 다른 파티션 키 및 정렬 키를 사용하여 <strong>데이터를 다른 방식으로 유연하게 쿼리(조회)</strong>하기 위한 기능입니다. 이는 용량 관리나 비용 최적화와는 직접적인 관련이 없습니다.</li>
</ul>
<p><strong>C. 프로비저닝된 용량 및 Auto Scaling을 사용하여 DynamoDB 테이블을 생성합니다.</strong> </p>
<p><strong>D. 프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 전역 테이블로 구성합니다.</strong></p>
<ul>
<li>사용량 예측이 안 되므로 프로비저닝은 무의미</li>
</ul>
<h1 id="80">80</h1>
<p>한 회사는 최근 애플리케이션 마이그레이션 이니셔티브에 대한 지원을 위해 AWS 관리형 서비스 공급자(MSP) 파트너와 계약을 체결했습니다. 솔루션 설계자는 기존 AWS 계정의 Amazon 머신 이미지(AMI)를 MSP 파트너의 AWS 계정과 공유해야 합니다. AMI는 Amazon Elastic Block Store(Amazon EBS)의 지원을 받으며 AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하여 EBS 볼륨 스냅샷을 암호화합니다. 솔루션 설계자가 MSP 파트너의 AWS 계정과 AMI 를 공유하는 가장 안전한 방법은 무엇입니까? </p>
<p>AMI, 특히 암호화된 EBS 스냅샷을 사용하는 AMI를 안전하게 공유하는 방법</p>
<p><strong>B. AMI 의 launchPermission 속성을 수정합니다. MSP 파트너의 AWS 계정과만 AMI 를 공유하십시오. MSP 파트너의 AWS 계정이 키를 사용할 수 있도록 키 정책을 수정합니다.</strong> </p>
<ul>
<li><strong>AMI 공유 (<code>launchPermission</code> 수정):</strong><ul>
<li><code>launchPermission</code>은 프라이빗 AMI를 특정 AWS 계정과 공유하기 위한 AWS의 공식적인 기능입니다. 이 속성을 수정하여 MSP 파트너의 AWS 계정 ID를 명시적으로 추가하면, 오직 해당 계정만이 이 AMI를 보고 인스턴스를 시작할 수 있는 권한을 갖게 됩니다.</li>
<li>이는 '최소 권한의 원칙(Principle of Least Privilege)'을 준수하는 방법입니다. 불필요하게 외부에 노출하지 않고, 꼭 필요한 대상에게만 접근을 허용하므로 보안성이 매우 높습니다.</li>
</ul>
</li>
<li><strong>암호화 키 공유 (KMS 키 정책 수정):</strong><ul>
<li>AMI가 암호화된 EBS 스냅샷을 사용하고 있으므로, AMI를 실행할 권한(<code>launchPermission</code>)만으로는 인스턴스를 시작할 수 없습니다. 인스턴스가 시작될 때 EBS 볼륨을 생성하려면 암호화된 스냅샷을 복호화해야 하기 때문입니다.</li>
<li>이 복호화 권한은 스냅샷을 암호화한 AWS KMS의 고객 관리형 키(CMK)가 부여해야 합니다. 키 소유자의 계정에서 <strong>키 정책(Key Policy)</strong>을 수정하여 MSP 파트너의 AWS 계정이 해당 키를 사용할 수 있도록 <code>kms:Decrypt</code>, <code>kms:ReEncrypt*</code>, <code>kms:GenerateDataKey*</code>, <code>kms:DescribeKey</code>와 같은 권한을 부여해야 합니다. (실제로는 <code>kms:CreateGrant</code>를 통해 필요한 권한을 위임하는 것이 더 안전하고 일반적입니다.)</li>
<li>결론적으로 <strong>AMI 접근 권한</strong>과 <strong>암호화 키 사용 권한</strong>을 모두 부여해야만 파트너 계정에서 암호화된 AMI로 인스턴스를 성공적으로 시작할 수 있으며, B는 이 두 가지 필수 요건을 가장 정확하고 안전하게 충족하는 방법입니다.</li>
</ul>
</li>
</ul>
<p><strong>A. 암호화된 AMI 및 스냅샷을 공개적으로 사용할 수 있도록 합니다. MSP 파트너의 AWS 계정이 키를 사용할 수 있도록 키 정책을 수정합니다.</strong> </p>
<ul>
<li>&quot;공개적으로 사용(publicly available)&quot;이라는 부분이 결정적인 문제입니다. 이는 AMI를 전 세계 모든 AWS 사용자에게 노출하는 것을 의미하며, 보안 요구사항에 정면으로 위배됩니다. 특정 파트너와 안전하게 공유해야 하는 상황에서 리소스를 공개하는 것은 절대 피해야 할 방식입니다.</li>
</ul>
<p><strong>C. AMI 의 launchPermission 속성을 수정합니다. MSP 파트너의 AWS 계정과만 AMI 를 공유하십시오. 암호화를 위해 MSP 파트너가 소유한 새 KMS 키를 신뢰하도록 키 정책을 수정합니다.</strong> </p>
<ul>
<li>원본 KMS 키의 키 정책은 다른 AWS 계정(Principal)에 권한을 부여하는 것이지, 다른 KMS 키를 '신뢰'하도록 설정하는 개념이 아닙니다.</li>
<li>만약 MSP 파트너가 소유한 키로 암호화하려면, MSP 파트너는 먼저 공유받은 AMI를 자신의 계정으로 <strong>복사</strong>해야 합니다. 복사 과정에서 새로운 KMS 키(자신이 소유한)를 지정하여 재암호화할 수 있습니다. 하지만 이 작업을 하려면, 우선 원본 스냅샷을 복호화할 수 있어야 하므로 결국 원본 키에 대한 사용 권한이 먼저 필요합니다.</li>
<li>따라서 이 보기는 단순히 AMI를 공유하여 인스턴스를 시작하는 가장 직접적인 방법이 아니며, 절차에 대한 설명도 부정확합니다. B가 훨씬 더 간단하고 직접적인 해결책입니다.</li>
</ul>
<p><strong>D. 원본 계정에서 MSP 파트너의 AWS 계정에 있는 Amazon S3 버킷으로 AMI 를 내보내고 MSP 파트너가 소유한 새 KMS 키로 S3 버킷을 암호화합니다. MSP 파트너의 AWS 계정에서 AMI를 복사하고 시작합니다.</strong></p>
<ul>
<li>EBS 기반 AMI를 S3로 '내보내는(export)' 기능은 주로 온프레미스 환경과의 VM 이미지 교환(VM Import/Export)을 위한 것이지, AWS 계정 간에 AMI를 공유하는 일반적인 방법이 아닙니다.</li>
<li>AWS 계정 간 AMI 공유는 <code>launchPermission</code>이라는 훨씬 간단하고 효율적인 네이티브 기능이 존재합니다. S3를 경유하는 것은 시간과 비용이 더 들고, S3 버킷 정책, 객체 접근 권한 등 추가적인 보안 설정을 관리해야 하므로 복잡성만 증가시킵니다.</li>
</ul>
<h1 id="81">81</h1>
<p>솔루션 설계자는 AWS 에 배포되는 새 애플리케이션을 위한 클라우드 아키텍처를 설계하고 있습니다. 처리할 작업 수에 따라 필요에 따라 애플리케이션 노드를 추가 및 제거하면서 프로세스가 병렬로 실행되어야 합니다. 프로세서 응용 프로그램은 상태 비저장입니다. 솔루션 설계자는 응용 프로그램이 느슨하게 연결되어 있고 작업 항목이 영구적으로 저장되어 있는지 확인해야 합니다. 솔루션 설계자는 어떤 디자인을 사용해야 합니까? </p>
<p><strong>C. 처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 템플릿을 생성합니다. 시작 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SQS 대기열의 항목 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다.</strong> </p>
<ul>
<li><strong>느슨한 결합 및 영구 저장 (Amazon SQS):</strong><ul>
<li><code>Amazon SQS(Simple Queue Service)</code>는 메시지(작업)를 임시로 저장하는 <strong>대기열 서비스</strong>입니다.</li>
</ul>
</li>
<li><strong>병렬 처리 및 확장성 (Auto Scaling Group):</strong><ul>
<li><code>Auto Scaling Group</code>은 EC2 인스턴스의 수를 자동으로 조절하여 애플리케이션의 가용성을 유지합니다.</li>
<li>여러 개의 EC2 인스턴스가 SQS 대기열에서 동시에 작업을 가져와 <strong>병렬로 처리</strong>할 수 있습니다.</li>
</ul>
</li>
<li><strong>가장 효율적인 조정 정책 (SQS 대기열의 항목 수):</strong><ul>
<li>이 아키텍처의 핵심입니다. Auto Scaling의 확장/축소 기준을 <strong>&quot;SQS 대기열에 쌓여있는 작업(메시지)의 수&quot;</strong>로 설정했습니다.</li>
<li><strong>확장(Scale-out):</strong> 대기열에 처리할 작업이 많이 쌓이면(예: <code>ApproximateNumberOfMessagesVisible</code> &gt; 100), 현재 처리 용량이 부족하다는 의미이므로 Auto Scaling Group이 새 EC2 인스턴스를 추가합니다.</li>
<li><strong>축소(Scale-in):</strong> 대기열의 작업이 거의 없으면(예: <code>ApproximateNumberOfMessagesVisible</code> &lt; 10), 현재 인스턴스가 너무 많아 비용이 낭비되고 있다는 의미이므로 Auto Scaling Group이 불필요한 인스턴스를 제거합니다.</li>
<li>이 방식은 &quot;처리할 작업 수에 따라&quot; 노드를 조절해야 한다는 요구사항에 가장 직접적이고 효율적인 방법입니다.</li>
</ul>
</li>
<li><strong>최신 모범 사례 (시작 템플릿):</strong><ul>
<li><code>시작 템플릿(Launch Template)</code>은 Auto Scaling Group이 새 EC2 인스턴스를 시작할 때 필요한 모든 구성(AMI ID, 인스턴스 유형, 키 페어, 보안 그룹 등)을 담고 있습니다.</li>
<li>과거에는 <code>시작 구성(Launch Configuration)</code>을 사용했지만, AWS는 버전 관리, 다양한 옵션 지원 등의 이점을 가진 <strong>시작 템플릿 사용을 권장</strong>합니다. 최신 모범 사례를 따르는 것이 정답일 확률이 높습니다.</li>
</ul>
</li>
</ul>
<p><strong>A. 처리해야 하는 작업을 보낼 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 구성을 생성합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. CPU 사용량에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다.</strong> </p>
<p><strong>D. 처리해야 하는 작업을 보낼 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 템플릿을 생성합니다. 시작 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SNS 주제에 게시된 메시지 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다.</strong></p>
<ul>
<li><strong>Amazon SNS 사용:</strong> <code>SNS(Simple Notification Service)</code>는 <strong>게시/구독(Pub/Sub) 모델</strong>의 메시징 서비스입니다. 하나의 메시지를 게시하면 해당 토픽을 구독하는 <strong>모든 대상에게 메시지를 푸시(Push) 방식으로 전달</strong>합니다. 작업 항목을 여러 작업자 중 하나가 가져가서 처리해야 하는 '작업 대기열' 패턴에는 적합하지 않습니다. 메시지가 영구적으로 보관되어 순차적으로 처리되는 것을 보장하지도 않습니다.</li>
</ul>
<p><strong>B.처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 구성을 생성합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. Auto Scaling 그룹의 조정 정책을 설정하여 네트워크 사용량에 따라 노드를 추가 및 제거합니다.</strong> </p>
<ul>
<li><strong>네트워크 사용량 기반 조정:</strong> 네트워크 사용량은 처리할 작업의 수와 직접적인 관련이 거의 없습니다.</li>
</ul>
<h1 id="82">82</h1>
<p>회사는 AWS 클라우드에서 웹 애플리케이션을 호스팅합니다. 회사는 AWS Certificate Manager(ACM)로 가져온 인증서를 사용하도록 Elastic Load Balancer 를 구성합니다. 각 인증서가 만료되기 30일 전에 회사 보안팀에 알려야 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 권장해야 합니까? </p>
<p><strong>B. 30 일 이내에 만료되는 인증서를 확인하는 AWS Config 규칙을 생성합니다. AWS Config 가 비준수 리소스를 보고할 때 Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 호출하도록 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다.</strong> </p>
<ul>
<li><strong>리소스 구성 감사 및 평가 (AWS Config):</strong><ul>
<li><strong>AWS Config</strong>는 AWS 리소스의 구성을 평가, 감사 및 검사하는 서비스입니다. &quot;우리 회사의 보안 정책에 따라 모든 리소스가 올바르게 설정되었는가?&quot;를 확인하는 데 특화되어 있습니다.</li>
<li>AWS Config에는 <strong>관리형 규칙(Managed Rule)</strong>인 <code>acm-certificate-expiration-check</code>가 내장되어 있습니다. 이 규칙을 활성화하고 파라미터로 <code>30</code>일을 설정하면, 30일 이내에 만료되는 모든 ACM 인증서를 자동으로 <strong>&quot;비준수(Non-compliant)&quot;</strong> 리소스로 탐지합니다.</li>
</ul>
</li>
<li><strong>상태 변경 감지 및 알림 (Amazon EventBridge + SNS):</strong><ul>
<li>AWS Config가 특정 리소스(여기서는 인증서)의 상태를 &quot;준수&quot;에서 &quot;비준수&quot;로 변경하면, 이 상태 변경 자체가 <strong>이벤트(Event)</strong>가 되어 <strong>Amazon EventBridge</strong>로 전송됩니다.</li>
<li>EventBridge에서는 &quot;AWS Config로부터 들어온 비준수 보고 이벤트&quot;를 감지하는 규칙을 생성할 수 있습니다.</li>
<li>이 규칙의 대상으로 <strong>Amazon SNS(Simple Notification Service)</strong> 주제(Topic)를 지정하면, 이벤트가 발생할 때마다 SNS가 보안팀의 이메일 주소나 다른 구독 엔드포인트로 알림을 자동으로 발송합니다.</li>
</ul>
</li>
</ul>
<p><strong>A. ACM 에 규칙을 추가하여 인증서가 만료되기 30 일 전부터 매일 Amazon Simple Notification Service(Amazon SNS) 주제에 사용자 지정 메시지를 게시합니다.</strong> </p>
<ul>
<li><strong>존재하지 않는 기능:</strong> AWS Certificate Manager(ACM) 서비스 자체에는 사용자가 직접 알림 규칙을 생성하고 SNS로 메시지를 게시하는 기능이 없습니다.</li>
</ul>
<p><strong>C. AWS Trusted Advisor 를 사용하여 30 일 이내에 만료되는 인증서를 확인합니다. 상태 변경 확인에 대한 Trusted Advisor 지표를 기반으로 하는 Amazon CloudWatch 경보를 생성합니다. Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 보내도록 경보를 구성합니다.</strong> </p>
<ul>
<li><strong>서비스 목적의 차이:</strong> AWS Trusted Advisor는 비용 최적화, 성능, 보안, 내결함성 등 AWS 모범 사례에 대한 <strong>상위 수준의 권장 사항</strong>을 제공하는 도구입니다.</li>
</ul>
<p><strong>D. 30 일 이내에 만료되는 모든 인증서를 감지하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다. AWS Lambda 함수를 호출하도록 규칙을 구성합니다. Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 보내도록 Lambda 함수를 구성합니다.</strong></p>
<ul>
<li><strong>비효율적인 아키텍처:</strong> 하지만 이 아키텍처의 가장 큰 문제점은 <strong>불필요한 Lambda 함수</strong>입니다. Amazon EventBridge는 Lambda 함수를 거치지 않고도 <strong>직접 Amazon SNS 주제를 대상(Target)으로 지정</strong>하여 알림을 보낼 수 있습니다. 단순히 알림을 보내는 작업을 위해 Lambda 코드를 작성하고 배포, 관리하는 것은 불필요한 복잡성과 운영 오버헤드를 초래합니다.</li>
</ul>
<h1 id="83">83</h1>
<p>회사의 동적 웹 사이트는 미국의 온프레미스 서버를 사용하여 호스팅됩니다. 이 회사는 유럽에서 제품을 출시하고 있으며 새로운 유럽 사용자를 위해 사이트 로딩 시간을 최적화하려고 합니다. 사이트의 백엔드는 미국에 있어야 합니다. 제품이 며칠 안에 출시되며 즉각적인 솔루션이 필요합니다. 솔루션 설계자는 무엇을 권장해야 합니까? </p>
<p><strong>C. 온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 를 사용합니다.</strong> </p>
<ul>
<li><strong>지연 시간 감소 (핵심):</strong><ul>
<li><strong>정적 콘텐츠 캐싱:</strong> 웹사이트의 이미지, CSS, JavaScript 파일과 같은 정적 콘텐츠는 유럽과 가까운 CloudFront 엣지 로케이션에 캐시(미리 저장)됩니다. 유럽 사용자가 웹사이트에 접속하면, 미국까지 요청을 보내는 대신 가까운 엣지 로케이션에서 이 콘텐츠를 즉시 받아보므로 로딩 속도가 비약적으로 향상됩니다.</li>
<li><strong>동적 콘텐츠 가속화:</strong> CloudFront는 동적 콘텐츠 요청(예: 사용자 로그인, 게시판 글쓰기)도 가속화합니다. 사용자의 요청이 엣지 로케이션에 도달하면, 거기서부터 미국 온프레미스 서버(오리진)까지의 구간은 일반 인터넷이 아닌 <strong>최적화된 AWS 글로벌 네트워크 백본</strong>을 통해 전송됩니다. 이는 일반 인터넷보다 훨씬 빠르고 안정적이므로 동적 콘텐츠 응답 시간도 단축됩니다.</li>
</ul>
</li>
<li><strong>제약 조건 충족:</strong><ul>
<li><strong>백엔드는 미국에 유지:</strong> CloudFront는 기존 인프라 앞에 위치하는 '캐싱 계층'입니다. 원본 서버(오리진)는 그대로 미국의 온프레미스 서버를 사용하므로, 백엔드를 이전할 필요가 없습니다. <code>사용자 지정 오리진(Custom Origin)</code> 설정을 통해 온프레미스 서버의 IP 주소나 도메인 이름을 오리진으로 지정할 수 있습니다.</li>
<li><strong>즉각적인 솔루션:</strong> CloudFront 배포를 생성하고 설정하는 작업은 서버를 마이그레이션하는 것보다 훨씬 간단하고 빠릅니다. 몇 시간 안에 설정하여 바로 적용할 수 있어 '즉각적인 솔루션'이라는 요구사항을 만족시킵니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, D가 적절하지않은이유</strong></p>
<p><strong>A. us-east-1 에서 Amazon EC2 인스턴스를 시작하고 사이트를 마이그레이션합니다.</strong> </p>
<ul>
<li><strong>지연 시간 문제 미해결:</strong> 서버 위치를 미국 내 온프레미스에서 미국 내 AWS 리전(us-east-1)으로 옮기는 것은 유럽 사용자의 물리적 거리를 좁혀주지 못합니다.</li>
</ul>
<p><strong>B. 웹사이트를 Amazon S3로 이동합니다. 지역 간 교차 지역 복제를 사용합니다.</strong> </p>
<ul>
<li><strong>동적 웹사이트 지원 불가 (결정적인 이유):</strong> Amazon S3는 정적(Static) 웹사이트 호스팅만 지원합니다.</li>
</ul>
<p><strong>D. 온프레미스 서버를 가리키는 Amazon Route 53 지리 근접 라우팅 정책을 사용합니다.</strong></p>
<ul>
<li><strong>기능의 오해:</strong> Route 53은 DNS 서비스로, 도메인 이름을 IP 주소로 변환해주는 역할을 합니다.</li>
</ul>
<h1 id="84">84</h1>
<p>회사는 기존 3 계층 웹 아키텍처의 비용을 절감하려고 합니다. 웹, 애플리케이션 및 데이터베이스 서버는 개발, 테스트 및 프로덕션 환경을 위한 Amazon EC2 인스턴스에서 실행됩니다. EC2 인스턴스의 평균 CPU 사용률은 사용량이 많은 시간에는 30%이고 사용량이 많지 않은 시간에는 10%입니다. 프로덕션 EC2 인스턴스는 하루 24 시간 실행됩니다. 개발 및 테스트 EC2 인스턴스는 매일 최소 8 시간 동안 실행됩니다. 회사는 개발을 중지하고 사용하지 않을 때 EC2 인스턴스를 테스트하는 자동화를 구현할 계획입니다. 어떤 EC2 인스턴스 구매 솔루션이 가장 비용 효율적으로 회사의 요구 사항을 충족합니까? </p>
<p><strong>B.프로덕션 EC2 인스턴스에 예약 인스턴스를 사용합니다. 개발 및 테스트 EC2 인스턴스에 온디맨드 인스턴스를 사용합니다.</strong></p>
<ul>
<li><strong>프로덕션 환경: 예약 인스턴스 (Reserved Instances, RI)</strong><ul>
<li><strong>특징:</strong> 프로덕션 EC2 인스턴스는 <strong>하루 24시간, 연중무휴 실행</strong>됩니다. 이것은 사용량이 항상 예측 가능하고 꾸준한 '상시(always-on)' 워크로드임을 의미합니다.</li>
</ul>
</li>
<li><strong>개발 및 테스트 환경: 온디맨드 인스턴스 (On-Demand Instances)</strong><ul>
<li><strong>특징:</strong> 개발 및 테스트 인스턴스는 하루 최소 8시간 동안 실행되지만, <strong>사용하지 않을 때는 자동으로 중지</strong>할 계획입니다. 이는 사용 시간이 불규칙하고 예측하기 어려운 워크로드를 의미합니다.</li>
</ul>
</li>
<li><strong>개발/테스트에 스팟 블록 사용 (부적절/비효율적):</strong> 개발 및 테스트 작업은 정해진 1~6시간 블록 단위로 이루어지지 않는 경우가 많습니다. 개발자가 필요에 따라 인스턴스를 시작하고 중지해야 하므로, 유연하게 켜고 끌 수 있는 온디맨드 방식이 훨씬 더 적합합니다.</li>
</ul>
<h1 id="85">85</h1>
<p>회사에 사용자가 웹 인터페이스 또는 모바일 앱을 통해 문서를 업로드하는 프로덕션 웹 애플리케이션이 있습니다. 새로운 규제 요구 사항에 따라. 새 문서는 저장 후에 수정하거나 삭제할 수 없습니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<p><strong>A. 업로드된 문서를 S3 버전 관리 및 S3 객체 잠금이 활성화된 Amazon S3 버킷에 저장합니다.</strong> </p>
<p>문제의 핵심 요구사항은 <strong>&quot;저장 후에 수정하거나 삭제할 수 없어야 한다&quot;</strong>는 것입니다. 이는 데이터의 <strong>불변성(Immutability)</strong>을 보장해야 한다는 의미이며, 규제 준수 환경에서 흔히 볼 수 있는 WORM(Write-Once, Read-Many) 모델을 요구하는 것입니다.</p>
<ul>
<li><strong>S3 Object Lock (객체 잠금):</strong> 이 요구사항을 충족하는 가장 직접적이고 강력한 AWS 기능입니다. S3 객체 잠금을 사용하면 지정된 보존 기간 동안 객체를 덮어쓰거나 삭제할 수 없도록 보호할 수 있습니다.<ul>
<li><strong>규정 준수 모드 (Compliance Mode):</strong> 이 모드에서는 <strong>루트 사용자를 포함한 그 어떤 사용자도</strong> 보존 기간이 만료되기 전까지 객체를 덮어쓰거나 삭제하거나 잠금 설정을 변경할 수 없습니다. 이는 문제의 엄격한 규제 요구사항을 완벽하게 만족시킵니다.</li>
</ul>
</li>
<li><strong>S3 Versioning (버전 관리):</strong> S3 객체 잠금을 사용하기 위한 <strong>필수 선행 조건</strong>입니다. 버전 관리는 모든 객체의 버전을 보존하므로, 사용자가 실수로 객체를 삭제하더라도 실제 데이터가 사라지는 대신 '삭제 마커'가 생성될 뿐 이전 버전은 그대로 남아있습니다. 객체 잠금은 바로 이 특정 버전에 적용되어 불변성을 보장합니다.</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>C. 업로드된 문서를 S3 버전 관리가 활성화된 Amazon S3 버킷에 저장합니다. 모든 액세스를 읽기 전용으로 제한하도록 ACL을 구성합니다.</strong> </p>
<ul>
<li><strong>ACL (Access Control List, 액세스 제어 목록):</strong> ACL이나 버킷 정책(Bucket Policy)으로 읽기 전용 권한을 설정할 수는 있습니다. 하지만 이러한 권한 설정은 <strong>언제든지 변경될 수 있습니다.</strong> 관리자 권한이 있는 사용자는 ACL이나 버킷 정책을 수정하여 다시 쓰기/삭제 권한을 부여할 수 있습니다. 이는 &quot;절대 수정/삭제 불가&quot;라는 엄격한 규제 요구사항을 만족시키지 못하는 임시방편일 뿐입니다. S3 객체 잠금의 규정 준수 모드처럼 되돌릴 수 없는 강력한 보호를 제공하지 못합니다.</li>
</ul>
<p><strong>B. 업로드된 문서를 Amazon S3 버킷에 저장합니다. 문서를 주기적으로 보관하도록 S3 수명 주기 정책을 구성합니다.</strong> </p>
<ul>
<li><strong>S3 수명 주기 정책 (Lifecycle Policy):</strong> 이 정책의 주된 목적은 <strong>비용 최적화</strong>입니다.</li>
</ul>
<p><strong>D. 업로드된 문서를 Amazon Elastic File System(Amazon EFS) 볼륨에 저장합니다. 읽기 전용 모드에서 볼륨을 마운트하여 데이터에 액세스합니다.</strong></p>
<ul>
<li><strong>Amazon EFS (Elastic File System):</strong> EFS는 여러 EC2 인스턴스에서 동시에 액세스할 수 있는 <strong>파일 스토리지</strong> 서비스입니다. 이는 객체 스토리지인 S3와 용도가 다릅니다.</li>
</ul>
<h1 id="86">86</h1>
<p>회사에는 공통 Amazon RDS MySQL 다중 AZ DB 인스턴스에 자주 액세스해야 하는 여러 웹 서버가 있습니다. 회사는 사용자 자격 증명을 자주 교체해야 하는 보안 요구 사항을 충족하면서 웹 서버가 데이터베이스에 연결할 수 있는 안전한 방법을 원합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>A. AWS Secrets Manager 에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 AWS Secrets Manager 에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.</strong> </p>
<ul>
<li><strong>AWS Secrets Manager</strong>는 데이터베이스 자격 증명, API 키, 기타 보안 암호 등을 수명 주기 전반에 걸쳐 관리, 검색 및 <strong>자동 교체</strong>하는 데 특화된 서비스</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. AWS Systems Manager OpsCenter 에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 OpsCenter에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.</strong> </p>
<ul>
<li><strong>잘못된 서비스 용도</strong>: AWS Systems Manager OpsCenter는 운영 문제(OpsItems)를 중앙에서 보고, 조사하고, 해결하기 위한 서비스입니다. 즉, 장애 관리 및 운영 인사이트를 위한 도구이지, 자격 증명과 같은 민감한 정보를 저장하고 관리하는 용도가 아닙니다. 보안 기능이나 자동 교체 기능이 전혀 없습니다.</li>
</ul>
<p><strong>C. 안전한 Amazon S3 버킷에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 자격 증명을 검색하고 데이터베이스에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.</strong> </p>
<ul>
<li><strong>자동 교체 기능 부재 :</strong> S3와 IAM에는 자동교체기능이없음</li>
</ul>
<p><strong>D. 웹 서버 파일 시스템의 AWS Key Management Service(AWS KMS)로 암호화된 파일에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버는 파일을 해독하고 데이터베이스에 액세스할 수 있어야 합니다.</strong></p>
<ul>
<li><strong>중앙 관리 부재</strong>: 자격 증명이 중앙에서 관리되지 않고 각 서버에 분산되어 있어 일관성을 유지하기 어렵고, 배포 과정에서 실수가 발생하면 일부 서버가 데이터베이스에 접속하지 못하는 문제가 생길 수 있습니다.</li>
</ul>
<h1 id="87">87</h1>
<p>회사는 Amazon API Gateway API에 의해 호출되는 AWS Lambda 함수에서 애플리케이션을 호스팅합니다. Lambda 함수는 고객 데이터를 Amazon Aurora MySQL 데이터베이스에 저장합니다. 회사에서 데이터베이스를 업그레이드할 때마다 Lambda 함수는 업그레이드가 완료될 때까지 데이터베이스 연결을 설정하지 못합니다. 그 결과 일부 이벤트에 대한 고객 데이터가 기록되지 않습니다. 솔루션 설계자는 데이터베이스 업그레이드 중에 생성되는 고객 데이터를 저장하는 솔루션을 설계해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?
이 문제의 핵심은 <strong>'일시적인 장애 상황에서 어떻게 데이터를 안전하게 보존할 것인가?'</strong> 입니다. 이럴 때 가장 효과적이고 표준적인 해결책은 <strong>SQS와 같은 메시징 큐를 중간에 두어 시스템을 디커플링하는 것</strong>입니다</p>
<p><strong>D. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 고객 데이터를 저장합니다. 대기열을 폴링하고 고객 데이터를 데이터베이스에 저장하는 새 Lambda 함수를생성합니다.</strong></p>
<h1 id="88">88</h1>
<p>설문 조사 회사는 미국 지역에서 수년 동안 데이터를 수집했습니다. 이 회사는 크기가 3TB 이고 계속 증가하는 Amazon S3 버킷에 데이터를 호스팅합니다. 이 회사는 S3 버킷이 있는 유럽 마케팅 회사와 데이터를 공유하기 시작했습니다. 회사는 데이터 전송 비용이 가능한 한 낮게 유지되기를 원합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?</p>
<p><strong>A. 회사의 S3 버킷에서 요청자 지불 기능을 구성합니다.</strong> </p>
<p><strong>요청자 지불(Requester Pays)</strong> 기능은 S3 버킷 소유자가 아닌, 데이터를 요청하고 다운로드하는 측(요청자)에게 데이터 전송 및 요청 비용이 부과되도록 하는 기능입니다.</p>
<ul>
<li><strong>문제 상황 적용:</strong> 이 시나리오에서 미국 설문 조사 회사가 S3 버킷에 <code>요청자 지불</code>을 활성화하면, 유럽 마케팅 회사가 데이터를 다운로드할 때 발생하는 모든 <strong>데이터 전송 비용(Data Transfer Out)</strong>은 유럽 마케팅 회사의 AWS 계정으로 청구됩니다.</li>
<li><strong>비용 효율성:</strong> 이를 통해 미국 설문 조사 회사는 데이터 공유로 인해 발생하는 데이터 전송 비용을 전혀 부담하지 않게 되므로, &quot;데이터 전송 비용을 가능한 한 낮게 유지&quot;하려는 요구사항을 완벽하게 충족합니다.</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. 회사의 S3 버킷에서 마케팅 회사의 S3 버킷 중 하나로 S3 교차 리전 복제를 구성합니다.</strong></p>
<ul>
<li>이 경우, 미국 리전에서 유럽 리전으로 데이터를 복제(전송)하는 데 발생하는 <strong>리전 간 데이터 전송 비용</strong>은 원본 버킷의 소유자인 <strong>미국 설문 조사 회사</strong>가 부담해야 합니다. 3TB가 넘는 데이터가 계속 증가하고 있으므로 상당한 비용이 발생하게 됩니다. 따라서 회사의 비용 절감 목표와 맞지 않습니다.</li>
</ul>
<p><strong>C. 마케팅 회사가 회사의 S3 버킷에 액세스할 수 있도록 마케팅 회사에 대한 교차 계정 액세스를 구성합니다.</strong> </p>
<ul>
<li>이것은 단순히 접근 권한을 설정하는 것입니다. 비용 정책을 변경하지 않으면, 기본적으로 S3 버킷에서 데이터가 나갈 때 발생하는 <strong>데이터 전송 비용은 버킷 소유자(미국 설문 조사 회사)에게 청구</strong>됩니다. 따라서 이 옵션만으로는 비용 문제를 해결할 수 없습니다.</li>
</ul>
<p><strong>D. S3 Intelligent-Tiering 을 사용하도록 회사의 S3 버킷을 구성합니다. S3 버킷을 마케팅 회사의 S3 버킷 중 하나와 동기화합니다.</strong></p>
<ul>
<li>이 기능은 <strong>저장 비용(Storage Cost)</strong>을 절감하는 것이지, <strong>데이터 전송 비용(Data Transfer Cost)</strong>과는 관련이 없습니다. 데이터를 동기화(Sync)하는 과정에서는 여전히 리전 간 데이터 전송 비용이 발생하며, 이 비용은 미국 회사가 부담하게 됩니다.</li>
</ul>
<h1 id="89">89</h1>
<p>회사는 Amazon S3 를 사용하여 기밀 감사 문서를 저장합니다. S3 버킷은 버킷 정책을 사용하여 최소 권한 원칙에 따라 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 제한합니다. 회사 관리자는 S3 버킷에서 실수로 문서가 삭제되는 것을 걱정하고 더 안전한 솔루션을 원합니다.  솔루션 설계자는 감사 문서를 보호하기 위해 무엇을 해야 합니까? </p>
<p><strong>A. S3 버킷에서 버전 관리 및 MFA 삭제 기능을 활성화합니다.</strong> </p>
<ul>
<li>버전 관리는 '실수'에 대한 복구 기능을 제공하고, MFA 삭제는 '실수'나 '악의적인 행위'로 인한 영구 삭제를 원천적으로 차단하므로, 이 둘의 조합이 가장 강력하고 안전한 솔루션</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. 각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에 대해 다단계 인증(MFA)을 활성화합니다.</strong> </p>
<ul>
<li>이 방법은 IAM 사용자가 AWS 관리 콘솔이나 CLI에 로그인할 때 MFA 인증을 거치도록 하여 <strong>계정 자체의 보안을 강화</strong>하는 것입니다.</li>
</ul>
<p><strong>C. 감사 날짜 동안 s3:DeleteObject 작업을 거부하도록 감사 팀의 IAM 사용자 계정에 S3 수명 주기 정책을 추가합니다.</strong> </p>
<ul>
<li><strong>S3 수명 주기 정책(Lifecycle Policy)</strong>은 IAM 사용자에게 적용하는 것이 아니라 <strong>S3 버킷에 적용</strong>하는 것입니다. 또한, 이 정책의 주된 목적은 객체를 다른 스토리지 클래스로 이동하거나 <strong>오래된 객체를 자동으로 삭제</strong>하는 것입니다. 즉, 삭제를 방지하는 기능이 아니라 오히려 삭제를 자동화하는 기능입니다.</li>
</ul>
<p><strong>D. AWS Key Management Service(AWS KMS)를 사용하여 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다.</strong></p>
<ul>
<li>KMS를 사용한 서버 측 암호화(SSE-KMS)는 S3에 저장된 데이터를 <strong>저장 시점(at-rest)에 암호화</strong>하여 데이터의 <strong>기밀성(Confidentiality)</strong>을 보장하는 기능입니다.</li>
</ul>
<h1 id="90">90</h1>
<p>회사에서 SQL 데이터베이스를 사용하여 공개적으로 액세스할 수 있는 영화 데이터를 저장하고 있습니다. 데이터베이스는 Amazon RDS 단일 AZ DB 인스턴스에서 실행됩니다. 스크립트는 데이터베이스에 추가된 새로운 영화의 수를 기록하기 위해 매일 임의의 간격으로 쿼리를 실행합니다. 스크립트는 업무 시간 동안의 최종 합계를 보고해야 합니다. 회사의 개발 팀은 스크립트가 실행 중일 때 데이터베이스 성능이 개발 작업에 부적절하다는 것을 알아차렸습니다. 솔루션 설계자는 이 문제를 해결하기 위한 솔루션을 권장해야 합니다. 최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p>문제 요구사항 분석</p>
<ol>
<li><strong>문제 상황:</strong> 개발팀이 사용하는 RDS DB 인스턴스(단일 AZ)에 보고용 스크립트가 쿼리를 실행하면서 <strong>데이터베이스 성능이 저하</strong>되고 있습니다.</li>
<li><strong>핵심 워크로드:</strong><ul>
<li><strong>기본 워크로드 (Primary):</strong> 개발팀의 개발 작업 (읽기 및 쓰기 작업이 모두 발생)</li>
<li><strong>문제 워크로드 (Secondary):</strong> 새로운 영화 수를 집계하는 스크립트의 <strong>읽기(Read) 쿼리</strong></li>
</ul>
</li>
<li><strong>해결 목표:</strong> 개발팀의 작업에 영향을 주지 않도록 <strong>성능 문제를 해결</strong>해야 합니다.</li>
<li><strong>핵심 제약 조건:</strong> <strong>최소한의 운영 오버헤드</strong>로 해결해야 합니다. 즉, 수동 작업이나 복잡한 관리가 필요 없는 자동화된 관리형 솔루션을 의미합니다.</li>
</ol>
<p>결론적으로, <strong>&quot;쓰기/개발 작업과 읽기/보고 작업을 분리하여 성능 저하를 막으면서, 관리는 가장 쉬운 방법을 찾아라&quot;</strong>는 것이 이 문제의 핵심 요구사항입니다.</p>
<p><strong>B. 데이터베이스의 읽기 전용 복제본을 생성합니다. 읽기 전용 복제본만 쿼리하도록 스크립트를 구성합니다.</strong></p>