# SAA-C03 덤프 121~150

게시일: Wed, 02 Jul 2025 13:34:32 GMT
링크: https://velog.io/@agline/SAA-C03-%EB%8D%A4%ED%94%84-121150

---

<h1 id="121">121</h1>
<p>회사는 AWS 에서 OLTP(온라인 트랜잭션 처리) 워크로드를 실행하고 있습니다. 이 워크로드는 다중 AZ 배포에서 암호화되지 않은 Amazon RDS DB 인스턴스를 사용합니다. 일일 데이터베이스 스냅샷은 이 인스턴스에서 가져옵니다. 데이터베이스와 스냅샷이 앞으로 항상 암호화되도록 하려면 솔루션 설계자가 무엇을 해야 합니까? </p>
<p><strong>A. 최신 DB 스냅샷 사본을 암호화합니다. 암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 교체합니다.</strong></p>
<ul>
<li>암호화된 스냅샷을 복원하면, 그로부터 생성되는 새로운 DB 인스턴스는 자동으로 암호화됩니다.</li>
</ul>
<ol>
<li><strong>기존 DB 인스턴스의 스냅샷 생성</strong>: 현재 운영 중인 데이터베이스의 최신 상태를 스냅샷으로 만듭니다. (문제에서는 이미 일일 스냅샷이 있다고 가정합니다).</li>
<li><strong>스냅샷 복사 및 암호화</strong>: 생성된 스냅샷의 <strong>사본</strong>을 만듭니다. 이 복사 과정에서 <strong>암호화 옵션을 활성화</strong>하고 AWS KMS 키를 지정할 수 있습니다. 원본 스냅샷은 암호화되지 않은 상태로 유지되지만, 사본은 암호화됩니다.</li>
<li><strong>암호화된 스냅샷에서 새 DB 인스턴스 복원</strong>: 암호화된 스냅샷 사본을 사용하여 <strong>새로운 DB 인스턴스를 복원</strong>합니다. 이 과정을 통해 생성된 새 DB 인스턴스는 암호화가 적용된 상태입니다.</li>
<li><strong>기존 인스턴스 교체</strong>: 애플리케이션의 데이터베이스 연결 엔드포인트를 이전 인스턴스에서 새로 생성된 암호화된 인스턴스로 변경합니다. 기존 인스턴스는 삭제하거나 중지하여 교체를 완료합니다.</li>
</ol>
<ul>
<li>이 방법은 데이터 손실 없이 운영 중인 데이터베이스를 암호화된 버전으로 안전하게 마이그레이션하는 AWS의 공식 권장 절차입니다. 또한, <strong>암호화된 DB 인스턴스에서 생성되는 모든 향후 스냅샷(자동 및 수동)은 자동으로 암호화</strong>되므로 문제의 모든 요구사항을 충족합니다.</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. 새 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고 여기에 스냅샷을 복사합니다. DB 인스턴스에서 암호화를 활성화합니다.</strong> </p>
<ul>
<li>RDS 스냅샷은 사용자가 직접 관리하는 EBS 볼륨에 복사할 수 있는 형태가 아닙니다.</li>
<li>실행 중인 기존 DB 인스턴스에서 암호화를 직접 활성화할 수 없다</li>
</ul>
<p><strong>C. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷을 복사하고 암호화를 활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스로 복원합니다.</strong> </p>
<ul>
<li>'암호화된 스냅샷을 <strong>기존 DB 인스턴스로 복원</strong>'한다는 부분이 틀렸습니다. RDS 스냅샷을 복원하면 항상 <strong>새로운 DB 인스턴스가 생성</strong>됩니다. 기존 인스턴스에 덮어쓰는 방식의 복원은 불가능합니다. A는 '기존 DB 인스턴스를 교체'한다고 정확하게 표현했지만, C는 기술적으로 불가능한 작업을 설명하고 있습니다.</li>
</ul>
<p><strong>D. AWS Key Management Service(AWS KMS) 관리형 키(SSE-KMS)로 서버 측 암호화를 사용하여 암호화된 Amazon S3 버킷에 스냅샷을 복사합니다.</strong></p>
<ul>
<li>이 작업은 DB 스냅샷 데이터를 분석(예: Athena 사용)이나 장기 보관을 위해 S3로 내보내는 절차입니다. 이 방법으로는 <strong>실행 중인 암호화된 DB 인스턴스를 만들 수 없습니다.</strong></li>
</ul>
<h1 id="122">122</h1>
<p>회사는 응용 프로그램의 데이터를 암호화해야 하는 개발자를 지원하기 위해 확장 가능한 키 관리 인프라를 구축하려고 합니다. 솔루션 설계자는 운영 부담을 줄이기 위해 무엇을 해야 합니까? </p>
<p><strong>B. AWS Key Management Service(AWS KMS)를 사용하여 암호화 키를 보호합니다.</strong> </p>
<ul>
<li>AWS Key Management Service(KMS)는 암호화 키를 쉽게 생성하고 제어할 수 있게 해주는 <strong>완전 관리형 서비스</strong>입니다. 문제의 핵심 요구사항인 <strong>확장성</strong>과 <strong>운영 부담 감소</strong>를 완벽하게 충족합니다.</li>
</ul>
<p><strong>A, C, D가 적절하지 않은 이유</strong></p>
<p><strong>A. MFA(다단계 인증)를 사용하여 암호화 키를 보호합니다.</strong></p>
<ul>
<li>MFA는 사용자 계정의 보안을 강화하기 위한 <strong>인증 메커니즘</strong>입니다. ****</li>
</ul>
<p><strong>C. AWS Certificate Manager(ACM)를 사용하여 암호화 키를 생성, 저장 및 할당합니다.</strong> </p>
<ul>
<li>AWS Certificate Manager(ACM)는 <strong>SSL/TLS 인증서</strong>를 프로비저닝, 관리 및 배포하는 서비스입니다.</li>
</ul>
<p><strong>D. IAM 정책을 사용하여 암호화 키를 보호할 수 있는 액세스 권한이 있는 사용자의 범위를 제한합니다.</strong></p>
<ul>
<li>IAM(Identity and Access Management) 정책은 AWS 리소스에 대한 <strong>접근 권한을 제어</strong>하는 중요한 도구입니다.</li>
</ul>
<h1 id="123">123</h1>
<p>회사에 두 개의 Amazon EC2 인스턴스에서 호스팅되는 동적 웹 애플리케이션이 있습니다. 회사에는 SSL 종료를 수행하기 위해 각 인스턴스에 있는 자체 SSL 인증서가 있습니다. 최근 트래픽이 증가하고 있으며 운영팀은 SSL 암호화 및 복호화로 인해 웹 서버의 컴퓨팅 용량이 최대 한도에 도달했다고 판단했습니다. 솔루션 설계자는 애플리케이션의 성능을 향상시키기 위해 무엇을 해야 합니까? </p>
<p><strong>D. SSL 인증서를 AWS Certificate Manager(ACM)로 가져옵니다. ACM 의 SSL 인증서를 사용하는 HTTPS 리스너로 Application Load Balancer를 생성합니다.</strong></p>
<ul>
<li>[클라이언트] --- (암호화된 HTTPS 트래픽) ---&gt; [ALB] --- (복호화된 HTTP 트래픽) ---&gt; [EC2 인스턴스]</li>
<li><strong>서버 부하 감소</strong>: 질문에 나온 시나리오처럼, 암호화 및 복호화 작업은 CPU를 많이 사용합니다. 이 작업을 EC2 인스턴스 대신 ALB가 전담함으로써, EC2 인스턴스는 오직 애플리케이션 실행에만 컴퓨팅 파워를 사용할 수 있어 <strong>성능이 크게 향상</strong>됩니다.</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. 각 인스턴스에 ACM 인증서를 설치합니다.</strong> </p>
<ul>
<li>이 방법은 인증서 발급 주체를 ACM으로 바꾸는 것일 뿐, <strong>SSL 암호화/복호화 작업은 여전히 개별 EC2 인스턴스에서 수행</strong>됩니다.</li>
</ul>
<p><strong>B. Amazon S3 버킷 생성 SSL 인증서를 S3 버킷으로 마이그레이션합니다. SSL 종료를 위해 버킷을 참조하도록 EC2 인스턴스를 구성합니다.</strong></p>
<p><strong>C. 다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 마이그레이션하고 기존 EC2 인스턴스에 직접 연결하도록 구성합니다.</strong> </p>
<ul>
<li>개념적으로는 SSL 오프로딩을 구현하는 방법 중 하나입니다. 프록시 서버(예: Nginx, HAProxy)를 직접 EC2에 설치하여 SSL을 처리하게 할 수 있습니다.</li>
<li>하지만 이 방법은 ALB라는 <strong>AWS 관리형 서비스를 사용하는 것보다 비효율적</strong>입니다. 프록시 서버용 EC2 인스턴스를 직접 설치, 구성, 패치, 확장 및 모니터링해야 하는 <strong>관리 부담</strong>이 발생하며, 고가용성을 위해서는 이중화 구성 등 추가적인 설계가 필요합니다. 이는 AWS 클라우드의 이점을 제대로 활용하지 못하는 방식입니다.</li>
</ul>
<h1 id="124">124</h1>
<p>회사에 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업이 있습니다. 작업은 본질적으로 상태 비저장이며 부정적인 영향 없이 주어진 시간에 시작 및 중지할 수 있으며 일반적으로 완료하는 데 총 60 분 이상이 걸립니다. 회사는 솔루션 설계자에게 작업 요구 사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계하도록 요청했습니다. 솔루션 설계자는 무엇을 권장해야 합니까? </p>
<p><strong>A. EC2 스팟 인스턴스를 구현합니다.</strong> </p>
<ul>
<li><strong>상태 비저장(Stateless)</strong>: 작업 중간에 중단되더라도 데이터 유실이나 문제가 없음</li>
<li><strong>중단 가능한 작업에 최적화</strong>: 스팟 인스턴스의 가장 큰 특징은 AWS가 해당 용량을 다시 필요로 할 때 2분의 경고 후 인스턴스를 중단시킬 수 있다는 점입니다. 문제의 작업은 &quot;상태 비저장이며 부정적인 영향 없이 시작 및 중지&quot;할 수 있으므로, 스팟 인스턴스가 중단되더라도 다른 스팟 인스턴스가 이어서 작업을 처리하면 되기 때문에 완벽한 조합입니다.</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. EC2 예약 인스턴스 구매.</strong> </p>
<p><strong>C. EC2 온디맨드 인스턴스를 구현합니다.</strong> </p>
<p><strong>D. AWS Lambda에서 처리를 구현합니다.</strong></p>
<h1 id="125">125</h1>
<p>회사는 AWS 에서 2 계층 전자상거래 웹사이트를 운영합니다. 웹 계층은 트래픽을 Amazon EC2 인스턴스로 보내는 로드 밸런서로 구성됩니다. 데이터베이스 계층은 Amazon RDS DB 인스턴스를 사용합니다. EC2 인스턴스 및 RDS DB 인스턴스는 공용 인터넷에 노출되어서는 안 됩니다. EC2 인스턴스는 타사 웹 서비스를 통한 주문 결제 처리를 완료하기 위해 인터넷 액세스가 필요합니다. 애플리케이션은 고가용성이어야 합니다. 이러한 요구 사항을 충족하는 구성 옵션의 조합은 무엇입니까? (2개를 선택하세요.) </p>
<p><strong>A. Auto Scaling 그룹을 사용하여 프라이빗 서브넷에서 EC2 인스턴스를 시작합니다. 프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다.</strong> </p>
<ul>
<li><strong>EC2 인스턴스를 프라이빗 서브넷에 배치</strong>: &quot;EC2 인스턴스는 공용 인터넷에 노출되어서는 안 된다&quot;는 <strong>보안 요구사항</strong>을 충족합니다.</li>
<li><strong>Auto Scaling 그룹 사용</strong>: 트래픽에 따라 EC2 인스턴스 수를 자동으로 조절하고, 인스턴스에 장애가 발생하면 자동으로 복구하여 <strong>고가용성</strong>을 확보합니다.</li>
<li><strong>RDS 다중 AZ(Multi-AZ) DB 인스턴스 배포</strong>: 기본 DB에 장애 발생 시 다른 가용 영역(AZ)에 있는 예비 DB로 자동 장애 조치(Failover)하여 데이터베이스의 <strong>고가용성</strong>을 보장합니다.</li>
<li><strong>RDS를 프라이빗 서브넷에 배치</strong>: &quot;RDS DB 인스턴스는 공용 인터넷에 노출되어서는 안 된다&quot;는 <strong>보안 요구사항</strong>을 충족합니다.</li>
</ul>
<p><strong>E. 2 개의 가용 영역에 걸쳐 2개의 퍼블릭 서브넷, 2개의 프라이빗 서브넷 및 2개의 NAT 게이트웨이로 VPC 를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer 를 배포합니다.</strong></p>
<ul>
<li><strong>2개의 가용 영역에 걸친 서브넷 구성</strong>: <strong>고가용성</strong> 요구사항을 충족하기 위한 가장 기본적인 네트워크 설계입니다.</li>
<li><strong>퍼블릭 서브넷에 Application Load Balancer(ALB) 배포</strong>: ALB는 외부 인터넷 트래픽을 수신하는 유일한 진입점이므로 반드시 <strong>퍼블릭 서브넷</strong>에 위치해야 합니다.</li>
<li><strong>2개의 프라이빗 서브넷</strong>: A에서 설명한 EC2 인스턴스와 RDS 인스턴스를 배치할 안전한 공간입니다.</li>
<li><strong>2개의 NAT 게이트웨이</strong>: 프라이빗 서브넷의 EC2 인스턴스가 인터넷으로 아웃바운드 통신(결제 처리)을 할 수 있도록 경로를 제공합니다. 각 가용 영역에 NAT 게이트웨이를 하나씩 두어 <strong>고가용성</strong>을 확보합니다. (하나의 AZ에 장애가 나도 다른 AZ의 NAT 게이트웨이를 통해 통신 가능)</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. 2 개의 가용 영역에 걸쳐 2 개의 프라이빗 서브넷과 2 개의 NAT 게이트웨이가 있는 VPC를 구성합니다. 프라이빗 서브넷에 Application Load Balancer를 배포합니다.</strong> </p>
<ul>
<li>Application Load Balancer를 <strong>프라이빗 서브넷</strong>에 배포하면 외부 인터넷에서 접근할 수 없습니다.</li>
</ul>
<p><strong>C. Auto Scaling 그룹을 사용하여 2 개의 가용 영역에 걸쳐 퍼블릭 서브넷에서 EC2 인스턴스를 시작합니다. 프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다.</strong> </p>
<ul>
<li>EC2 인스턴스를 <strong>퍼블릭 서브넷</strong>에 시작하면 공인 IP를 할당받아 인터넷에 직접 노출될 수 있습니다. 이는 &quot;EC2 인스턴스는 공용 인터넷에 노출되어서는 안 된다&quot;는 핵심 <strong>보안 요구사항</strong>에 정면으로 위배됩니다.</li>
</ul>
<p><strong>D. 2 개의 가용 영역에 걸쳐 1개의 퍼블릭 서브넷, 1개의 프라이빗 서브넷 및 2개의 NAT 게이트웨이로 VPC 를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer 를 배포합니다.</strong> </p>
<ul>
<li><strong>고가용성</strong>을 위해서는 최소 2개의 가용 영역(AZ)에 걸쳐 리소스를 분산해야 합니다.</li>
</ul>
<h1 id="126">126</h1>
<p>A solutions architect needs to implement a solution to reduce a company's storage costs. All the company's data is in the Amazon S3 Standard storage class. The company must keep all data for at least 25 years. Data from the most recent 2 years must be highly available and immediately retrievable. Which solution will meet these requirements? </p>
<p><strong>B. Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 2 years.</strong> </p>
<p> (2년 후 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 정책 설정)</p>
<ul>
<li><strong>처음 2년 동안:</strong> 데이터는 <strong>S3 Standard</strong>에 남아있습니다. S3 Standard는 여러 가용 영역(AZ)에 데이터를 복제하여 <strong>고가용성</strong>을 보장하고, <strong>즉시 검색</strong>이 가능합니다.</li>
<li><strong>2년 후:</strong> S3 수명 주기 정책에 따라 데이터가 자동으로 <strong>S3 Glacier Deep Archive</strong>로 이동합니다.</li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong></p>
<p><strong>A. Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive immediately.</strong> </p>
<ul>
<li>객체를 즉시 S3 Glacier Deep Archive로 전환- 이 경우, 생성된 지 2년이 안 된 데이터도 바로 아카이빙됩니다. S3 Glacier Deep Archive의 데이터는 검색하는 데 몇 시간이 걸리므로, &quot;즉시 검색 가능해야 한다&quot;는 요구사항을 위반하게 됩니다.</li>
</ul>
<p><strong>C. Use S3 Intelligent-Tiering. Activate the archiving option to ensure that data is archived in S3 Glacier Deep Archive.</strong> </p>
<ul>
<li><strong>S3 Intelligent-Tiering 사용:</strong> S3 Intelligent-Tiering은 액세스 패턴을 알 수 없거나 자주 바뀌는 데이터에 적합합니다. 이 시나리오처럼 <strong>&quot;2년&quot;이라는 명확한 시간 기준</strong>이 있을 때는, 정해진 시간에 따라 데이터를 이동시키는 <strong>S3 수명 주기 정책</strong>이 더 직접적이고 비용 효율적인 솔루션입니다.</li>
</ul>
<p><strong>D. Set up an S3 Lifecycle policy to transition objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately and to S3 Glacier Deep Archive after 2 years.</strong></p>
<ul>
<li>S3 One Zone-IA로 즉시 전환 후 2년 뒤 S3 Glacier Deep Archive로 전환:  해당 가용 영역에 장애가 발생하면 데이터에 접근할 수 없으므로 <strong>&quot;고가용성&quot;</strong> 요구사항을 충족하지 못합니다.</li>
</ul>
<h1 id="127">127</h1>
<p>한 미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 처리를 위한 가능한 최대 I/O 성능을 갖춘 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB 의 매우 내구성 있는 스토리지, 더 이상 사용하지 않는 아카이브 미디어에 대한 요구 사항을 충족하기 위해 900TB의 스토리지가 필요합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 서비스 세트를 권장해야 합니까? </p>
<p><strong>D. 최고의 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier</strong></p>
<ul>
<li>최고의 성능 (최대 I/O): Amazon EC2 인스턴스 스토어<ul>
<li>AWS는 특정 워크로드를 위해 매우 큰 용량의 인스턴스 스토어를 제공하는 EC2 인스턴스 유형(Instance Type)들을 갖추고 있습니다. 특히 <strong>스토리지 최적화(Storage Optimized)</strong> 인스턴스 패밀리가 여기에 해당합니다.</li>
<li><strong><code>i4i.16xlarge</code></strong> 인스턴스는 <strong>15TB (7.5TB NVMe SSD 2개)</strong>의 인스턴스 스토어를 제공합니다.</li>
<li><strong><code>i3en.12xlarge</code></strong> 인스턴스는 <strong>30TB (7.5TB NVMe SSD 4개)</strong>의 인스턴스 스토어를 제공합니다.</li>
</ul>
</li>
<li>내구성 있는 스토리지: Amazon S3</li>
<li>아카이브 스토리지: Amazon S3 Glacier</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 최고의 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier</strong> </p>
<p><strong>B. 최고의 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon EFS, 아카이브 스토리지를 위한 Amazon S3 Glacier</strong> </p>
<p><strong>C. 최고의 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon EFS, 아카이브 스토리지를 위한 Amazon S3</strong> </p>
<ul>
<li>Amazon EBS → EC2 인스턴스 스토어보다는 I/O 성능이 낮습니다.</li>
<li>Amazon EFS → 내구성이 높지만, 주로 여러 서버가 공통 파일에 접근해야 하는 워크로드에 사용됩니다. 300TB의 미디어 콘텐츠를 저장하는 용도로는 객체 스토리지인 <strong>S3가 확장성 및 비용 효율성 면에서 훨씬 뛰어난</strong> 선택입니다.</li>
<li>아카이브 스토리지를 위한 Amazon S3 → &quot;아카이브&quot;라는 명확한 요구사항에는 저렴한 장기 보관용 서비스인 <strong>Amazon S3 Glacier</strong>를 사용하는 것이 비용 효율적</li>
</ul>
<h1 id="128">128</h1>
<p>회사에서 AWS 클라우드의 컨테이너에서 애플리케이션을 실행하려고 합니다. 이러한 애플리케이션은 상태 비저장이며 기본 인프라 내에서 중단을 허용할 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<p><strong>B. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 스팟 인스턴스를 사용합니다.</strong> </p>
<ul>
<li><strong>비용 최소화 (스팟 인스턴스)</strong>: 애플리케이션이 <strong>상태 비저장(stateless)</strong>이고 <strong>중단을 허용</strong>할 수 있으므로, AWS가 유휴 컴퓨팅 용량을 매우 저렴하게 제공하는 <strong>스팟 인스턴스(Spot Instances)</strong>를 사용하는 것이 가장 비용 효율적입니다.</li>
<li><strong>운영 오버헤드 최소화 (EKS 관리형 노드 그룹)</strong>: 컨테이너화된 애플리케이션을 직접 EC2에서 운영하는 것보다 <strong>Amazon EKS</strong>와 같은 관리형 컨테이너 오케스트레이션 서비스를 사용하는 것이 훨씬 편리합니다.</li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong></p>
<p><strong>A. Amazon EC2 Auto Scaling 그룹의 스팟 인스턴스를 사용하여 애플리케이션 컨테이너를 실행합니다.</strong> </p>
<ul>
<li><strong>운영 오버헤드</strong>: 이 방식은 EC2 인스턴스에 직접 Docker와 같은 컨테이너 런타임을 설치하고, 컨테이너 스케줄링, 네트워킹, 로드 밸런싱 등을 수동으로 구성해야 합니다.</li>
</ul>
<p><strong>C. Amazon EC2 Auto Scaling 그룹의 온디맨드 인스턴스를 사용하여 애플리케이션 컨테이너를 실행합니다.</strong> </p>
<ul>
<li><strong>비용</strong>: 중단 가능한 워크로드임에도 불구하고 비싼 <strong>온디맨드 인스턴스(On-Demand Instances)</strong>를 사용하므로 '비용 최소화'에 실패합니다.</li>
<li><strong>운영 오버헤드</strong>: A와 마찬가지로 EC2에서 직접 컨테이너를 관리해야 하므로 운영 부담이 큽니다.</li>
</ul>
<p><strong>D. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 온디맨드 인스턴스를 사용합니다.</strong></p>
<ul>
<li><strong>운영 오버헤드</strong>: EKS 관리형 노드 그룹을 사용하므로 운영 부담은 적습니다.</li>
<li><strong>비용</strong>: 애플리케이션이 중단을 허용할 수 있음에도 불구하고, 저렴한 스팟 인스턴스 대신 비싼 <strong>온디맨드 인스턴스</strong>를 사용합니다. 이는 '비용 최소화'라는 핵심 요구사항을 충족하지 못하는 결정입니다.</li>
</ul>
<h1 id="129">129</h1>
<p>회사에서 온프레미스에서 다중 계층 웹 애플리케이션을 실행하고 있습니다. 웹 애플리케이션은 컨테이너화되어 있으며 사용자 레코드가 포함된 PostgreSQL 데이터베이스에 연결된 여러 Linux 호스트에서 실행됩니다. 인프라 및 용량 계획을 유지 관리하는 운영 오버헤드가 회사의 성장을 제한하고 있습니다. 솔루션 설계자는 애플리케이션의 인프라를 개선해야 합니다. 솔루션 설계자는 이를 달성하기 위해 어떤 조합의 조치를 취해야 합니까? (2개 선택) </p>
<p><strong>A. PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션합니다.</strong> </p>
<ul>
<li>완전 관리형 서비스로 전환</li>
</ul>
<p><strong>E. Amazon Elastic Container Service(Amazon ECS)를 사용하여 AWS Fargate 에서 호스팅할 웹 애플리케이션을 마이그레이션합니다.</strong></p>
<ul>
<li>서버리스 컨테이너 환경으로 전환</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다.</strong> </p>
<ul>
<li>이 방식은 단순히 온프레미스 서버를 클라우드 가상 서버(EC2)로 옮기는 <strong>'리프트 앤 시프트(Lift and Shift)'</strong>에 해당합니다.</li>
</ul>
<p><strong>C. 웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다.</strong> </p>
<ul>
<li>CloudFront는 <strong>CDN(콘텐츠 전송 네트워크)</strong> 서비스입니다. 정적/동적 콘텐츠를 사용자에게 더 가까운 엣지 로케이션에 캐싱하여 웹 사이트 로딩 속도를 높이고 원본 서버의 부하를 줄여주는 역할을 합니다.</li>
</ul>
<p><strong>D. 웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache를 설정합니다.</strong> </p>
<ul>
<li>ElastiCache는 <strong>인 메모리 캐싱 서비스</strong>입니다. 데이터베이스에서 자주 조회하는 데이터를 메모리에 캐싱하여 응답 속도를 높이고 데이터베이스 부하를 줄여주는 역할을 합니다.</li>
</ul>
<h1 id="130">130</h1>
<p>애플리케이션은 여러 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40% 또는 거의 40%일 때 가장 잘 수행됩니다. 솔루션 설계자는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 합니까? </p>
<p>B. 대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다. </p>
<ul>
<li><strong>대상 추적(Target Tracking) 조정 정책</strong>은 특정 지표(Metric)를 원하는 목표 값으로 유지하도록 설계되었습니다.<ul>
<li><strong>작동 방식</strong>: 솔루션 설계자는 목표 값으로 <strong>평균 CPU 사용률 40%</strong>를 설정하기만 하면 됩니다. 그러면 Amazon EC2 Auto Scaling이 이 목표를 유지하기 위해 필요한 EC2 인스턴스의 수를 자동으로 계산하여 조정합니다.</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong> </p>
<p><strong>A. Auto Scaling 그룹을 동적으로 확장하려면 간단한 확장 정책을 사용합니다.</strong> </p>
<ul>
<li>단순 조정 정책 (Simple Scaling Policy)-  이 방식은 CPU 사용률을 특정 목표(40%)에 정확히 맞추기 어렵습니다.</li>
</ul>
<p><strong>C. AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량을 업데이트합니다.</strong> </p>
<ul>
<li>Lambda 함수를 사용하여 주기적으로 또는 경보에 따라 Auto Scaling 그룹의 용량을 직접 조절하는 것은 <strong>가능은 하지만, 불필요하게 복잡한 방법</strong>입니다.</li>
</ul>
<p><strong>D. 예약된 조정 작업을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다.</strong></p>
<ul>
<li>예약된 조정은 <strong>트래픽을 예측할 수 있는 경우</strong>에 사용됩니다.</li>
<li>문제의 시나리오는 실시간 CPU 사용률이라는 동적인 지표에 따라 용량을 조절해야 하는 상황입니다. 트래픽이 시간에 따라 예측 가능한 패턴을 보인다는 언급이 없으므로, 예약된 조정은 적합하지 않습니다.</li>
</ul>
<h1 id="131">131</h1>
<p>한 회사에서 Amazon S3 버킷을 스토리지로 사용할 파일 공유 애플리케이션을 개발 중입니다. 회사는 Amazon CloudFront 배포를 통해 모든 파일을 제공하려고 합니다. 회사는 S3 URL에 대한 직접 탐색을 통해 파일에 액세스하는 것을 원하지 않습니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<ul>
<li><strong>직접 접근 차단</strong>: 사용자가 S3 버킷의 고유 URL(예: <code>https://my-bucket.s3.ap-northeast-2.amazonaws.com/document.pdf</code>)을 알아내더라도, 이 주소로 직접 접속하는 것을 <strong>반드시 막아야 합니다.</strong></li>
<li><strong>우회 경로 차단</strong>: 모든 파일 접근은 <strong>반드시 CloudFront를 통해서만</strong> 이루어져야 합니다. (예: <code>https://d123xyz.cloudfront.net/document.pdf</code>)</li>
</ul>
<p>D. 원본 액세스 ID(OAI)를 생성합니다. CloudFront 배포에 OAI 를 할당합니다. OAI 만 읽기 권한을 갖도록 S3 버킷 권한을 구성합니다.</p>
<ul>
<li><p><strong>OAI란?</strong>: OAI는 Amazon CloudFront를 위한 일종의 가상 사용자 또는 특별한 ID입니다. 일반 IAM 사용자와는 다릅니다. 이 ID의 유일한 목적은 CloudFront가 S3 버킷의 파일에 접근할 수 있도록 허용하는 것입니다.</p>
</li>
<li><p><strong>작동 방식</strong>:</p>
<ul>
<li>먼저 CloudFront 전용 OAI를 생성합니다.</li>
<li>생성된 OAI를 CloudFront 배포 설정의 원본(Origin)에 연결합니다. 이렇게 하면 이제 해당 CloudFront 배포는 OAI라는 신분증을 갖게 됩니다.</li>
<li>마지막으로, S3 버킷의 권한 정책(Bucket Policy)을 수정하여 <strong>오직 이 OAI만이 버킷의 객체를 읽을 수 있도록 (<code>s3:GetObject</code>) 허용</strong>합니다.</li>
</ul>
</li>
<li><p><strong>나이트클럽 비유 🕺</strong></p>
<ul>
<li><p><strong>S3 버킷</strong>: 아무나 들어올 수 없는 <strong>비공개 VIP 파티장</strong>입니다.</p>
</li>
<li><p><strong>S3 버킷 정책</strong>: 파티장 입구를 지키는 <strong>경호원(바운서)</strong>의 규칙입니다.</p>
</li>
<li><p><strong>CloudFront</strong>: 손님들을 파티장까지 안전하게 데려다주는 <strong>공식 리무진 서비스</strong>입니다.</p>
</li>
<li><p><strong>OAI (정답 방식)</strong>: 리무진 기사만 가지고 있는 <strong>고유한 신분증</strong>입니다.</p>
<p>이 상황에서 파티 주최자는 경호원에게 이렇게 말해야 합니다.</p>
<p>올바른 방식 (OAI 사용): &quot;우리와 계약된 리무진 서비스의 <strong>'특별 신분증(OAI)'</strong>을 보여주는 기사가 데려온 손님만 들여보내 줘.&quot;</p>
</li>
</ul>
</li>
<li><p><strong>사용자 → CloudFront (성공)</strong>: 사용자가 CloudFront URL로 파일에 접근하면, CloudFront는 자신의 OAI 신분증을 사용하여 S3 버킷에서 파일을 가져와 사용자에게 전달합니다.</p>
</li>
<li><p><strong>사용자 → S3 URL (실패)</strong>: 사용자가 S3 버킷의 URL로 직접 파일에 접근하려고 하면, S3 버킷 정책에 따라 허용된 OAI가 아니므로 <strong>&quot;403 Forbidden (액세스 거부)&quot;</strong> 오류가 발생합니다.</p>
</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 각 S3 버킷에 대한 개별 정책을 작성하여 CloudFront 액세스에 대해서만 읽기 권한을 부여합니다.</strong> </p>
<ul>
<li><strong>잘못된 방식 (A의 해석)</strong>: &quot;검은색 리무진을 타고 오는 손님은 모두 들여보내 줘.&quot;</li>
<li><strong>보안 문제 (아무나 들어올 수 있음)</strong><ul>
<li>세상에는 우리가 계약한 리무진 외에도 수많은 '검은색 리무진'이 있습니다. 다른 파티에 가는 손님이나, 심지어 초대받지 않은 손님도 검은색 리무진을 타고 올 수 있습니다.</li>
<li>마찬가지로, <strong>CloudFront의 IP 주소는 수많은 AWS 사용자가 함께 공유</strong>합니다. 내 웹사이트뿐만 아니라 다른 회사의 웹사이트 트래픽도 같은 IP 주소에서 올 수 있습니다. 따라서 IP 주소만으로 허용하는 것은 우리 파티에 초대받지 않은 손님도 들어올 수 있게 문을 열어두는 것과 같아서 매우 위험합니다.</li>
</ul>
</li>
<li><strong>관리 문제 (규칙이 계속 바뀜)</strong><ul>
<li>만약 우리 리무진 회사가 내일부터 갑자기 '하얀색 리무진'으로 차를 모두 바꾼다면 어떻게 될까요? 경호원은 바뀐 규칙을 전달받지 못하면 정식 손님도 들여보내 주지 못할 겁니다. 규칙을 계속 업데이트해야 하는 번거로움이 생깁니다.</li>
<li>마찬가지로 <strong>AWS는 CloudFront의 IP 주소 대역을 수시로 변경</strong>합니다. 이 변경 사항을 계속 추적해서 S3 버킷 정책을 일일이 수정하는 것은 거의 불가능하며, 실수가 발생하기 쉽습니다.</li>
</ul>
</li>
</ul>
<p><strong>B. IAM 사용자를 생성합니다. 사용자에게 S3 버킷의 객체에 대한 읽기 권한을 부여합니다. 사용자를 CloudFront에 할당합니다.</strong> </p>
<ul>
<li><strong>CloudFront 배포에 IAM 사용자를 직접 할당하는 기능은 없습니다.</strong> IAM 사용자는 사람, 애플리케이션, EC2 인스턴스 등이 AWS 서비스에 접근할 때 사용하는 자격 증명입니다.</li>
</ul>
<p><strong>C. CloudFront 배포 ID 를 보안 주체로 할당하고 대상 S3 버킷을 Amazon 리소스 이름(ARN)으로 할당하는 S3 버킷 정책을 작성합니다.</strong> </p>
<ul>
<li><strong>CloudFront 배포 ID는 S3 버킷 정책의 유효한 보안 주체(Principal)가 아님.</strong>S3가 인식할 수 있는 유효한 보안 주체가 아니기 때문입니다. S3 정책의 보안 주체는 AWS 계정 ARN, IAM 사용자 ARN, IAM 역할 ARN, 또는 OAI와 같은 특정 서비스 보안 주체여야 합니다. 이 선택지는 그럴듯해 보이지만 기술적으로 불가능한, 흔한 오답 유형입니다.</li>
</ul>
<h1 id="132">132</h1>
<p>회사 웹사이트는 사용자에게 다운로드 가능한 과거 실적 보고서를 제공합니다. 웹 사이트에는 전 세계적으로 회사의 웹 사이트 요구 사항을 충족하도록 확장할 수 있는 솔루션이 필요합니다. 솔루션은 비용 효율적이어야 하고 인프라 리소스 프로비저닝을 제한하며 가능한 가장 빠른 응답 시간을 제공해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조합을 권장해야 합니까? </p>
<p><strong>A. Amazon CloudFront 및 Amazon S3</strong> </p>
<ul>
<li><strong>Amazon S3 (Simple Storage Service)</strong><ul>
<li>보고서와 같은 <strong>정적 파일을 저장</strong>하기에 가장 이상적이고 저렴한 서비스입니다.</li>
<li>내구성이 매우 높고 확장이 용이하며, 서버를 프로비저닝하거나 관리할 필요가 없습니다.</li>
</ul>
</li>
<li><strong>Amazon CloudFront</strong><ul>
<li>글로벌 <strong>콘텐츠 전송 네트워크(CDN)</strong> 서비스입니다.</li>
<li>S3에 저장된 원본 보고서 파일을 전 세계에 분산된 <strong>엣지 로케이션(Edge Location)에 캐싱</strong>합니다.</li>
<li>사용자가 웹사이트에 접속하면, 물리적으로 가장 가까운 엣지 로케이션에서 보고서 파일을 전송받게 됩니다.</li>
</ul>
</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. AWS Lambda 및 Amazon DynamoDB</strong> </p>
<ul>
<li>이 조합은 <strong>서버리스 컴퓨팅과 NoSQL 데이터베이스</strong>로, 주로 <strong>동적인 데이터 처리나 API 백엔드</strong>를 구축할 때 사용됩니다.</li>
</ul>
<p><strong>C. Amazon EC2 Auto Scaling 이 있는 Application Load Balancer</strong> </p>
<ul>
<li>이것은 <strong>동적 웹 애플리케이션을 위한 전통적인 서버 기반 아키텍처</strong>입니다.</li>
</ul>
<p><strong>D. 내부 Application Load Balancer 가 있는 Amazon Route 53</strong></p>
<ul>
<li>가장 결정적인 오류는 <strong>내부(Internal) Application Load Balancer</strong>를 사용한다는 점입니다. 내부 ALB는 VPC 내부에서만 접근 가능하며, <strong>인터넷을 통해 전 세계 사용자가 접속할 수 없습니다.</strong></li>
</ul>
<h1 id="133">133</h1>
<p>회사는 온프레미스에서 Oracle 데이터베이스를 실행합니다. 회사는 AWS 로 마이그레이션하는 과정에서 데이터베이스를 사용 가능한 최신 버전으로 업그레이드하려고 합니다. 회사는 또한 데이터베이스에 대한 재해 복구(DR)를 설정하려고 합니다. 회사는 정상 운영 및 DR 설정을 위한 운영 오버헤드를 최소화해야 합니다. 회사는 또한 데이터베이스의 기본 운영 체제에 대한 액세스를 유지 관리해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<ul>
<li><strong>운영 오버헤드 최소화</strong>: 관리형 서비스(Managed Service)를 선호합니다.</li>
<li><strong>재해 복구(DR) 설정</strong>: 다른 AWS 리전(Region)에 복구 솔루션을 마련해야 합니다.</li>
<li><strong>기본 운영 체제(OS) 액세스 유지</strong>: 데이터베이스가 실행되는 서버의 OS에 직접 접근할 수 있어야 합니다.</li>
</ul>
<p><strong>C. Oracle 데이터베이스를 Oracle 용 Amazon RDS Custom 으로 마이그레이션합니다. 다른 AWS 리전의 데이터베이스에 대한 읽기 전용 복제본을 생성합니다.</strong></p>
<ul>
<li><strong>운영 오버헤드 최소화</strong>: <strong>Amazon RDS Custom</strong>은 Amazon RDS의 관리형 기능(자동 백업, 패치 등) 일부를 제공하면서도 OS 및 데이터베이스 환경에 대한 제어 권한을 부여하는 서비스입니다.</li>
<li><strong>재해 복구(DR) 설정</strong>: <strong>다른 AWS 리전에 읽기 전용 복제본(Cross-Region Read Replica)</strong>을 생성하는 것은 대표적인 DR 전략입니다. 주 리전에 재해가 발생하면 몇 분 안에 다른 리전의 읽기 전용 복제본을 독립적인 주 데이터베이스로 승격시켜 서비스를 빠르게 복구할 수 있습니다.</li>
<li><strong>기본 운영 체제(OS) 액세스 유지</strong>: <strong>Amazon RDS Custom</strong>의 핵심 기능입니다. 표준 RDS와 달리, RDS Custom은 SSH 등을 통해 기본 EC2 인스턴스의 OS에 접근하여 특정 패치를 적용하거나 사용자 지정 소프트웨어를 설치하는 등의 작업을 수행할 수 있습니다.</li>
</ul>
<p><strong>A, B, D가 적절하지 않은 이유</strong></p>
<p><strong>A. Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션합니다. 다른 AWS 리전으로 데이터베이스 복제를 설정합니다.</strong> </p>
<ul>
<li><strong>운영 오버헤드 최소화 실패</strong>: EC2 인스턴스에 직접 Oracle을 설치하면 OS 패치, 데이터베이스 설치 및 구성, 백업, 고가용성(HA), 재해 복구(DR) 등 모든 것을 사용자가 직접 책임지고 관리해야 합니다.</li>
</ul>
<p><strong>B. Oracle 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 교차 리전 자동 백업을 활성화하여 다른 AWS 리전에 스냅샷을 복제합니다.</strong> </p>
<ul>
<li><strong>기본 운영 체제(OS) 액세스 불가</strong>: Amazon RDS는 완전 관리형 서비스로, AWS가 OS와 데이터베이스 관리를 책임집니다. 이 때문에 사용자는 <strong>기본 OS에 접근할 수 있는 권한이 없습니다.</strong></li>
</ul>
<p><strong>D. Oracle 데이터베이스를 Oracle용 Amazon RDS로 마이그레이션합니다. 다른 가용 영역에 대기 데이터베이스를 생성합니다.</strong></p>
<ul>
<li><strong>대기 데이터베이스(Multi-AZ)는 운영 오버헤드가 높은 것이 아니라, 오히려 매우 낮습니다.</strong> AWS가 자동으로 관리해주기 때문이죠.</li>
<li><strong>대기 데이터베이스 (다중 AZ/Multi-AZ)</strong>: <strong>하나의 리전(Region) 내</strong>에서 서로 다른 가용 영역(AZ)에 복제본을 두는 방식입니다. 이는 한 데이터 센터(AZ)에 정전이나 네트워크 장애가 발생했을 때, 같은 리전 내의 다른 데이터 센터(AZ)로 자동 전환하여 서비스를 중단 없이 이어가기 위한 <strong>고가용성(High Availability, HA)</strong> 솔루션입니다.</li>
<li><strong>문제의 요구사항 (재해 복구/DR)</strong>: 지진, 홍수 등으로 <strong>리전 전체가 마비되는 재해 상황</strong>에 대비하는 것입니다. 이를 위해서는 <strong>물리적으로 멀리 떨어진 다른 리전(Cross-Region)</strong>에 데이터베이스 복제본을 두어야 합니다</li>
</ul>
<h1 id="134">134</h1>
<p>한 회사에서 애플리케이션을 서버리스 솔루션으로 이동하려고 합니다. 서버리스 솔루션은 SQL 을 사용하여 기존 및 신규 데이터를 분석해야 합니다. 회사는 데이터를 Amazon S3 버킷에 저장합니다. 데이터는 암호화가 필요하며 다른 AWS 리전에 복제해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<ul>
<li><strong>서버리스 솔루션</strong>으로 데이터 분석</li>
<li>데이터는 <strong>S3</strong>에 저장</li>
<li>데이터 <strong>암호화</strong> 필요</li>
<li>다른 리전으로 <strong>데이터 복제</strong> 필요</li>
<li><strong>최소한의 운영 오버헤드</strong></li>
</ul>
<p><strong>C. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.</strong> </p>
<ul>
<li><strong>Amazon Athena</strong>: S3에 저장된 데이터를 별도의 서버나 데이터베이스 없이 직접 표준 SQL로 쿼리할 수 있는 <strong>완전 서버리스 서비스</strong>입니다. 데이터 분석 요구사항과 서버리스 조건에 완벽하게 부합합니다.</li>
<li><strong>SSE-S3 (Amazon S3 관리형 암호화 키)</strong>: S3에서 객체를 저장할 때 자동으로 암호화해주는 가장 간단한 방법입니다. AWS가 암호화 키를 모두 관리하므로 사용자는 키 관리에 대한 어떠한 <strong>운영 오버헤드도 부담하지 않습니다</strong>. '최소한의 운영 오버헤드' 요구사항에 가장 적합합니다.</li>
<li><strong>S3 교차 리전 복제 (CRR)</strong>: S3 버킷의 객체를 다른 리전의 버킷으로 자동 복제하는 기능입니다. 데이터 복제 요구사항을 충족하며, SSE-S3로 암호화된 객체도 원활하게 복제됩니다.</li>
<li><strong>기존 S3 버킷 사용</strong>: '기존 및 신규 데이터'를 분석해야 하므로, 불필요하게 새 버킷을 만들어 데이터를 이전하는 것보다 기존 버킷을 활용하는 것이 더 간단하고 효율적입니다.</li>
</ul>
<p><strong>A, B, D가 적절하지 않은 이유</strong></p>
<p><strong>A. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS 다중 리전 kay(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다.</strong> </p>
<ul>
<li>SSE-KMS는 사용자가 직접 KMS 키를 생성하고 권한 및 수명 주기를 관리해야 합니다. 이는 SSE-S3에 비해 더 세분화된 제어가 가능하지만, 키 정책 관리, 감사 추적 등 <strong>추가적인 운영 오버헤드</strong>가 발생합니다.</li>
</ul>
<p><strong>B. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS 다중 리전 키(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon RDS 를 사용하여 데이터를 쿼리합니다.</strong> </p>
<p><strong>D. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용합니다. Amazon RDS를 사용하여 데이터를 쿼리합니다.</strong></p>
<ul>
<li><strong>Amazon RDS 사용</strong>: B와 D는 데이터 쿼리에 <strong>Amazon RDS</strong>를 사용한다고 제안합니다.<ul>
<li>RDS는 관계형 데이터베이스 서비스로, S3에 저장된 데이터를 직접 쿼리할 수 없습니다. S3의 데이터를 RDS로 가져오는 별도의 ETL(Extract, Transform, Load) 파이프라인을 구축하고 관리해야 합니다.</li>
<li>이는 '서버리스 분석'이 아니며, RDS 인스턴스 관리와 데이터 로딩 과정에서 상당한 <strong>운영 오버헤드</strong>를 발생시킵니다. 따라서 문제의 핵심 요구사항을 위반합니다.</li>
</ul>
</li>
</ul>
<h1 id="135">135</h1>
<p>회사는 AWS에서 워크로드를 실행합니다. 회사는 외부 공급자의 서비스에 연결해야 합니다. 서비스는 공급자의 VPC에서 호스팅됩니다. 회사 보안 팀에 따르면 연결은 비공개여야 하며 대상 서비스로 제한되어야 합니다. 연결은 회사의 VPC에서만 시작되어야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<ul>
<li><strong>프라이빗 연결</strong>: 인터넷을 통하지 않아야 합니다.</li>
<li><strong>서비스 제한</strong>: 공급자의 전체 VPC가 아닌, 특정 서비스에만 연결이 제한되어야 합니다.</li>
<li><strong>단방향 시작</strong>: 연결은 항상 회사 VPC에서 시작되어야 합니다.</li>
</ul>
<p><strong>D. 공급자에게 대상 서비스에 대한 VPC 엔드포인트를 생성하도록 요청합니다. AWS PrivateLink 를 사용하여 대상 서비스에 연결합니다.</strong></p>
<ul>
<li><strong>프라이빗 연결</strong>: <strong>AWS PrivateLink</strong>는 트래픽이 AWS 프라이빗 네트워크 내에서만 이동하도록 보장합니다. 인터넷을 전혀 거치지 않으므로 보안성이 높습니다.</li>
<li><strong>서비스 제한</strong>: PrivateLink는 공급자의 VPC에 있는 특정 서비스(정확히는 Network Load Balancer에 연결된 서비스)에 대한 <strong>엔드포인트(VPC Interface Endpoint)</strong>를 회사 VPC 내에 생성합니다. 이를 통해 공급자의 다른 리소스에는 전혀 접근할 수 없고 오직 해당 서비스에만 연결이 제한됩니다.</li>
<li><strong>단방향 시작</strong>: 회사 VPC의 리소스가 VPC 엔드포인트를 통해 공급자의 서비스로 요청을 보내는 단방향 연결입니다. 공급자 측에서 회사 VPC로 먼저 연결을 시작할 수 없습니다.</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 회사의 VPC 와 공급자의 VPC 간에 VPC 피어링 연결을 생성합니다. 대상 서비스에 연결하도록 라우팅 테이블을 업데이트합니다.</strong> </p>
<ul>
<li>VPC 피어링은 특정 '서비스'에 연결하는 것이 아니라, <strong>'네트워크 대 네트워크'</strong>로 연결합니다. 즉, 공급자 VPC의 <strong>전체 네트워크(또는 서브넷)가 회사 VPC에 노출</strong>됩니다.</li>
</ul>
<p><strong>B. 공급자에게 VPC 에 가상 프라이빗 게이트웨이를 생성하도록 요청합니다. AWS PrivateLink 를 사용하여 대상 서비스에 연결합니다.</strong> </p>
<ul>
<li><strong>가상 프라이빗 게이트웨이(Virtual Private Gateway, VGW)</strong>는 VPC와 온프레미스 네트워크를 VPN 또는 Direct Connect로 연결할 때 사용하는 구성 요소입니다. 공급자의 VPC와 회사 VPC를 연결하는 시나리오에는 적합하지 않습니다. AWS PrivateLink와 함께 사용되는 구성 요소도 아니므로 잘못된 조합입니다.</li>
</ul>
<p><strong>C. 회사의 VPCUpdate 라우팅 테이블의 퍼블릭 서브넷에 NAT 게이트웨이를 생성하여 대상 서비스에 연결합니다.</strong> </p>
<ul>
<li><strong>NAT 게이트웨이</strong>는 프라이빗 서브넷의 인스턴스가 <strong>인터넷</strong>으로 아웃바운드 트래픽을 보낼 수 있게 해주는 서비스입니다.</li>
<li>&quot;연결은 비공개여야 한다&quot;는 핵심 요구사항에 정면으로 위배됩니다.</li>
</ul>
<h1 id="136">136</h1>
<p>회사는 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL 로 마이그레이션하고 있습니다. 온-프레미스 데이터베이스는 온라인 상태를 유지하고 마이그레이션 중에 액세스할 수 있어야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화된 상태를 유지해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까? (2 개를 선택하세요.) </p>
<ul>
<li><strong>온프레미스 데이터베이스 (PostgreSQL)</strong>:<ul>
<li>현재 <strong>운영 중인 메인 데이터베이스</strong>입니다.</li>
<li>모든 애플리케이션과 사용자는 여전히 이 데이터베이스에 접속해서 데이터를 읽고, 쓰고, 수정하고 있습니다. (Live / Production 상태)</li>
<li>이 데이터베이스가 바로 '진실의 원천(Source of Truth)'입니다.</li>
</ul>
</li>
<li><strong>AWS Aurora 데이터베이스 (PostgreSQL)</strong>:<ul>
<li><strong>새롭게 구축되는 대상(Target) 데이터베이스</strong>입니다.</li>
<li>아직 애플리케이션 트래픽을 받지 않습니다.</li>
<li>AWS DMS를 통해 온프레미스 DB의 데이터를 실시간으로 복제 받으며 '따라가는' 역할을 합니다. 즉, 온프레미스 DB의 '그림자 복제본'처럼 동기화되고 있는 상태입니다.</li>
</ul>
</li>
</ul>
<p><strong>C. AWS Database Migration Service(AWS DMS) 복제 서버를 생성합니다.</strong> </p>
<ul>
<li>'최소 다운타임' 마이그레이션을 위해 사용하는 대표적인 AWS 서비스가 바로 AWS Database Migration Service(DMS)입니다.</li>
</ul>
<p><strong>A. 지속적인 복제 작업을 만듭니다.</strong> </p>
<ul>
<li>복제 인스턴스를 만든 후, 실제 데이터 이전을 정의하는 <strong>작업(Task)</strong>을 생성해야 합니다. 이 시나리오에서는 마이그레이션 중에도 원본의 변경 사항을 계속 따라잡아야 하므로, <strong>지속적인 복제(Ongoing Replication)</strong> 또는 <strong>변경 데이터 캡처(Change Data Capture, CDC)</strong> 기능을 활성화한 작업을 만들어야 합니다. 이 작업은 다음과 같이 동작합니다.<ul>
<li><strong>전체 로드(Full Load)</strong>: 먼저 원본 데이터베이스의 기존 데이터를 모두 타겟 데이터베이스로 복사합니다.</li>
<li><strong>변경 데이터 캡처(CDC)</strong>: 전체 로드가 진행되는 동안 및 완료된 후에 발생하는 모든 데이터 변경(INSERT, UPDATE, DELETE)을 지속적으로 타겟에 적용하여 동기화를 유지합니다.</li>
</ul>
</li>
</ul>
<p><strong>B, D, E가 적절하지 않은이유</strong></p>
<p><strong>B. 온프레미스 데이터베이스의 데이터베이스 백업을 생성합니다.</strong> </p>
<ul>
<li>백업은 특정 시점의 데이터 스냅샷일 뿐입니다. 백업을 생성해서 복원하는 방식은 <strong>지속적인 동기화</strong> 요구사항을 충족할 수 없습니다.</li>
</ul>
<p><strong>D. AWS Schema Conversion Tool(AWS SCT)을 사용하여 데이터베이스 스키마를 변환합니다.</strong> </p>
<ul>
<li>AWS SCT는 서로 <strong>다른 종류의 데이터베이스 엔진</strong> 간에 마이그레이션할 때(예: Oracle → PostgreSQL, SQL Server → Aurora MySQL) 주로 사용됩니다. 스키마, 코드, 저장 프로시저 등이 호환되지 않을 수 있기 때문에 변환 작업이 필요합니다.</li>
</ul>
<p><strong>E. 데이터베이스 동기화를 모니터링하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.</strong></p>
<ul>
<li>EventBridge나 CloudWatch를 사용하여 DMS 작업의 상태(예: 복제 지연 시간)를 모니터링하는 것은 매우 좋은 운영 방식입니다. 하지만 이것은 마이그레이션을 <strong>수행</strong>하는 조치가 아니라, 수행되는 과정을 <strong>감시</strong>하는 조치입니다.</li>
</ul>
<h1 id="137">137</h1>
<p>회사는 AWS Organizations 를 사용하여 각 사업부에 대한 전용 AWS 계정을 생성하여 요청 시 각 사업부의 계정을 독립적으로 관리합니다. 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림을 놓치지 않기를 원합니다. 향후 알림은 계정 관리자로 제한되어야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>B. 모든 AWS 계정 루트 사용자 이메일 주소를 알림에 응답할 수 있는 소수의 관리자에게 전달되는 배포 목록으로 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성합니다.</strong> </p>
<ul>
<li><strong>배포 목록(Distribution List) 사용</strong>: 루트 사용자 이메일을 개인 이메일(<code>hong-gildong@company.com</code>)이 아닌, 여러 관리자가 포함된 그룹 이메일 주소(<code>aws-admins@company.com</code> 등)로 설정하는 것입니다.<ul>
<li>한 명의 담당자가 부재중이거나 이메일을 놓치더라도 다른 관리자들이 알림을 수신할 수 있습니다. 이를 통해 <strong>단일 장애 지점(Single Point of Failure)</strong>을 제거하여 알림을 놓칠 위험을 크게 줄일 수 있습니다.</li>
</ul>
</li>
<li><strong>AWS 계정 대체 연락처(Alternate Contacts) 구성</strong>: AWS Organizations의 기능으로, 계정의 루트 이메일을 변경하지 않고도 <strong>청구(Billing), 운영(Operations), 보안(Security)</strong> 관련 알림을 수신할 별도의 이메일 주소를 지정할 수 있습니다.<ul>
<li>중요한 알림을 실제 담당하는 팀(예: 보안팀, 재무팀)의 배포 목록으로 직접 보낼 수 있습니다. 이를 통해 &quot;알림은 계정 관리자로 제한되어야 한다&quot;는 요구사항을 충족하면서, 알림 종류에 따라 가장 적절한 담당자 그룹에게 전달할 수 있어 효율적이고 안전합니다.</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지 않은 이유</strong></p>
<p><strong>A. AWS 계정 루트 사용자 이메일 주소로 전송되는 알림 이메일 메시지를 조직의 모든 사용자에게 전달하도록 회사 이메일 서버를 구성합니다.</strong> </p>
<ul>
<li><strong>알림 이메일을 조직의 모든 사용자에게 전달</strong> : <strong>최소 권한 원칙(Principle of Least Privilege)</strong>에 정면으로 위배됩니다.</li>
</ul>
<p><strong>C. 경보를 모니터링하고 해당 경보를 적절한 그룹에 전달할 책임이 있는 한 명의 관리자에게 모든 AWS 계정 루트 사용자 이메일 메시지를 보내도록 구성합니다.</strong> </p>
<ul>
<li><strong>한 명의 관리자에게 모든 루트 이메일 메시지를 전달 :</strong> 문제의 근본 원인을 해결하지 못합니다. 기존의 '루트 이메일 수신자'라는 <strong>단일 장애 지점(Single Point of Failure)</strong>을 '한 명의 관리자'라는 또 다른 단일 장애 지점으로 옮기는 것에 불과합니다. 만약 그 관리자가 휴가를 가거나 퇴사하면 똑같은 문제가 반복됩니다.</li>
</ul>
<p><strong>D. 동일한 루트 사용자 이메일 주소를 사용하도록 기존의 모든 AWS 계정과 새로 생성된 모든 계정을 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성합니다.</strong></p>
<ul>
<li><strong>모든 계정에 동일한 루트 사용자 이메일 주소 사용 :</strong> 매우 위험한 <strong>보안 안티 패턴(Anti-Pattern)</strong>입니다. 모든 계정이 동일한 루트 이메일 주소를 공유하면, 만약 그 이메일 계정이 해킹당했을 때 조직의 <strong>모든 AWS 계정</strong>이 한 번에 위험에 처하게 됩니다.</li>
</ul>
<h1 id="138">138</h1>
<p>회사는 AWS 에서 전자 상거래 애플리케이션을 실행합니다. 모든 새 주문은 단일 가용 영역의 Amazon EC2 인스턴스에서 실행되는 RabbitMQ 대기열에 마사지로 게시됩니다. 이러한 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에서 처리됩니다. 이 애플리케이션은 다른 EC2 인스턴스의 PostgreSQL 데이터베이스에 세부 정보를 저장합니다. 모든 EC2 인스턴스는 동일한 가용 영역에 있습니다. 회사는 최소한의 운영 오버헤드로 최고의 가용성을 제공하도록 아키텍처를 재설계해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<p><strong>B. 대기열을 Amazon MQ 에서 RabbitMQ 인스턴스의 중복 쌍(활성/대기)으로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 용 Amazon RDS 의 다중 AZ 배포에서 실행하도록 데이터베이스를 마이그레이션합니다.</strong> </p>
<ul>
<li><strong>Amazon MQ</strong>로 마이그레이션합니다.</li>
<li><strong>다중 AZ Auto Scaling 그룹</strong>을 생성합니다.</li>
<li><strong>Amazon RDS 다중 AZ 배포</strong>로 마이그레이션합니다.</li>
</ul>
<p><strong>A, C, D가 적절하지 않은 이유</strong></p>
<p><strong>A. 대기열을 Amazon MQ 에서 RabbitMQ 인스턴스의 중복 쌍(활성/대기)으로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling 그룹을 생성합니다.</strong> </p>
<ul>
<li>데이터베이스에 Auto Scaling 그룹을 사용하는 것이 치명적인 실수입니다.</li>
</ul>
<p><strong>C. RabbitMQ 대기열을 호스팅하는 EC2 인스턴스용 다중 AZ Auto Scaling 그룹을 생성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 용 Amazon RDS 의 다중 AZ 배포에서 실행하도록 데이터베이스를 마이그레이션합니다.</strong></p>
<p><strong>D. RabbitMQ 대기열을 호스팅하는 EC2 인스턴스용 다중 AZ Auto Scaling 그룹을 생성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대한 세 번째 다중 AZ Auto Scaling 그룹을 생성합니다.</strong></p>
<ul>
<li>EC2에 직접 RabbitMQ를 설치하고 Auto Scaling으로 구성하는 것(C, D)은 여전히 패치, 버전 관리, 클러스터링 설정 등 직접 해야 할 운영 부담이 큽니다.</li>
<li>반면 <strong>Amazon MQ</strong>는 AWS가 직접 관리해주는 <strong>관리형 서비스(Managed Service)</strong>입니다. 따라서 사용자는 복잡한 설정이나 관리 없이 RabbitMQ의 기능을 그대로 사용하면서 운영 부담을 최소화할 수 있습니다.</li>
</ul>
<h1 id="139">139</h1>
<p>보고 팀은 Amazon S3 버킷에서 매일 파일을 수신합니다. 보고 팀은 이 초기 S3 버킷의 파일을 수동으로 검토하고 Amazon QuickSight 와 함께 사용하기 위해 매일 같은 시간에 분석 S3 버킷으로 복사합니다. 추가 팀이 초기 S3 버킷에 더 큰 크기의 더 많은 파일을 보내기 시작했습니다. 보고 팀은 파일이 초기 S3 버킷에 들어갈 때 자동으로 분석 S3 버킷을 이동하려고 합니다. 또한 보고 팀은 AWS Lambda 함수를 사용하여 복사된 데이터에서 패턴 일치 코드를 실행하려고 합니다. 또한 보고 팀은 데이터 파일을 Amazon SageMaker Pipelines 의 파이프라인으로 보내려고 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까?</p>
<p><strong>현재 상황 (As-Is)</strong></p>
<ul>
<li><strong>소스:</strong> '초기 S3 버킷'으로 매일 파일이 수신됩니다.</li>
<li><strong>프로세스:</strong> 보고 팀이 이 파일들을 <strong>수동으로 검토</strong>하고 '분석 S3 버킷'으로 복사합니다.</li>
<li><strong>목적:</strong> '분석 S3 버킷'의 데이터를 Amazon QuickSight 시각화에 사용합니다.</li>
<li><strong>문제점:</strong> 최근 파일의 <strong>크기와 양이 증가</strong>하여 수동 작업에 부담이 되고 있습니다.</li>
</ul>
<p><strong>새로운 요구사항 (To-Be)</strong></p>
<ul>
<li><strong>파일 복사 자동화</strong><ul>
<li>'초기 S3 버킷'에 파일이 들어오면, '분석 S3 버킷'으로 <strong>자동으로 복사</strong>되어야 합니다.</li>
</ul>
</li>
<li><strong>데이터 처리 자동화 (파일 복사 후)</strong><ul>
<li>파일이 '분석 S3 버킷'에 복사되면, 아래 두 가지 작업이 <strong>자동으로 실행</strong>되어야 합니다.<ul>
<li><strong>작업 1:</strong> <strong>AWS Lambda 함수</strong>를 호출하여 데이터에 대한 패턴 매칭 코드를 실행합니다.</li>
<li><strong>작업 2:</strong> <strong>Amazon SageMaker Pipelines</strong>로 데이터 파일을 전송합니다.</li>
</ul>
</li>
</ul>
</li>
<li><strong>핵심 제약 조건</strong><ul>
<li>이 모든 솔루션은 <strong>최소한의 운영 오버헤드</strong>로 구축되어야 합니다.</li>
</ul>
</li>
</ul>
<p><strong>D. S3 버킷 간에 S3 복제를 구성합니다. Amazon EventBridge(Amazon CloudWatch Events)에 이벤트 알림을 보내도록 분석 S3 버킷을 구성합니다. EventBridge(CloudWatch 이벤트)에서 ObjectCreated 규칙을 구성합니다. 규칙의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다.</strong></p>
<ul>
<li><strong>최소 운영 오버헤드</strong>: S3 복제는 AWS에서 직접 관리하는 완전 관리형 기능입니다. 사용자는 복제 규칙만 설정하면 되며, 파일을 복사하기 위한 별도의 코드(Lambda)를 작성하거나 인프라를 관리할 필요가 없습니다.</li>
<li><strong>후속 작업 트리거: Amazon EventBridge 사용</strong><ul>
<li><strong>다중 대상(Target) 지원</strong>: 파일이 '분석 S3 버킷'에 복사된 후, <strong>Lambda 함수 실행</strong>과 <strong>SageMaker 파이프라인 시작</strong>이라는 두 가지 작업을 동시에 수행해야 합니다. EventBridge는 단일 이벤트 소스(S3 객체 생성)에 대해 여러 개의 대상(Lambda, SageMaker 등)을 손쉽게 설정할 수 있는 <strong>팬아웃(fan-out) 패턴</strong>에 최적화되어 있습니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 생성합니다. 분석 S3 버킷에 대한 S3 이벤트 알림을 생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다. s3:ObjectCreated:Put 을 이벤트 유형으로 구성합니다.</strong> </p>
<ul>
<li>Lambda로 복사 + S3 이벤트 알림</li>
</ul>
<p><strong>B. 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 생성합니다. Amazon EventBridge(Amazon CloudWatch Events)에 이벤트 알림을 보내도록 분석 S3 버킷을 구성합니다. EventBridge(CloudWatch 이벤트)에서 ObjectCreated 규칙을 구성합니다. 규칙의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다.</strong> </p>
<ul>
<li>Lambda로 복사 + EventBridge</li>
</ul>
<p><strong>C. S3 버킷 간에 S3 복제를 구성합니다. 분석 S3 버킷에 대한 S3 이벤트 알림을 생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다. s3:ObjectCreated:Put 을 이벤트 유형으로 구성합니다.</strong> </p>
<ul>
<li>S3 복제 + S3 이벤트 알림</li>
<li><strong>Lambda로 복사</strong>: 파일을 복사하기 위해 Lambda 함수를 직접 개발하고 관리해야 합니다. 이는 S3 복제 기능을 사용하는 것보다 <strong>운영 오버헤드가 더 높습니다.</strong></li>
<li><strong>S3 이벤트 알림</strong>: S3 이벤트 알림은 일반적으로 단일 이벤트에 대해 단일 대상을 지정하는 데 사용됩니다. Lambda와 SageMaker 파이프라인이라는 <strong>두 개의 대상을 직접 연결하기 어렵습니다.</strong></li>
</ul>
<h1 id="140">140</h1>
<p>솔루션 설계자는 회사가 AWS 에서 애플리케이션을 실행하는 비용을 최적화할 수 있도록 도와야 합니다. 애플리케이션은 아키텍처 내 컴퓨팅을 위해 Amazon EC2 인스턴스, AWS Fargate 및 AWS Lambda 를 사용합니다. EC2 인스턴스는 애플리케이션의 데이터 수집 계층을 실행합니다. EC2 사용은 산발적이고 예측할 수 없습니다. EC2 인스턴스에서 실행되는 워크로드는 언제든지 중단될 수 있습니다. 애플리케이션 프런트 엔드는 Fargate 에서 실행되고 Lambda 는 API 계층을 제공합니다. 프론트엔드 활용도와 API 계층 활용도는 내년에 예측할 수 있습니다. 이 애플리케이션을 호스팅하는 데 가장 비용 효율적인 솔루션을 제공하는 구매 옵션 조합은 무엇입니까? (2개 선택) </p>
<p><strong>A. 데이터 수집 계층에 스팟 인스턴스 사용</strong> </p>
<ul>
<li>이 워크로드는 중단이 가능하다고 했으므로 스팟 인스턴스의 가장 큰 단점(중단 가능성)을 수용할 수 있습니다. 또한, 사용량이 예측 불가능하므로 약정 기반 모델(예: 예약 인스턴스)보다 사용한 만큼만 저렴하게 지불하는 스팟 인스턴스가 비용 효율성 측면에서 가장 유리합니다.</li>
</ul>
<p><strong>C. 프런트 엔드 및 API 계층에 대한 1년 Compute Savings Plan을 구매합니다.</strong> </p>
<ul>
<li><strong>Compute Savings Plan</strong>은 EC2, Fargate, Lambda 등 다양한 컴퓨팅 서비스에 자동으로 할인이 적용되는 가장 유연한 플랜입니다.</li>
<li>Fargate와 Lambda 사용량이 예측 가능하므로, 해당 사용량에 맞춰 Compute Savings Plan에 가입하면 온디맨드 요금보다 훨씬 저렴하게 서비스를 이용할 수 있습니다. 두 가지 다른 서비스(Fargate, Lambda)를 모두 포괄해야 하므로 Compute Savings Plan이 가장 적합한 선택입니다.</li>
</ul>
<p><strong>B, D, E가 적절하지않은이유</strong></p>
<p><strong>B. 데이터 수집 계층에 온디맨드 인스턴스 사용</strong> </p>
<ul>
<li><strong>온디맨드 인스턴스</strong>는 약정 없이 사용한 만큼 비용을 지불하지만, 할인율이 전혀 없습니다. 워크로드가 중단될 수 없는 경우에는 좋은 선택이지만, 이 시나리오에서는 워크로드가 <strong>중단 가능</strong>하므로 훨씬 저렴한 스팟 인스턴스를 사용하는 것이 비용을 최적화하는 길입니다.</li>
</ul>
<p><strong>D. 데이터 수집 계층에 대한 1년 전체 선결제 예약 인스턴스를 구매합니다.</strong> </p>
<ul>
<li><strong>예약 인스턴스(Reserved Instances, RI)</strong>는 꾸준하고 예측 가능한 사용량에 적합합니다. 데이터 수집 계층의 워크로드는 <strong>산발적이고 예측 불가능</strong>하므로, RI를 구매하면 사용량이 적은 기간에는 비용을 낭비하게 됩니다.</li>
</ul>
<p><strong>E. 프런트 엔드 및 API 계층을 위한 1년 EC2 인스턴스 Savings Plan을 구매합니다.</strong></p>
<ul>
<li><strong>EC2 Instance Savings Plan:</strong> 특정 리전의 특정 인스턴스 패밀리(예: 서울 리전의 c5)에만 적용되며, EC2에만 할인이 적용됩니다.</li>
<li>프런트엔드와 API 계층은 Fargate와 Lambda를 사용하므로, <strong>EC2에만 적용되는 EC2 Instance Savings Plan은 아무런 할인 혜택을 주지 못합니다.</strong></li>
</ul>
<h1 id="141">141</h1>
<p>한 회사는 사용자에게 글로벌 속보, 지역 경보 및 날씨 업데이트를 제공하는 웹 기반 포털을 운영합니다. 포털은 정적 콘텐츠와 동적 콘텐츠를 혼합하여 각 사용자에게 개인화된 보기를 제공합니다. 콘텐츠는 ALB (Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 실행되는 API 서버를 통해 HTTPS 를 통해 제공됩니다. 회사는 포털이 이 콘텐츠를 가능한 한 빨리 전 세계 사용자에게 제공하기를 원합니다. 솔루션 설계자는 모든 사용자의 대기 시간을 최소화하도록 애플리케이션을 어떻게 설계해야 합니까?</p>
<p><strong>A. 단일 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon CloudFront 를 사용하여 ALB 를 오리진으로 지정하여 모든 정적 및 동적 콘텐츠를 제공합니다.</strong> </p>
<ul>
<li><strong>정적 콘텐츠 가속</strong>: <strong>Amazon CloudFront</strong>는 전 세계에 퍼져있는 <strong>엣지 로케이션(Edge Location)에 정적 콘텐츠(HTML, CSS, JS, 이미지 등)를 캐싱</strong>합니다. 사용자가 콘텐츠를 요청하면, 물리적으로 가장 가까운 엣지 로케이션에서 바로 콘텐츠를 전송받으므로 지연 시간이 획기적으로 줄어듭니다.</li>
<li><strong>동적 콘텐츠 가속</strong>: CloudFront는 캐싱할 수 없는 <strong>동적 콘텐츠(개인화된 뉴스, 날씨 등)의 전송 속도도 향상</strong>시킵니다.<ul>
<li><strong>TCP/TLS 핸드셰이크 최적화</strong>: 사용자는 멀리 있는 오리진(Origin) 리전이 아닌, 가장 가까운 엣지 로케이션과 빠르고 안전한 연결을 맺습니다.</li>
<li><strong>AWS 글로벌 네트워크 활용</strong>: 엣지 로케이션에서 오리진 ALB까지의 통신은 혼잡한 공용 인터넷 대신, 빠르고 안정적인 <strong>AWS의 전용 글로벌 네트워크 백본</strong>을 통해 이루어집니다. 이 구간에서 지연 시간이 크게 단축됩니다.</li>
<li><strong>오리진 연결 재사용</strong>: CloudFront는 오리진과의 연결을 유지하고 재사용하여, 요청마다 새로운 연결을 맺는 오버헤드를 줄입니다.</li>
</ul>
</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. 두 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon Route 53 지연 시간 라우팅 정책을 사용하여 가장 가까운 리전의 ALB에서 모든 콘텐츠를 제공합니다.</strong> </p>
<ul>
<li>이 방법은 CloudFront와 같은 CDN을 사용하지 않습니다. 사용자는 가장 가까운 '리전'까지는 빠르게 연결될 수 있지만, 엣지 로케이션만큼 가깝지는 않습니다. 예를 들어 호주에 있는 사용자는 싱가포르 리전으로 연결될 수 있지만, 시드니 엣지 로케이션에서 직접 캐시된 콘텐츠를 받는 것보다는 훨씬 느립니다.</li>
</ul>
<p><strong>C. 단일 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon CloudFront 를 사용하여 정적 콘텐츠를 제공합니다. ALB에서 직접 동적 콘텐츠를 제공합니다.</strong> </p>
<ul>
<li><strong>동적 콘텐츠 가속 포기</strong>: 이 아키텍처는 CloudFront의 가장 중요한 장점 중 하나인 <strong>동적 콘텐츠 가속 기능</strong>을 활용하지 않습니다.</li>
</ul>
<p><strong>D. 두 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon Route 53 지리적 위치 라우팅 정책을 사용하여 가장 가까운 리전에서 ALB의 모든 콘텐츠를 제공합니다.</strong></p>
<ul>
<li><strong>부적절한 라우팅 정책</strong>: <strong>지리적 위치(Geolocation) 라우팅</strong>은 사용자의 물리적인 위치(국가, 대륙 등)를 기반으로 트래픽을 라우팅합니다.</li>
<li><strong>'지리적으로 가장 가깝다' → '네트워크 속도가 가장 빠르다'</strong>는 아님</li>
</ul>
<h1 id="142">142</h1>
<p>게임 회사는 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 실행되며 UDP 기반 트래픽만 지원합니다. 회사는 최상의 사용자 경험을 제공하기 위해 프런트 엔드 계층이 필요합니다. 해당 계층은 대기 시간이 짧고 가장 가까운 엣지 로케이션으로 트래픽을 라우팅하고 애플리케이션 엔드포인트에 진입하기 위한 고정 IP 주소를 제공해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<ul>
<li><strong>프로토콜:</strong> <strong>UDP</strong> 기반 트래픽만 지원해야 합니다.</li>
<li><strong>애플리케이션 환경:</strong> 수정된 <strong>Linux 커널</strong>에서 실행됩니다.</li>
<li><strong>프런트엔드 요구사항:</strong><ul>
<li><strong>낮은 대기 시간 (Low Latency)</strong></li>
<li>가장 가까운 <strong>엣지 로케이션</strong>으로 트래픽 라우팅</li>
<li>진입점(Entry Point)을 위한 <strong>고정 IP 주소</strong> 제공</li>
</ul>
</li>
</ul>
<p><strong>C. 요청을 Network Load Balancer 로 전달하도록 AWS Global Accelerator 를 구성합니다. EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다.</strong> </p>
<ul>
<li><strong>AWS Global Accelerator:</strong><ul>
<li><strong>UDP 지원:</strong> TCP와 UDP 트래픽을 모두 지원합니다.</li>
<li><strong>낮은 대기 시간 및 엣지 라우팅:</strong> AWS의 글로벌 네트워크 인프라를 활용하여 사용자를 가장 가까운 엣지 로케이션으로 연결하고, 최적의 경로로 애플리케이션 엔드포인트까지 트래픽을 전달하여 지연 시간을 크게 줄여줍니다.</li>
<li><strong>고정 IP 주소:</strong> 변경되지 않는 두 개의 고정 Anycast IP 주소를 제공하여 애플리케이션의 안정적인 진입점 역할을 합니다.</li>
</ul>
</li>
<li><strong>Network Load Balancer (NLB)</strong><ul>
<li><strong>UDP 지원:</strong> OSI 4계층에서 작동하며, 대규모 UDP 트래픽을 처리하는 데 최적화되어 있습니다. 게임과 같이 높은 처리량과 낮은 지연 시간이 중요한 워크로드에 매우 적합합니다.</li>
</ul>
</li>
<li><strong>Amazon EC2 인스턴스 (in Auto Scaling 그룹):</strong><ul>
<li><strong>수정된 Linux 커널:</strong> EC2 인스턴스를 사용하면 사용자가 직접 운영체제와 커널을 제어할 수 있으므로, 수정된 Linux 커널을 사용하는 애플리케이션을 실행할 수 있습니다.</li>
<li><strong>고가용성:</strong> Auto Scaling 그룹을 사용하면 트래픽에 따라 인스턴스 수를 자동으로 조절하고, 인스턴스에 장애가 발생하면 자동으로 교체하여 고가용성을 보장할 수 있습니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, D가 적절하지않은이유</strong></p>
<p><strong>B. 요청을 Network Load Balancer 로 전달하도록 Amazon CloudFront를 구성합니다. AWS Application Auto Scaling 그룹의 애플리케이션에 AWS Lambda를 사용합니다.</strong> </p>
<ul>
<li><strong>AWS Lambda:</strong> Lambda는 서버리스 컴퓨팅 서비스로, 사용자가 OS나 커널을 수정할 수 없습니다. 따라서 <strong>수정된 Linux 커널</strong> 요구사항을 충족할 수 없습니다.</li>
</ul>
<p><strong>A. 요청을 Application Load Balancer 로 전달하도록 Amazon Route 53 을 구성합니다. AWS Application Auto Scaling 의 애플리케이션에 AWS Lambda 를 사용합니다.</strong> </p>
<p><strong>D. 요청을 Application Load Balancer 로 전달하도록 Amazon API Gateway 를 구성합니다. EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다.</strong></p>
<ul>
<li><strong>Application Load Balancer (ALB):</strong> ALB는 OSI 7계층(HTTP, HTTPS)에서 작동하며 <strong>UDP 트래픽을 지원하지 않습니다.</strong> 이것이 가장 결정적인 오답 이유입니다.</li>
</ul>
<h1 id="143">143</h1>
<p>회사에서 기존 온프레미스 모놀리식 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 회사는 프론트엔드 코드와 백엔드 코드를 최대한 많이 유지하려고 합니다. 그러나 회사는 응용 프로그램을 더 작은 응용 프로그램으로 나누기를 원합니다. 다른 팀에서 각 애플리케이션을 관리합니다. 회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 솔루션이 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>D. Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS를 대상으로 하여 Application Load Balancer를 설정합니다.</strong></p>
<ul>
<li><strong>기존 코드 최대한 재사용</strong>: 애플리케이션을 컨테이너화하면 기존 코드베이스를 거의 변경하지 않고도 AWS 환경에서 실행할 수 있습니다. 이는 모놀리식 애플리케이션을 마이그레이션하는 일반적이고 효율적인 첫 단계입니다.</li>
<li><strong>애플리케이션 분할 (마이크로서비스 아키텍처)</strong>: <strong>ECS</strong>는 컨테이너 기반의 마이크로서비스를 배포하고 관리하는 데 최적화된 서비스입니다. 기존 모놀리식 애플리케이션을 여러 개의 작은 서비스(컨테이너)로 분리하고, 각 팀이 독립적으로 자신의 서비스를 관리하고 배포할 수 있습니다.</li>
<li><strong>높은 확장성</strong>: <strong>Application Load Balancer(ALB)</strong>와 ECS 서비스의 <strong>Auto Scaling</strong> 기능을 결합하면 트래픽 양에 따라 컨테이너 수를 자동으로 조절하여 높은 확장성을 확보할 수 있습니다. ALB는 들어오는 트래픽을 여러 컨테이너에 지능적으로 분산시켜 줍니다.</li>
<li><strong>최소한의 운영 오버헤드</strong>: <strong>ECS</strong>는 컨테이너 오케스트레이션 서비스로, 컨테이너의 배포, 네트워킹, 스케일링 등을 AWS가 관리해 줍니다. 특히 <strong>AWS Fargate</strong> 시작 유형을 사용하면 기본 EC2 인스턴스를 관리할 필요가 없어 서버리스 환경처럼 운영 오버헤드를 크게 줄일 수 있습니다.</li>
</ul>
<blockquote>
<p>💡 AWS SAA 시험 팁: '모놀리식 애플리케이션을 마이크로서비스로 전환', '운영 오버헤드 최소화', '확장성'이라는 키워드가 함께 나오면 <strong>컨테이너 서비스(ECS, EKS)</strong>와 <strong>Fargate</strong>를 가장 먼저 떠올리는 것이 좋습니다.</p>
</blockquote>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. AWS Lambda 에서 애플리케이션을 호스팅합니다. 애플리케이션을 Amazon API Gateway 와 통합합니다.</strong> </p>
<ul>
<li><strong>AWS Lambda + Amazon API Gateway</strong>: 이 조합은 서버리스 아키텍처입니다. 기존 모놀리식 애플리케이션의 코드를 Lambda 함수 형식에 맞게 <strong>대대적으로 수정하고 재작성</strong>해야 합니다.</li>
</ul>
<p><strong>B. AWS Amplify를 사용하여 애플리케이션을 호스팅합니다. AWS Lambda와 통합된 Amazon API Gateway API 에 애플리케이션을 연결합니다.</strong> </p>
<ul>
<li><strong>AWS Amplify + Lambda + API Gateway</strong>: Amplify는 주로 프론트엔드 개발 및 배포, 또는 새로운 클라우드 네이티브 애플리케이션을 신속하게 구축하는 데 사용되는 프레임워크입니다. 기존 백엔드 코드가 많은 모놀리식 애플리케이션을 마이그레이션하는 시나리오와는 거리가 멉니다.</li>
</ul>
<p><strong>C. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Auto Scaling 그룹의 EC2 인스턴스를 대상으로 하여 Application Load Balancer를 설정합니다.</strong> </p>
<ul>
<li><strong>Amazon EC2 + Auto Scaling + ALB</strong>: 이 방식은 '리프트 앤 시프트(Lift and Shift)' 마이그레이션에 적합합니다. 애플리케이션을 EC2 가상 서버로 그대로 옮기는 방식이라 코드 재사용성은 높습니다. 하지만 EC2 인스턴스의 운영체제(OS) 패치, 보안 관리, 소프트웨어 설치 등 <strong>직접 관리해야 할 부분이 많아 운영 오버헤드가 가장 높습니다.</strong></li>
</ul>
<h1 id="144">144</h1>
<p>한 회사는 최근 글로벌 전자 상거래 애플리케이션의 데이터 저장소로 Amazon Aurora 를 사용하기 시작했습니다. 대규모 보고서가 실행되면 개발자는 전자상거래 애플리케이션의 성능이 좋지 않다고 보고합니다. Amazon CloudWatch의 지표를 검토한 후 솔루션 설계자는 월별 보고서가 실행될 때 ReadIOPS 및 CPUUtilizalion 지표가 급증하고 있음을 발견했습니다. 가장 비용 효율적인 솔루션은 무엇입니까? </p>
<p><strong>B. 월별 보고를 Aurora 복제본으로 마이그레이션합니다.</strong> </p>
<ul>
<li><strong>Aurora 복제본(Read Replica)</strong>은 읽기 전용 워크로드를 분리하기 위해 만들어진 기능입니다. 현재 문제 상황은 대규모 보고서(읽기 작업)가 실행될 때 기본 데이터베이스(Writer DB)의 <strong>ReadIOPS</strong>와 <strong>CPU 사용률</strong>이 급증하여 전자상거래 애플리케이션(쓰기/읽기 트랜잭션)의 성능을 저하하고 있습니다.<ul>
<li><strong>워크로드 분리:</strong> 보고서 쿼리를 Aurora 복제본으로 보내면, 기본 데이터베이스는 전자상거래 애플리케이션의 트랜잭션 처리에만 집중할 수 있습니다. 이렇게 읽기/쓰기 워크로드를 분리하면 보고서 실행 중에도 메인 애플리케이션의 성능 저하를 막을 수 있습니다.</li>
<li><strong>비용 효율성:</strong> Aurora 복제본을 추가하는 것은 데이터베이스 인스턴스를 수직 확장(Scaling Up)하거나 별도의 데이터 웨어하우스를 구축하는 것보다 훨씬 비용 효율적입니다. 월별 보고서 실행 시에만 부하가 발생하므로, 필요한 시점에만 복제본을 사용하거나 낮은 사양의 복제본을 유지하는 방식으로 비용을 최적화할 수 있습니다.</li>
<li><strong>간단한 구현:</strong> 기존 Aurora 클러스터에 복제본을 추가하고, 보고용 애플리케이션의 데이터베이스 엔드포인트를 복제본의 엔드포인트로 변경하기만 하면 되므로 구현이 간단합니다.</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong></p>
<p><strong>A. 월별 보고를 Amazon Redshift로 마이그레이션합니다.</strong> </p>
<ul>
<li><strong>과도한 솔루션(Overkill):</strong> <strong>Amazon Redshift</strong>는 페타바이트급 데이터 웨어하우스 서비스로, 복잡하고 대규모인 분석 쿼리에 최적화되어 있습니다. 월별 보고서 하나를 위해 Redshift 클러스터를 구축하고, Aurora에서 Redshift로 데이터를 옮기는 ETL(Extract, Transform, Load) 파이프라인을 구성 및 유지하는 것은 <strong>상당한 비용과 복잡성</strong>을 초래합니다. 문제 해결은 가능하지만 '가장 비용 효율적인' 솔루션은 아닙니다.</li>
</ul>
<p><strong>C. Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다.</strong> </p>
<ul>
<li><strong>비용 비효율성:</strong> 데이터베이스 인스턴스 자체를 더 큰 사양으로 업그레이드(수직 확장)하면 보고서 실행 시 부하를 감당할 수는 있습니다. 하지만 이 문제는 <strong>한 달에 한 번</strong> 발생합니다. 보고서를 실행하지 않는 나머지 기간 동안에는 불필요하게 비싼 인스턴스 비용을 계속 지불해야 하므로 매우 비효율적입니다.</li>
</ul>
<p><strong>D. Aurora 인스턴스에서 프로비저닝된 IOPS를 늘립니다.</strong></p>
<ul>
<li><strong>근본적인 해결책이 아님:</strong> 문제의 원인은 <strong>ReadIOPS</strong>뿐만 아니라 <strong>CPU 사용률</strong> 급증도 포함됩니다. IOPS(초당 입출력 작업 수)를 늘리는 것은 스토리지 성능 문제만 일부 해결할 뿐, 보고서 쿼리로 인한 CPU 경합 문제는 해결하지 못합니다.</li>
</ul>
<h1 id="145">145</h1>
<p>회사는 단일 Amazon EC2 온디맨드 인스턴스에서 웹 사이트 분석 애플리케이션을 호스팅합니다. 분석 소프트웨어는 PHP 로 작성되었으며 MySQL 데이터베이스를 사용합니다. 분석 소프트웨어, PHP 를 제공하는 웹 서버 및 데이터베이스 서버는 모두 EC2 인스턴스에서 호스팅됩니다. 응용 프로그램은 바쁜 시간 동안 성능 저하 징후를 보이고 5xx 오류를 표시합니다. 회사는 애플리케이션을 원활하게 확장해야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? </p>
<p><strong>D. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI 를 생성합니다. 시작 템플릿에 AMI 를 적용합니다. 시작 템플릿으로 Auto Scaling 그룹 생성 스팟 집합을 사용하도록 시작 템플릿을 구성합니다. Auto Scaling 그룹에 Application Load Balancer 를 연결합니다.</strong></p>
<ul>
<li><strong>자동 확장성 (Smoothly Scale)</strong>: Auto Scaling Group(ASG)은 트래픽 변화에 따라 EC2 인스턴스 수를 자동으로 늘리거나 줄여줍니다. 이를 통해 사용량이 많은 시간에는 성능 저하 없이 서비스를 제공하고, 사용량이 적을 때는 불필요한 인스턴스를 종료하여 비용을 절감할 수 있습니다. 이는 &quot;원활하게 확장해야 한다&quot;는 핵심 요구사항을 완벽하게 만족시킵니다.</li>
<li><strong>비용 효율성 (Cost-Effective)</strong>: <strong>스팟 인스턴스(Spot Instances)</strong>를 사용하도록 구성하는 것이 결정적인 장점입니다. 스팟 인스턴스는 온디맨드 인스턴스에 비해 최대 90% 저렴한 비용으로 사용할 수 있습니다. 웹 애플리케이션과 같이 상태를 저장하지 않는(stateless) 워크로드는 스팟 인스턴스의 중단에 대비하기 용이하며, Auto Scaling Group과 함께 사용하면 특정 스팟 인스턴스가 중단되더라도 그룹이 자동으로 다른 인스턴스를 시작해주므로 서비스 연속성을 유지하면서 비용을 크게 절감할 수 있습니다.</li>
<li><strong>고가용성 및 성능</strong>:<ul>
<li><strong>Application Load Balancer (ALB)</strong>는 여러 가용 영역(AZ)에 걸쳐 있는 EC2 인스턴스로 트래픽을 지능적으로 분산하고, 비정상 인스턴스를 감지하여 트래픽 전송을 중단시키는 헬스 체크 기능을 제공합니다.</li>
<li>데이터베이스를 <strong>Amazon Aurora</strong>로 마이그레이션하면 기존 MySQL보다 뛰어난 성능과 확장성, 그리고 자동 복제 및 장애 조치 기능을 통해 높은 가용성을 확보할 수 있습니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI 를 생성합니다. AMI 를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. Application Load Balancer 를 사용하여 각 EC2 인스턴스에 로드를 분산합니다.</strong> </p>
<ul>
<li><strong>수동 확장</strong>: 이 솔루션은 EC2 인스턴스를 2개로 고정합니다. 트래픽이 이 2개의 인스턴스가 감당할 수 있는 수준 이상으로 급증하면 결국 다시 성능 저하와 5xx 오류가 발생합니다. <strong>자동으로 확장하는 기능(Auto Scaling)이 없어</strong> &quot;원활하게 확장&quot;이라는 요구사항을 충족하지 못합니다.</li>
</ul>
<p><strong>B. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI 를 생성합니다. AMI 를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. Amazon Route 53 가중 라우팅을 사용하여 두 EC2 인스턴스에 로드를 분산합니다.</strong> </p>
<ul>
<li><strong>부적절한 로드 밸런싱</strong>: <strong>Amazon Route 53</strong>은 DNS 서비스로, IP 주소 레벨에서 트래픽을 분산합니다.</li>
<li><strong>수동 확장</strong>:  <strong>Auto Scaling 기능이 없습니다</strong>.</li>
</ul>
<p><strong>C. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. AWS Lambda 함수를 생성하여 EC2 인스턴스를 중지하고 인스턴스 유형을 변경합니다. CPU 사용률이 75%를 초과할 때 Lambda 함수를 호출하는 Amazon CloudWatch 경보를 생성합니다.</strong> </p>
<ul>
<li><strong>서비스 중단 발생</strong>: 이 방법은 인스턴스 수를 늘리는 <strong>수평 확장(Horizontal Scaling)</strong>이 아닌, 인스턴스의 사양(크기)을 높이는 <strong>수직 확장(Vertical Scaling)</strong>을 제안합니다. EC2 인스턴스 유형을 변경하려면 <strong>인스턴스를 중지(stop)했다가 다시 시작</strong>해야 합니다. 이 과정에서 <strong>서비스 중단(Downtime)이 발생</strong>하므로 &quot;원활하게 확장&quot;이라는 요구사항에 정면으로 위배됩니다. 웹 애플리케이션의 트래픽을 처리하는 중에는 절대 사용할 수 없는 방식입니다.</li>
</ul>
<h1 id="146">146</h1>
<p>회사는 Application Load Balancer 뒤의 Amazon EC2 온디맨드 인스턴스 그룹에서 프로덕션 환경에서 상태 비저장 웹 애플리케이션을 실행합니다. 매일 8 시간 동안 애플리케이션 사용량이 많습니다. 응용 프로그램 사용량은 보통이고 밤새 안정적입니다. 주말에는 애플리케이션 사용량이 적습니다. 이 회사는 애플리케이션의 가용성에 영향을 주지 않으면서 EC2 비용을 최소화하려고 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>B. 기본 사용량 수준에 대해 예약 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 용량에 대해 스팟 인스턴스를 사용합니다.</strong> </p>
<ul>
<li><strong>기준 사용량: 예약 인스턴스 (Reserved Instances) 또는 Savings Plans</strong><ul>
<li>시나리오에서 &quot;밤새 안정적이고 주말에는 사용량이 적지만 꾸준한&quot; 기본 부하(Baseline)가 존재합니다. 이처럼 <strong>예측 가능하고 지속적인 워크로드</strong>에 대해서는 예약 인스턴스(RI)나 Savings Plans를 사용하는 것이 가장 비용 효율적입니다.</li>
</ul>
</li>
<li><strong>추가 용량: 스팟 인스턴스 (Spot Instances)</strong><ul>
<li><strong>역할</strong>: &quot;매일 8시간 동안 사용량이 많은&quot; 피크(Peak) 시간대의 <strong>변동성 있고 추가적인 부하</strong>를 처리하는 데 사용됩니다.</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong></p>
<p><strong>A. 전체 워크로드에 대해 스팟 인스턴스를 사용합니다.</strong> </p>
<ul>
<li>모든 인스턴스를 스팟으로만 구성하면, 스팟 인스턴스 가격이 급등하거나 AWS의 유휴 용량이 부족해질 경우 <strong>모든 인스턴스가 동시에 중단될 위험</strong>이 있습니다.</li>
</ul>
<p><strong>C. 기준 사용 수준에 대해 온디맨드 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 용량에 대해 스팟 인스턴스를 사용합니다.</strong> </p>
<ul>
<li>예측 가능한 <strong>기준 사용량에 대해 온디맨드 인스턴스를 사용하는 것은 예약 인스턴스를 사용하는 것보다 훨씬 비쌉니다.</strong></li>
</ul>
<p><strong>D. 기본 사용량 수준에 대해 전용 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 용량에 대해 온디맨드 인스턴스를 사용합니다.</strong></p>
<ul>
<li><strong>전용 인스턴스(Dedicated Instances)</strong>는 물리적 서버를 단일 고객만 사용하도록 격리하는 옵션으로, 주로 강력한 규제 준수나 특정 라이선스 요구 사항이 있을 때 사용합니다. 일반적인 웹 애플리케이션에는 필요 없으며 <strong>매우 비쌉니다.</strong></li>
</ul>
<h1 id="147">147</h1>
<p>회사는 중요한 애플리케이션에 대한 애플리케이션 로그 파일을 10년 동안 보관해야 합니다. 애플리케이션 팀은 문제 해결을 위해 지난 달의 로그에 정기적으로 액세스하지만 1 개월 이상 된 로그는 거의 액세스하지 않습니다. 애플리케이션은 매월 10TB 이상의 로그를 생성합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 옵션은 무엇입니까? </p>
<p><strong>B. Amazon S3 에 로그를 저장합니다. S3 수명 주기 정책을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive 로 이동합니다.</strong> </p>
<ul>
<li><strong>비용 효율성:</strong> 매월 10TB에 달하는 대용량 로그를 저장하는 데 Amazon S3는 매우 저렴하고 확장성이 뛰어난 솔루션입니다. 특히 첫 한 달간 자주 접근하는 로그를 S3 Standard 클래스에 저장하면 필요할 때 즉시 접근할 수 있습니다.</li>
<li><strong>장기 보관 저장소: S3 Glacier Deep Archive</strong><ul>
<li><strong>최저 비용:</strong> <code>S3 Glacier Deep Archive</code>는 AWS에서 제공하는 가장 저렴한 스토리지 클래스입니다. 거의 접근하지 않지만 10년 동안 의무적으로 보관해야 하는 데이터에 최적화되어 있습니다.</li>
</ul>
</li>
<li><strong>데이터 이동 방법: S3 수명 주기 정책 (Lifecycle Policy)</strong></li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong></p>
<p><strong>A. Amazon S3에 로그를 저장합니다. AWS Backup을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive 로 이동합니다.</strong> </p>
<ul>
<li><strong>잘못된 도구 사용:</strong> <code>AWS Backup</code>은 EC2, RDS, EBS 등 다양한 AWS 서비스의 데이터를 중앙에서 백업하고 복원 정책을 관리하기 위한 서비스입니다. S3 객체의 스토리지 클래스를 변경하는 용도로는 적합하지 않으며, <strong>S3 수명 주기 정책</strong>에 비해 불필요하게 복잡하고 비용이 더 발생할 수 있습니다. S3 내에서의 데이터 이동은 수명 주기 정책이 가장 간단하고 효율적인 방법입니다.</li>
</ul>
<p><strong>C. Amazon CloudWatch Logs 에 로그를 저장합니다. AWS Backup을 사용하여 1개월 이상 된 로그를 S3 Glacier Deep Archive 로 이동합니다.</strong> </p>
<p><strong>D. Amazon CloudWatch Logs 에 로그를 저장합니다. Amazon S3 수명 주기 정책을 사용하여 1 개월 이상 된 로그를 S3 Glacier Deep Archive로 이동합니다.</strong></p>
<ul>
<li><strong>은 초기 저장 비용:</strong> <code>Amazon CloudWatch Logs</code>는 실시간 로그 모니터링, 검색, 분석에 최적화된 서비스이지만, 데이터 수집(Ingestion) 및 저장 비용이 S3보다 훨씬 비쌉니다. 매월 10TB라는 대용량 로그를 CloudWatch Logs에 직접 저장하는 것은 매우 비효율적입니다.</li>
</ul>
<h1 id="148">148</h1>
<p>회사에는 다음 구성 요소를 포함하는 데이터 수집 워크플로가 있습니다.</p>
<ul>
<li>새로운 데이터 전송에 대한 알림을 받는 Amazon Simple Notation Service(Amazon SNS)
주제입니다.</li>
<li>데이터를 처리하고 저장하는 AWS Lambda 함수입니다.
네트워크 연결 문제로 인해 수집 워크플로가 때때로 실패합니다. 장애가 발생하면 회사에서 수동으로 작업을 다시 실행하지 않는 한 해당 데이터가 수집되지 않습니다. 모든 알림이 최종적으로 처리되도록 하려면 솔루션 설계자가 무엇을 해야 합니까?</li>
</ul>
<p><strong>D. Amazon Simple Queue Service(Amazon SQS) 대기열을 장애 시 대상으로 구성합니다. 대기열의 메시지를 처리하도록 Lambda 함수를 수정합니다.</strong></p>
<ul>
<li><strong>데드 레터 큐(Dead-Letter Queue, DLQ)</strong> 패턴</li>
<li>DLQ에 저장된 실패 메시지들은 네트워크 문제가 해결된 후, <strong>별도의 프로세스나 수정된 Lambda 함수를 통해 다시 처리</strong>될 수 있습니다. 이를 통해 수동 개입 없이도 &quot;모든 알림이 최종적으로 처리되도록&quot; 하는 핵심 요구사항을 만족시킬 수 있습니다.</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 여러 가용 영역에 걸쳐 배포할 Lambda 함수를 구성합니다.</strong> </p>
<ul>
<li><strong>잘못된 전제:</strong> AWS Lambda는 사용자가 별도로 구성하지 않아도 <strong>기본적으로 여러 가용 영역(Multi-AZ)에서 자동으로 실행</strong>되는 고가용성 서비스입니다.</li>
</ul>
<p><strong>B. Lambda 함수의 구성을 수정하여 함수에 대한 CPU 및 메모리 할당을 늘립니다.</strong> </p>
<ul>
<li><strong>문제와 무관:</strong> CPU나 메모리 증가는 <strong>처리할 데이터가 너무 많거나 계산이 복잡해서</strong> 함수가 느려지거나 타임아웃될 때 필요한 조치입니다.</li>
</ul>
<p><strong>C. 재시도 횟수와 재시도 간 대기 시간을 모두 늘리도록 SNS 주제의 재시도 전략을 구성합니다.</strong> </p>
<ul>
<li><strong>불완전한 해결책:</strong> 재시도를 늘리면 아주 잠깐의 네트워크 불안정에는 대응할 수 있습니다.</li>
<li><strong>데이터 유실 위험:</strong> 하지만 네트워크 문제가 <strong>설정한 재시도 시간을 초과할 만큼 길어지면, 메시지는 결국 영구적으로 폐기</strong>되어 데이터가 유실됩니다.</li>
</ul>
<h1 id="149">149</h1>
<p>회사에 이벤트 데이터를 생성하는 서비스가 있습니다. 회사는 AWS 를 사용하여 이벤트 데이터를 수신하는 대로 처리하려고 합니다. 데이터는 처리 전반에 걸쳐 유지되어야 하는 특정 순서로 작성됩니다. 회사는 운영 오버헤드를 최소화하는 솔루션을 구현하려고 합니다. 솔루션 설계자는 이를 어떻게 달성해야 합니까? </p>
<p><strong>A. 메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 생성합니다. 대기열의 메시지를 처리하도록 AWS Lambda 함수를 설정합니다.</strong> </p>
<h1 id="150">150</h1>
<p>회사는 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션하고 있습니다. 마이그레이션 설계 요구 사항의 일부로 솔루션 설계자는 인프라 메트릭 경보를 구현해야 합니다. CPU 사용률이 단기간에 50% 이상으로 증가하는 경우 회사는 조치를 취할 필요가 없습니다. 하지만 CPU 사용률이 50% 이상으로 증가하고 디스크의 읽기 IOPS 가 동시에 높다면 회사에서 최대한 빨리 조치를 취해야 합니다. 솔루션 설계자는 또한 오경보를 줄여야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?</p>
<p><strong>A. 가능한 경우 Amazon CloudWatch 복합 경보를 생성합니다.</strong> </p>
<ul>
<li><strong>복합 경보</strong>는 여러 다른 CloudWatch 경보의 상태를 규칙으로 결합하여 하나의 경보를 생성하는 기능입니다. 이 시나리오에 가장 적합한 이유는 다음과 같습니다.<ul>
<li><strong>다중 조건 결합</strong>: <code>CPU 사용률 &gt; 50%</code>에 대한 경보(경보 1)와 <code>디스크 읽기 IOPS &gt; 임계값</code>에 대한 경보(경보 2)를 각각 생성합니다. 그 후, <strong><code>경보 1 AND 경보 2</code></strong> 라는 규칙을 가진 복합 경보를 생성할 수 있습니다.</li>
<li><strong>정확한 경보 및 오경보 감소</strong>: 이 복합 경보는 두 기본 경보가 <strong>동시에 '경보(ALARM)' 상태일 때만</strong> 트리거됩니다. 따라서 CPU 사용률만 일시적으로 급증하는 경우에는 경보가 울리지 않아 오경보를 효과적으로 줄일 수 있습니다. 이는 문제에서 요구하는 사항을 정확히 만족시킵니다.</li>
</ul>
</li>
<li><strong>구현 단계:</strong><ol>
<li>EC2 인스턴스의 <code>CPUUtilization</code> 지표가 50%를 초과할 때 트리거되는 CloudWatch 경보를 생성합니다.</li>
<li>동일한 인스턴스의 <code>DiskReadOps</code> 지표가 특정 임계값을 초과할 때 트리거되는 또 다른 CloudWatch 경보를 생성합니다.</li>
<li>위 두 경보가 모두 <code>ALARM</code> 상태일 때만 트리거되도록 <code>AND</code> 조건으로 복합 경보를 생성합니다.</li>
</ol>
</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. Amazon CloudWatch 대시보드를 생성하여 지표를 시각화하고 문제에 신속하게 대응합니다.</strong> </p>
<ul>
<li>대시보드는 여러 지표를 <strong>시각화</strong>하여 한눈에 모니터링하는 데 매우 유용한 도구입니다. 하지만 대시보드 자체는 특정 조건이 충족되었을 때 자동으로 경보를 발생시키는 기능이 없습니다.</li>
</ul>
<p><strong>C. Amazon CloudWatch Synthetics 카나리아를 생성하여 애플리케이션을 모니터링하고 경보를 발생시킵니다.</strong> </p>
<ul>
<li>Synthetics 카나리아는 웹 페이지, API 엔드포인트 등 <strong>애플리케이션의 외부 동작을 시뮬레이션하고 테스트</strong>하는 데 사용됩니다. 예를 들어 &quot;웹사이트가 정상적으로 응답하는가?&quot; 또는 &quot;로그인 기능이 작동하는가?&quot; 등을 확인합니다. 이 문제에서 요구하는 것은 EC2 인스턴스 내부의 <strong>인프라 지표(CPU, 디스크 I/O)</strong> 이므로 카나리아는 적합한 도구가 아닙니다.</li>
</ul>
<p><strong>D. 가능한 경우 여러 지표 임계값으로 단일 Amazon CloudWatch 지표 경보를 생성합니다.</strong></p>
<ul>
<li>표준 CloudWatch 경보(단일 지표 경보)는 기본적으로 <strong>하나의 지표</strong>만을 기준으로 상태를 평가합니다. 하나의 경보에 여러 지표(CPU와 IOPS)를 결합하여 &quot;AND&quot; 조건으로 평가하는 기능은 없습니다. 따라서 이 선택지는 기술적으로 불가능합니다.</li>
</ul>