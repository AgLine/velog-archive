# SAA-C03 덤프 31~60

게시일: 2025-07-02T13:29:51.879Z
시리즈: Solutions Architect - Associate

---

# 31

AWS에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하기를 원합니다. Amazon RDS DB 인스턴스. Amazon Redshift 클러스터는 태그로 구성됩니다. 회사는 이 검사를 구성하고 운영하는 노력을 최소화하기를 원합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?

**A. AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 리소스를 정의하고 감지합니다.**

**AWS Config**는 AWS 리소스의 구성을 평가, 감사 및 검토할 수 있게 해주는 **완전 관리형 서비스**입니다. 문제의 핵심 요구사항은 "검사를 구성하고 운영하는 노력을 최소화"하는 것입니다.

- **최소 노력:** AWS Config는 `required-tags`와 같은 관리형 규칙(Managed Rules)을 기본으로 제공합니다. 관리자는 코드를 한 줄도 작성할 필요 없이, 콘솔에서 몇 번의 클릭만으로 "모든 EC2, RDS, Redshift 리소스는 'Name', 'Project' 태그를 가져야 한다"와 같은 규칙을 설정할 수 있습니다.
- **자동화된 탐지:** 규칙이 설정되면, AWS Config가 **지속적으로** 리소스 구성을 모니터링합니다. 새로운 리소스가 생성되거나 기존 리소스의 태그가 변경될 때마다 규칙을 위반하는지 자동으로 검사하고, 위반 시 대시보드에 표시하거나 SNS를 통해 알림을 보낼 수 있습니다.
- **목적 부합성:** AWS Config는 바로 이러한 **리소스 구성의 규정 준수(Compliance)를 확인**하기 위해 만들어진 서비스입니다. 문제의 요구사항과 서비스의 목적이 정확히 일치합니다.

**B, C, D가 절적하지 않은 이유**

**B. 비용 탐색기를 사용하여 제대로 태그가 지정되지 않은 리소스를 표시합니다. 해당 리소스에 수동으로 태그를 지정합니다.**

비용 탐색기(Cost Explorer) 사용:

- **목적이 다름:** 비용 탐색기는 이름 그대로 **비용을 분석하고 시각화**하는 도구이지, 리소스 구성의 규정 준수를 실시간으로 감사하는 도구가 아닙니다.
- **수동 작업:** 태그가 없는 리소스를 찾기 위해 매번 리포트를 생성하고 필터링해야 합니다. 이는 "노력 최소화" 원칙에 정면으로 위배되는 **수동적이고 번거로운 작업**입니다.

**C. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행합니다.**

- **과도한 운영 부담:** 이 방법은 태그를 검사하는 코드를 직접 작성해야 할 뿐만 아니라, 그 코드를 실행할 EC2 인스턴스를 프로비저닝하고 직접 관리(OS 패치, 보안 설정 등)해야 합니다. 이는 AWS가 지양하라고 하는 **‘차별화되지 않은 무거운 작업'**의 전형적인 예입니다. 관리형 서비스인 AWS Config가 있는데 굳이 이렇게 복잡하게 구현할 이유가 없습니다.

**D. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. Amazon CloudWatch 를 통해 AWS Lambda 함수를 예약하여 코드를 주기적으로 실행합니다.**

Lambda 함수를 예약하여 주기적으로 코드 실행:

- **불필요한 직접 구현:** C보다는 EC2 인스턴스 관리가 필요 없어 진일보한 방법이지만, 여전히 태그를 검사하는 로직을 담은 **코드를 직접 개발하고 유지보수**해야 합니다.
- **더 나은 대안 존재:** AWS Config에 이미 만들어져 있는 관리형 규칙을 사용하는 것이 Lambda 함수를 직접 작성하는 것보다 훨씬 **노력이 적게 듭니다.**

# 32

개발 팀은 다른 팀이 액세스할 웹사이트를 호스팅해야 합니다. 웹사이트 콘텐츠는 HTML, CSS, 클라이언트 측 JavaScript 및 이미지로 구성됩니다. 웹 사이트 호스팅에 가장 비용 효율적인 방법은 무엇입니까?

HTML, CSS, 클라이언트 측 JavaScript, 이미지로만 구성된 웹사이트는 **정적 웹사이트(Static Website)**입니다

**B. Amazon S3 버킷을 생성하고 거기에서 웹 사이트를 호스팅합니다.**

- **압도적인 비용 효율성:** S3는 서버를 프로비저닝하거나 관리할 필요가 없는 **서버리스(Serverless)** 서비스입니다. 따라서 EC2처럼 24시간 켜두는 데 드는 컴퓨팅 비용이 전혀 없습니다. 오직 데이터를 저장하는 비용(스토리지 비용)과 사용자가 웹사이트에 접속할 때 발생하는 데이터 전송 비용(요청 및 데이터 전송 비용)만 지불하면 되는데, 이 비용은 매우 저렴합니다.
- **간편한 운영:** 서버 관리, 운영 체제 패치, 보안 업데이트 등을 신경 쓸 필요가 전혀 없습니다. 파일을 S3 버킷에 업로드하고 몇 가지 설정을 클릭하는 것만으로 웹사이트를 배포할 수 있습니다.
- **높은 내구성 및 확장성:** S3는 AWS가 전적으로 관리하는 서비스로, 기본적으로 매우 높은 내구성(99.999999999%)과 가용성을 제공하며, 트래픽이 급증해도 별도의 작업 없이 자동으로 확장됩니다.

**A, C, D가 적절하지 않은 이유**

**A. 웹 사이트를 컨테이너화하고 AWS Fargate에서 호스팅합니다.
C. Amazon EC2 인스턴스에 웹 서버를 배포하여 웹 사이트를 호스팅합니다.
D. Express.js 프레임워크를 사용하는 AWS Lambda 대상으로 Application Load Balancer를 구성합니다.**

- **과도한 기능 (Overkill):** Fargate는 컨테이너화된 애플리케이션을 실행하기 위한 서비스입니다. 정적인 파일을 제공하기 위해 웹 서버(예: Nginx)를 컨테이너로 만들고 Fargate에서 실행하는 것은 매우 비효율적입니다. 이는 동적인 애플리케이션 로직이 필요할 때 적합한 솔루션입니다.
- **높은 비용:** 웹 서버(예: Apache, Nginx)를 실행할 EC2 인스턴스를 24시간 내내 켜두어야 합니다. 이는 유휴 시간에도 지속적인 컴퓨팅 비용을 발생시킵니다.
- **관리 부담:** 사용자가 직접 인스턴스의 운영 체제, 보안 패치, 웹 서버 설치 및 설정, 트래픽에 따른 확장/축소 등을 모두 관리해야 합니다. 이는 상당한 운영 부담을 유발합니다.
- **불필요한 복잡성 및 비용:** 이 아키텍처는 동적 요청을 처리하여 서버리스 기반의 애플리케이션을 만들 때 사용됩니다. 정적 파일을 제공하기 위해 ALB와 Lambda를 거치도록 설계하는 것은 매우 복잡하고 불필요한 과정입니다.

# 33

회사는 AWS 에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 이 애플리케이션은 피크 시간에 수십만 명의 사용자에게 서비스를 제공합니다. 이 회사는 수백만 건의 금융 거래 세부 정보를 다른 여러 내부 애플리케이션과 공유할 수 있는 확장 가능한 거의 실시간 솔루션이 필요합니다. 또한 지연 시간이 짧은 검색을 위해 문서 데이터베이스에 저장하기전에 민감한 데이터를 제거하기 위해 트랜잭션을 처리해야 합니다.

**C. 트랜잭션 데이터를 Amazon Kinesis Data Streams 로 스트리밍합니다. AWS Lambda 통합을 사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 Amazon DynamoDB 에 트랜잭션 데이터를 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림의 트랜잭션 데이터를 사용할 수 있습니다.**

- **실시간 스트리밍 및 공유 (Kinesis Data Streams)**:
    - **Amazon Kinesis Data Streams**는 대량의 데이터를 실시간으로 수집하고 처리하기 위한 핵심 서비스입니다.
    - 가장 큰 장점은 **'팬아웃(fan-out)' 기능**입니다. 즉, 하나의 데이터 스트림에 여러 개의 독립적인 소비자(consumer) 애플리케이션을 연결할 수 있습니다. 이를 통해 "여러 내부 애플리케이션과 공유"라는 요구사항을 완벽하게 만족시킵니다. 데이터는 스트림에 보관 기간(기본 24시간) 동안 저장되어 여러 애플리케이션이 각자의 속도로 데이터를 읽어갈 수 있습니다.
- **데이터 처리 (AWS Lambda)**:
    - Kinesis Data Streams와 **AWS Lambda**를 통합하는 것은 표준적인 실시간 데이터 처리 패턴입니다.
    - 스트림에 새로운 데이터 레코드가 들어오면 Lambda 함수를 자동으로 트리거하여 "저장 전 민감 데이터 제거"라는 요구사항을 효율적으로 처리할 수 있습니다. Lambda는 트래픽에 따라 자동 확장되므로 피크 시간에도 안정적인 처리가 가능합니다.
- **데이터 저장 (Amazon DynamoDB)**:
    - **Amazon DynamoDB**는 지연 시간이 매우 짧은 NoSQL 문서 데이터베이스입니다. 처리된 데이터를 저장하고 "낮은 지연 시간의 검색" 요구사항을 충족시키기에 가장 적합한 서비스입니다.

**A, B, D가 적절하지않은이유**

**A. 트랜잭션 데이터를 Amazon DynamoDB 에 저장합니다. 쓰기 시 모든 트랜잭션에서 민감한 데이터를 제거하도록 DynamoDB 에서 규칙을 설정합니다. DynamoDB 스트림을 사용하여 다른 애플리케이션과 트랜잭션 데이터를 공유합니다.**

- **잘못된 처리 순서**: 이 선택지는 "DynamoDB에서 규칙을 설정하여 민감한 데이터를 제거"한다고 설명합니다. 하지만 **DynamoDB에는 데이터를 쓰는 시점(on-write)에 데이터를 변환하거나 특정 필드를 제거하는 기능이 내장되어 있지 않습니다.** 데이터는 일단 원본 그대로 저장된 후에 DynamoDB Streams와 Lambda를 통해 후처리될 수는 있지만, 이는 "저장하기 전에 처리"라는 요구사항에 위배됩니다.

**B. 트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB 및 Amazon S3 에 데이터를 저장합니다. Kinesis Data Firehose 와 AWS Lambda 통합을 사용하여 민감한 데이터를 제거하십시오. 다른 애플리케이션은 Amazon S3 에 저장된 데이터를 사용할 수 있습니다.**

- **잘못된 데이터 공유 방식**: **Amazon Kinesis Data Firehose**는 데이터를 S3, Redshift, OpenSearch 등으로 쉽게 '전달(delivery)'하는 데 특화된 서비스입니다. Kinesis Data Streams처럼 여러 애플리케이션이 실시간으로 스트림 자체를 구독하여 사용하는 방식이 아닙니다. S3에 저장된 데이터를 다른 앱이 사용하는 것은 실시간 스트리밍이 아닌 배치(batch) 방식에 가깝습니다.
- **잘못된 데이터 저장 대상**: Kinesis Data Firehose는 **DynamoDB로 직접 데이터를 전송할 수 없습니다.** Lambda를 이용한 변환은 가능하지만, 최종 목적지로 DynamoDB를 지원하지 않습니다.

**D. 일괄 처리된 트랜잭션 데이터를 Amazon S3 에 파일로 저장합니다. Amazon S3 에서 파일을 업데이트하기 전에 AWS Lambda 를 사용하여 모든 파일을 처리하고 민감한 데이터를 제거하십시오. 그러면 Lambda 함수가 Amazon DynamoDB 에 데이터를 저장합니다. 다른 애플리케이션은 Amazon S3 에 저장된 트랜잭션 파일을 사용할 수 있습니다.**

S3를 이용한 데이터 처리는 '배치(Batch)' 방식에 가깝기 때문에 '거의 실시간(near real-time)' 요구사항을 충족시키지 못하기 때문

**S3 기반 아키텍처가 실시간 처리에 부적합한 이유**

S3는 파일(객체)을 저장하는 서비스이지, 데이터를 실시간으로 흘려보내는 스트리밍 서비스가 아닙니다.

- **처리 단위의 차이**:
    - **S3 (선택지 D)**: 트랜잭션 데이터를 모아서 하나의 **파일(File)로 만들어 S3에 업로드**해야 합니다. Lambda는 파일 업로드가 완료된 후에야 실행됩니다. 이는 개별 트랜잭션이 발생한 시점과 실제 처리되는 시점 사이에 지연이 발생할 수밖에 없는 구조입니다.
    - **Kinesis (선택지 C)**: 트랜잭션이 발생할 때마다 즉시 작은 **레코드(Record) 단위로 스트림에 전송**합니다. Lambda는 이 레코드를 거의 즉시 읽어서 처리합니다.
- **지연 시간(Latency)의 차이**:
    - **S3 방식**: `지연 시간 = 데이터를 파일로 모으는 시간 + S3에 업로드하는 시간 + Lambda가 실행되기까지의 시간` 입니다. 데이터가 충분히 모일 때까지 기다려야 하므로 지연 시간은 **수 초에서 수 분**까지 길어질 수 있습니다.
    - **Kinesis 방식**: 지연 시간은 **일반적으로 1초 미만(sub-second)** 입니다. 데이터가 발생하는 즉시 스트림을 통해 흐르기 때문입니다.
- **아키텍처 목적의 차이**:
    - **S3 → Lambda 패턴**은 이미지 파일이 업로드되면 썸네일을 만들거나, 로그 파일이 주기적으로 저장되면 분석하는 등 **비동기적이고 배치성이 강한 작업**에 매우 적합합니다.
    - **Kinesis → Lambda 패턴**은 금융 거래, IoT 센서 데이터, 클릭 스트림 등 **지속적으로 발생하는 데이터를 지연 없이 처리**해야 하는 실시간 분석 및 응용 프로그램에 최적화되어 있습니다.

# 34

회사는 AWS 에서 다중 계층 애플리케이션을 호스팅합니다. 규정 준수, 거버넌스, 감사 및 보안을 위해 회사는 AWS 리소스의 구성 변경 사항을 추적하고 이러한 리소스에 대한 API 호출 기록을 기록해야 합니다.
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**B. AWS Config 를 사용하여 구성 변경을 추적하고 AWS CloudTrail을 사용하여 API 호출을 기록합니다**

- **AWS Config**: **"내 AWS 리소스가 어떻게 구성되어 있는가?"** 에 대한 답을 주는 서비스입니다.
    - 리소스의 구성(Configuration)을 지속적으로 모니터링하고 기록합니다.
    - 시간에 따른 **구성 변경 내역을 추적**하고, 특정 시점의 구성 상태를 확인할 수 있습니다.
    - 미리 정의된 규칙(Config Rules)을 통해 리소스 구성이 규정을 준수하는지 자동으로 평가할 수 있어 **규정 준수 및 감사**에 필수적입니다.
- **AWS CloudTrail**: **"누가, 언제, 어디서, 무엇을 했는가?"** 에 대한 답을 주는 서비스입니다.
    - AWS 계정에서 발생하는 거의 모든 **API 호출을 기록**하고 로그 파일로 저장합니다.
    - 사용자, 역할(IAM Role), AWS 서비스가 수행한 모든 작업을 추적할 수 있습니다.
    - 보안 분석, 문제 해결, **거버넌스 및 감사**를 위한 중요한 활동 기록을 제공합니다.

**A, C, D가 적절하지 않은 이유**

- **AWS Config** ➡️ 리소스 **구성(설정)**의 변경 내역을 추적 및 감사 (What it looked like)
- **AWS CloudTrail** ➡️ **누가 무엇을 했는지** API 호출(행위)을 기록 및 감사 (Who did what)
- **Amazon CloudWatch** ➡️ 리소스의 **성능과 상태**를 실시간으로 모니터링 및 대응 (How it's doing)
    - CloudWatch의 주된 역할은 **성능 모니터링 및 관찰**입니다. 즉, 리소스의 CPU 사용률 같은 **메트릭(Metrics)**, 애플리케이션 **로그(Logs)**, 특정 이벤트(Events)를 수집하여 알람을 생성하는 데 사용됩니다.

# 35

한 회사가 AWS 클라우드에서 공개 웹 애플리케이션 출시를 준비하고 있습니다. 아키텍처는 Elastic Load Balancer(ELB) 뒤의 VPC 내 Amazon EC2 인스턴스로 구성됩니다. DNS 에는 타사 서비스가 사용됩니다. 
회사의 솔루션 설계자는 대규모 DDoS 공격을 감지하고 보호하기 위한 솔루션을 권장해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**D. AWS Shield Advanced 를 활성화하고 ELB를 할당합니다.** 

- **전문적인 DDoS 방어:** AWS Shield는 DDoS(분산 서비스 거부) 공격으로부터 AWS에서 실행되는 애플리케이션을 보호하는 관리형 서비스입니다. 기본적으로 모든 AWS 고객은 추가 비용 없이 **AWS Shield Standard**의 자동 보호를 받지만, 이는 네트워크 및 전송 계층(계층 3, 4)의 일반적인 공격을 방어합니다. 문제에서 언급된 **대규모(large-scale) 또는 정교한 애플리케이션 계층(계층 7) 공격**에 대해서는 **Shield Advanced**가 필요합니다.
- **보호 대상 지정:** Shield Advanced는 특정 리소스를 지정하여 보호 수준을 높일 수 있습니다. 이 아키텍처에서 외부 트래픽이 가장 먼저 도달하는 관문은 **ELB(Elastic Load Balancer)**입니다. 따라서 ELB를 Shield Advanced의 보호 대상으로 지정하는 것이 가장 효과적인 방법입니다.
- **추가 혜택:** Shield Advanced는 24시간 연중무휴로 운영되는 **AWS DDoS 대응팀(DRT)**의 지원을 받을 수 있고, 공격에 대한 거의 실시간 가시성을 확보하며, DDoS로 인해 발생한 확장 비용을 보호해주는 '비용 보호' 혜택도 제공합니다.

AWS에서 **DDoS 공격 방어**와 관련된 문제가 나오면 가장 먼저 **AWS Shield**를 떠올려야 합니다.

- **일반적인 DDoS 방어:** AWS Shield Standard (자동, 무료)
- **대규모, 정교한 DDoS 방어 및 전문 지원:** **AWS Shield Advanced** (유료, 리소스 지정)

**A, B, C가 적절하지 않은 이유**

**A. Amazon GuardDuty를 활성화합니다.**

- **GuardDuty의 역할:** Amazon GuardDuty는 **위협 탐지 서비스**입니다. AWS 계정 및 워크로드에서 악의적인 활동이나 무단 동작을 지속적으로 모니터링합니다. 예를 들어, 침해된 EC2 인스턴스, 계정 손상 시도 등을 탐지합니다.
- GuardDuty는 DDoS 공격의 징후(예: 비정상적인 트래픽 패턴)를 **탐지**할 수는 있지만, 공격 트래픽을 직접 **차단하거나 완화하는 보호(Protection) 기능은 수행하지 않습니다.** 문제에서는 '보호'까지 요구했으므로 GuardDuty만으로는 부족합니다.

**B. EC2 인스턴스에서 Amazon Inspector를 활성화합니다.**

- **Inspector의 역할:** Amazon Inspector는 **취약점 관리 서비스**입니다. EC2 인스턴스나 컨테이너 이미지의 소프트웨어 취약점 또는 의도치 않은 네트워크 노출을 검사하고 평가합니다.
- Inspector는 서버 **내부의 보안 약점**을 찾는 데 중점을 둡니다. DDoS 공격은 서버 외부에서 대량의 트래픽을 보내 서비스를 마비시키는 공격이므로, 서버 내부의 취약점을 점검하는 Inspector는 이 문제의 해결책이 될 수 없습니다.

**C. AWS Shield 를 활성화하고 여기에 Amazon Route 53을 할당합니다.**

- 가장 결정적인 이유는 문제에서 **'DNS에는 타사 서비스가 사용됩니다'** 라고 명시했기 때문입니다. 이 회사는 Amazon Route 53을 사용하고 있지 않으므로, Route 53을 보호하는 것은 아무런 의미가 없습니다. 설령 Route 53을 사용하더라도, 웹 애플리케이션 자체를 보호하려면 트래픽의 관문인 ELB나 CloudFront를 보호하는 것이 더 직접적이고 효과적입니다.

# 36

회사는 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 AWS 리전의 Amazon S3 버킷에 데이터를 저장합니다. 회사는 AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하여 S3 버킷에 저장된 모든 데이터를 암호화해야 합니다. 두 S3 버킷의 데이터는 동일한 KMS 키로 암호화 및 복호화해야 합니다. 데이터와 키는 두 지역 각각에 저장되어야 합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

**B. 고객 관리형 다중 지역 KMS 키를 생성합니다. 각 리전에서 S3 버킷을 생성합니다. S3 버킷 간의 복제를 구성합니다. 클라이언트 측 암호화와 함께 KMS 키를 사용하도록 애플리케이션을 구성합니다.**

- **'동일한 키' 요구사항 충족**: 문제의 가장 중요한 요구사항은 **두 개의 다른 리전**에 있는 데이터를 **동일한 암호화 키**로 암호화하고 복호화하는 것입니다.
    - 표준 KMS 키는 **리전별 서비스**이므로 한 리전에서 생성된 키는 다른 리전에서 직접 사용할 수 없습니다.
    - **다중 지역 KMS 키(Multi-Region Key)**는 바로 이 문제를 해결하기 위해 설계된 기능입니다. 동일한 키 ID와 키 구성 요소(key material)를 여러 리전에 복제하여, 마치 동일한 키를 여러 리전에서 사용하는 것처럼 동작하게 합니다. 따라서 이 요구사항을 만족시키는 유일한 방법입니다.
- **'고객 관리형 키' 요구사항 충족**: "고객 관리형 다중 지역 KMS 키"를 생성하므로, 사용자가 직접 키를 제어하고 관리해야 한다는 요구사항을 만족합니다.
- **'데이터 복제' 요구사항 충족**: "S3 버킷 간의 복제를 구성"하여 두 리전에 데이터가 모두 저장되도록 합니다.

**A, C, D가 적절하지 않은 이유**

**A. 각 리전에서 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)와 함께 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.**

이 옵션은 SSE-S3(Amazon S3 관리형 암호화 키)를 사용합니다. 이는 AWS가 키를 관리하는 방식이며, 문제에서 요구하는 '고객 관리형 키(Customer-Managed Key)'를 사용해야 한다는 조건에 위배됩니다.

**C. 각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)와 함께 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.**

이 옵션은 '고객 관리형 KMS 키를 생성'하라고 하면서 동시에 **SSE-S3**를 사용하라고 말합니다. 이는 논리적으로 모순되며, A와 마찬가지로 '고객 관리형 키' 요구사항을 충족하지 못합니다.

**D. 각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.**

이 옵션은 "각 리전에서 고객 관리형 KMS 키를 생성"하라고 제안합니다. 이렇게 하면 **리전 A의 키**와 **리전 B의 키**는 이름만 같을 수 있을 뿐, 키 ID와 키 구성 요소가 완전히 다른 **별개의 키**가 됩니다.

# 37

한 회사는 최근 AWS 계정의 Amazon EC2 인스턴스에서 다양한 새로운 워크로드를 출시했습니다. 회사는 인스턴스에 원격으로 안전하게 액세스하고 관리하는 전략을 수립해야 합니다. 회사는 기본 AWS 서비스와 함께 작동하고 AWS Well-Architected 프레임워크를 따르는 반복 가능한 프로세스를 구현해야 합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

**B. 각 기존 인스턴스와 새 인스턴스에 적절한 IAM 역할을 연결합니다. AWS Systems Manager Session Manager 를 사용하여 원격 SSH 세션을 설정합니다.**

**AWS Systems Manager Session Manager**를 사용하는 이 방식이 가장 이상적인 이유는 다음과 같습니다.

- **보안 강화 (Enhanced Security)**
    - **인바운드 포트 불필요:** EC2 인스턴스의 보안 그룹에서 SSH(22)나 RDP(3389) 포트를 열 필요가 전혀 없습니다. 이를 통해 외부 공격에 대한 노출 지점을 원천적으로 차단합니다.
    - **IAM을 통한 중앙 집중식 접근 제어:** SSH 키 파일을 관리하고 배포하는 대신, IAM 역할과 정책을 사용하여 어떤 사용자가 어떤 인스턴스에 접근할 수 있는지 세밀하게 제어할 수 있습니다. 이는 '최소 권한의 원칙'을 따르는 가장 좋은 방법입니다.
    - **감사 및 로깅:** 모든 세션 활동은 AWS CloudTrail에 기록되며, 세션의 입출력 내용을 Amazon S3나 CloudWatch Logs로 스트리밍하여 상세한 감사 로그를 남길 수 있습니다.
- **운영 오버헤드 최소화 (Minimal Operational Overhead)**
    - **배스천 호스트 불필요:** 배스천 호스트를 구축하고, 패치를 적용하고, 모니터링하는 등의 관리 부담이 완전히 사라집니다.
    - **SSH 키 관리 불필요:** SSH 키를 생성, 배포, 교체, 폐기하는 복잡하고 번거로운 작업이 필요 없습니다.
    - **반복 가능하고 확장 가능한 프로세스:** 새 인스턴스를 시작할 때 적절한 IAM 역할만 연결하면 즉시 Session Manager를 통해 관리할 수 있으므로, 워크로드가 늘어나도 관리 방식이 복잡해지지 않습니다.

**A, C, D가 적절하지 않은 이유:** 

**A. EC2 직렬 콘솔을 사용하여 관리를 위해 각 인스턴스의 터미널 인터페이스에 직접 액세스합니다**

- **EC2 직렬 콘솔:** 직렬 콘솔은 인스턴스의 부팅 문제나 네트워크 연결 실패 등 **비상 상황에서 문제를 해결하기 위한 도구**입니다. 일상적인 원격 관리 및 운영 목적으로 사용하기에는 비효율적이며 적합하지 않습니다.

**C. 관리 SSH 키 쌍을 만듭니다. 공개 키를 각 EC2 인스턴스에 로드합니다. 퍼블릭 서브넷에 배스천 호스트를 배포하여 각 인스턴스의 관리를 위한 터널을 제공합니다.**

**배스천 호스트(Bastion Host):** 이는 전통적인 방식이지만 여러 단점이 있습니다.

- **운영 부담:** 배스천 호스트 자체를 지속적으로 패치하고 관리해야 하는 운영 오버헤드가 발생합니다.
- **보안 위험:** 배스천 호스트는 퍼블릭 서브넷에 위치하므로 외부 공격의 대상이 될 수 있습니다. 또한, 여전히 SSH 키를 관리해야 하는 부담이 있습니다.
- **비용 발생:** 배스천 호스트 역할을 할 EC2 인스턴스에 대한 비용이 추가로 발생합니다.

**D. AWS Site-to-Site VPN 연결을 설정합니다. 관리자에게 로컬 온프레미스 머신을 사용하여 VPN 터널에서 SSH 키를 사용하여 인스턴스에 직접 연결하도록 지시합니다.**

- **AWS Site-to-Site VPN:** 이 방법은 단순히 EC2 인스턴스 관리를 위해 사용하기에는 지나치게 복잡하고 비용이 많이 드는 솔루션(Over-engineered)입니다. Site-to-Site VPN은 온프레미스 데이터 센터와 AWS VPC 전체를 연결하는 하이브리드 클라우드 환경을 구축하기 위한 것입니다. 또한 이 방법을 사용하더라도 여전히 SSH 키를 관리해야 하는 문제는 그대로 남습니다.

# 38

회사는 Amazon S3 에서 정적 웹 사이트를 호스팅하고 DNS 에 Amazon Route 53 을 사용하고 있습니다. 웹 사이트는 전 세계적으로 수요가 증가하고 있습니다. 회사는 웹 사이트에 액세스하는 사용자의 대기 시간을 줄여야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

**C. S3 버킷 앞에 Amazon CloudFront 배포를 추가합니다. CloudFront 배포를 가리키도록 Route 53 항목을 편집합니다.**

**Amazon CloudFront**는 AWS의 **CDN(콘텐츠 전송 네트워크)** 서비스입니다. 이 서비스의 핵심 목표는 전 세계 사용자에게 콘텐츠(웹사이트, 동영상, API 등)를 빠르고 안정적으로 제공하는 것입니다.

- **지연 시간 감소 (Low Latency)**: CloudFront는 전 세계에 분산된 수백 개의 **엣지 로케이션(Edge Location)**을 가지고 있습니다. 정적 웹사이트(HTML, CSS, JS, 이미지 파일 등)를 CloudFront를 통해 배포하면, 이 파일들은 원본 S3 버킷에서 복사되어 전 세계 엣지 로케이션에 **캐싱(Caching)**됩니다. 사용자가 웹사이트에 접속하면, 가장 가까운 엣지 로케이션에서 캐시된 콘텐츠를 직접 받게 됩니다. 이로 인해 데이터가 이동하는 물리적 거리가 획기적으로 줄어들어 대기 시간이 크게 감소합니다.
- **비용 효율성 (Cost-Effectiveness)**:
    - **데이터 전송 비용 절감**: 일반적으로 S3에서 인터넷으로 직접 데이터를 전송하는 비용보다 CloudFront 엣지 로케이션에서 인터넷으로 데이터를 전송하는 비용이 더 저렴합니다.
    - **Origin 부하 감소**: 사용자의 요청 대부분을 엣지 로케이션의 캐시가 처리하므로, 원본 S3 버킷으로 가는 요청(GET 요청)이 크게 줄어듭니다. 이는 S3 요청 비용을 절감하는 효과도 가져옵니다.
- **간단한 통합**: S3 버킷을 원본(Origin)으로 설정하여 CloudFront 배포를 생성하고, Route 53에서 기존의 S3 엔드포인트 대신 CloudFront 배포 도메인 이름을 가리키도록 레코드를 수정하기만 하면 되므로 구현이 매우 간단합니다.

**A, B, D가 적절하지 않은 이유**

**A. 웹 사이트가 포함된 S3 버킷을 모든 AWS 리전에 복제합니다. Route 53 지리적 위치 라우팅 항목을 추가합니다.**

이 방법도 기술적으로는 지연 시간을 줄일 수 있지만, **비용과 관리 복잡성** 측면에서 비효율적입니다.

- **높은 비용**: 모든 리전에 S3 버킷을 만들고 데이터를 복제하면, 스토리지 비용이 리전 수만큼 배가 됩니다. 또한, 리전 간 데이터를 복제할 때마다 **리전 간 데이터 전송 비용**이 발생합니다.
- **관리의 어려움**: 웹사이트 콘텐츠가 업데이트될 때마다 모든 리전의 버킷에 동기화되었는지 확인해야 하는 등 관리 부담이 매우 큽니다.
- **CloudFront와의 비교**: CloudFront는 수백 개의 엣지 로케이션을 사용하지만, 이 방식은 고작해야 십여 개의 리전만 사용할 수 있어 지연 시간 감소 효과도 제한적입니다.

**B. AWS Global Accelerator 에서 액셀러레이터를 프로비저닝합니다.**

- **Global Accelerator의 용도**: 이 서비스는 TCP/UDP 기반의 **동적 트래픽**(예: 게임, VoIP, 상태 유지가 필요한 애플리케이션)을 AWS 글로벌 네트워크를 통해 최적의 경로로 라우팅하여 성능을 개선하는 데 특화되어 있습니다. 정적 콘텐츠를 캐싱하는 기능이 없습니다.

**D. 버킷에서 S3 Transfer Acceleration 을 활성화합니다.**

- **S3 Transfer Acceleration의 용도**: 이 기능은 주로 전 세계 사용자가 S3 버킷으로 **대용량 파일을 빠르게 업로드/다운로드**할 때 사용됩니다. CloudFront 엣지 네트워크를 활용하여 S3 버킷과의 데이터 전송 경로를 최적화합니다.

# 39

회사는 웹 사이트에서 검색 가능한 항목 저장소를 유지 관리합니다. 데이터는 천만 개 이상의 행이 포함된 Amazon RDS for MySQL 데이터베이스 테이블에 저장됩니다. 데이터베이스에는 2TB 의 범용 SSD 스토리지가 있습니다. 회사 웹 사이트를 통해 이 데이터에 대한 수백만 건의 업데이트가 매일 있습니다.
이 회사는 일부 삽입 작업이 10 초 이상 걸리는 것을 확인했습니다. 회사는 데이터베이스 스토리지 성능이 문제라고 판단했습니다. 이 성능 문제를 해결하는 솔루션은 무엇입니까?

**A. 스토리지 유형을 프로비저닝된 IOPS SSD로 변경합니다.**

- **범용 SSD (General Purpose SSD, gp2/gp3):** 이 스토리지 유형은 비용 효율적이며, 기본 성능과 함께 '버스트(Burst)' 기능을 제공합니다. 즉, 평소에는 정해진 성능을 내다가 짧은 시간 동안 급증하는 트래픽을 처리할 수 있도록 I/O 크레딧을 사용해 성능을 순간적으로 높입니다. 하지만 문제의 시나리오처럼 **지속적으로 높은 I/O가 발생하면 I/O 크레딧이 모두 소진**되고, 결국 스토리지 성능이 기본 수준으로 크게 저하됩니다. 이로 인해 `INSERT`와 같은 쓰기 작업이 10초 이상 걸리는 병목 현상이 발생할 수 있습니다.
- **프로비저닝된 IOPS SSD (Provisioned IOPS SSD, io1/io2):** 이 유형은 **일관되고 예측 가능한 고성능**이 필요한 I/O 집약적인 워크로드(특히 대규모 관계형 데이터베이스)를 위해 설계되었습니다. 사용자가 필요한 IOPS(초당 입출력 작업 수)를 직접 지정하므로, 버스트 크레딧에 의존하지 않고 항상 보장된 성능을 제공합니다.

**크레딧 시스템**은 **"평소에는 사용량이 적고 가끔씩 바쁜"** 워크로드(예: 개발 서버, 소규모 웹사이트)에 매우 비용 효율적입니다.

**B, C, D가 적절하지 않은 이유**

**B. DB 인스턴스를 메모리 최적화 인스턴스 클래스로 변경합니다:**

- 메모리가 많아지면 더 많은 데이터를 캐시에 올려놓을 수 있어 디스크 I/O를 줄여주므로 성능 향상에 도움이 될 수 있습니다. 하지만 문제에서 이미 '스토리지 성능'이 원인으로 지목되었고, 수백만 건의 '업데이트(쓰기)'가 발생하므로 근본적인 스토리지 I/O 처리량을 늘리는 것이 우선입니다. 메모리 증설은 근본적인 해결책이 아닐 수 있습니다.

**C. DB 인스턴스를 버스트 가능한 성능 인스턴스 클래스로 변경합니다:**

- 버스트 가능 인스턴스(T 시리즈)는 CPU 사용량이 평소에는 낮다가 가끔 급증하는 워크로드에 적합합니다. 지속적으로 높은 트래픽이 발생하는 데이터베이스에는 부적합하며, 오히려 CPU 크레딧이 고갈되어 성능이 더 나빠질 수 있습니다.

**D. MySQL 기본 비동기 복제로 다중 AZ RDS 읽기 전용 복제본을 활성화합니다:**

- 읽기 전용 복제본(Read Replica)은 **읽기(SELECT) 트래픽을 분산** 하여 데이터베이스의 읽기 성능을 확장하는 데 사용됩니다. 이 문제에서는 **쓰기(INSERT) 작업의 지연**이 문제이므로, 읽기 전용 복제본은 해결책이 될 수 없습니다. 다중 AZ(Multi-AZ)는 고가용성 및 장애 조치를 위한 기능이지 성능 향상이 주 목적이 아닙니다.

# 40

회사에는 매일 1TB 의 상태 알림을 집합적으로 생성하는 수천 개의 엣지 장치가 있습니다. 각 경고의 크기는 약 2KB 입니다. 솔루션 설계자는 향후 분석을 위해 경고를 수집하고 저장하는 솔루션을 구현해야 합니다. 회사는 고가용성 솔루션을 원합니다. 그러나 회사는 비용을 최소화해야 하며 추가 인프라 관리를 원하지 않습니다. 또한 회사는 즉각적인 분석을 위해 14 일 동안의 데이터를 유지하고 14일이 지난 데이터를 보관하기를 원합니다. 이러한 요구 사항을 충족하는 가장 운영 효율성이 높은 솔루션은 무엇입니까?

**A. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon S3 버킷에 알림을 전달하도록 Kinesis Data Firehose 스트림을 구성합니다. 14일 후에 데이터를 Amazon S3 Glacier 로 전환하도록 S3 수명 주기 구성을 설정합니다.**

- **데이터 수집 (Kinesis Data Firehose):**
    - **관리형 서비스:** 수천 개의 엣지 장치에서 발생하는 대규모 스트리밍 데이터(일일 1TB)를 수집하기 위해 서버를 직접 관리할 필요가 없는 완전 관리형 서비스입니다. 이는 "추가 인프라 관리를 원하지 않음"이라는 요구사항을 완벽하게 충족합니다.
    - **고가용성 및 확장성:** Firehose는 데이터 볼륨에 따라 자동으로 확장되며, 기본적으로 여러 가용 영역에 걸쳐 데이터를 복제하여 고가용성을 보장합니다.
    - **간편한 통합:** 수집한 데이터를 Amazon S3, Redshift, OpenSearch 등 다른 AWS 서비스로 직접 전송하도록 간단하게 구성할 수 있습니다.
- **데이터 저장 및 아카이빙 (Amazon S3 및 S3 Glacier):**
    - **비용 효율적인 저장:** Amazon S3는 내구성이 뛰어나고 저렴한 객체 스토리지입니다. Firehose를 통해 데이터를 S3에 저장하는 것은 매우 일반적이고 비용 효율적인 패턴입니다.
    - **자동화된 데이터 수명 주기 관리:** "14일 동안 즉각적인 분석, 이후 데이터는 보관"이라는 요구사항은 **S3 수명 주기 정책(Lifecycle Configuration)을 통해 완벽하게 자동화**할 수 있습니다. S3 Standard 클래스에 14일간 데이터를 보관하다가(즉시 접근 가능), 14일이 지나면 훨씬 저렴한 아카이브 스토리지인 S3 Glacier로 자동으로 이동시킬 수 있습니다. 이 과정은 수동 개입이 전혀 필요 없어 운영 효율성이 매우 높습니다.

**B, C, D가 적절하지 않은 이유**

**B. 두 가용 영역에서 Amazon EC2 인스턴스를 시작하고 Elastic Load Balancer 뒤에 배치하여 알림을 수집합니다. Amazon S3 버킷에 경고를 저장할 EC2 인스턴스에 대한 스크립트를 생성합니다. 14 일 후에 데이터를 Amazon S3 Glacier 로 전환하도록 S3 수명 주기 구성을 설정합니다.**

- EC2와 ELB를 이용한 수집
    - **인프라 관리 부담:** 이 솔루션은 Elastic Load Balancer(ELB) 뒤에 Amazon EC2 인스턴스를 직접 배포해야 합니다. 이는 EC2 인스턴스의 OS 패치, 보안 관리, 오토 스케일링 구성, 애플리케이션 배포 및 관리 등 상당한 운영 오버헤드를 발생시킵니다. "추가 인프라 관리를 원하지 않는다"는 핵심 요구사항에 정면으로 위배됩니다.
    - **운영 비효율성:** 데이터 수집 로직(스크립트)을 직접 개발하고 EC2에 배포 및 유지보수해야 하므로 A의 Kinesis Firehose 방식에 비해 운영 효율성이 현저히 떨어집니다.

**C. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 알림을 전달하도록 Kinesis Data Firehose 스트림을 구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터를 설정하여 매일 수동 스냅샷을 만들고 클러스터에서 14 일이 지난 데이터를 삭제합니다.**

- Kinesis Data Firehose를 OpenSearch로 전송
    - **비용 문제:** Amazon OpenSearch Service(구 Elasticsearch Service)는 실시간 검색 및 대시보드와 같은 대화형 분석에 최적화된 서비스입니다. 단순히 데이터를 저장하고 나중에 분석하기 위한 용도로 일일 1TB의 원본 데이터를 모두 저장하기에는 S3에 비해 비용이 훨씬 비쌉니다.
    - **운영 비효율성:** "매일 수동 스냅샷 생성"은 자동화되지 않은 프로세스로 운영 효율성이 떨어집니다. 또한 스냅샷은 백업 및 복구 용도이지, S3 Glacier처럼 비용 효율적인 장기 보관(Archiving)을 위한 솔루션이 아닙니다. 14일이 지난 데이터를 클러스터에서 삭제하면, 해당 데이터를 다시 분석하려면 스냅샷을 복원해야 하는 복잡한 과정을 거쳐야 합니다.

**D. Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 생성하여 알림을 수집하고 메시지 보존 기간을 14 일로 설정합니다. SQS 대기열을 폴링하고, 메시지의 수명을 확인하고, 필요에 따라 메시지 데이터를 분석하도록 소비자를 구성합니다. 메시지가 14일이 지난 경우 소비자는 메시지를 Amazon S3 버킷에 복사하고 SQS 대기열에서 메시지를 삭제해야 합니다.**

- **운영 복잡성:** Amazon SQS는 메시지 대기열 서비스로 디커플링에 유용하지만, 이 시나리오에서는 데이터 처리 로직이 매우 복잡해집니다.
    - 소비자(Consumer) 애플리케이션을 별도로 개발하고 관리해야 합니다. (e.g., Lambda, EC2)
    - 이 소비자는 지속적으로 SQS 대기열을 폴링(Polling)해야 합니다.
    - 각 메시지의 보관 기간을 확인하고, 14일이 지난 메시지를 S3로 복사한 후 대기열에서 삭제하는 복잡한 로직을 직접 구현해야 합니다.
- **비효율적인 아키텍처:** A 안은 간단한 설정만으로 가능한 일을 D 안은 복잡한 사용자 지정 코드를 통해 구현하려고 합니다. 이는 "가장 운영 효율성이 높은 솔루션"이라는 요구사항에 맞지 않습니다. SQS의 최대 메시지 보존 기간은 14일이므로, 14일이 되기 직전에 소비자가 처리하지 못하면 데이터가 유실될 위험도 있습니다.

# 41

회사의 애플리케이션은 데이터 수집을 위해 여러 SaaS(Software-as-a-Service) 소스와 통합됩니다. 이 회사는 Amazon EC2 인스턴스를 실행하여 데이터를 수신하고 분석을 위해 데이터를 Amazon S3 버킷에 업로드합니다. 데이터를 수신하고 업로드하는 동일한 EC2 인스턴스도 업로드가 완료되면 사용자에게 알림을 보냅니다. 회사는 느린 응용 프로그램 성능을 발견했으며 가능한 한 성능을 개선하려고 합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

**B. Amazon AppFlow 흐름을 생성하여 각 SaaS 소스와 S3 버킷 간에 데이터를 전송합니다. S3 버킷에 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 S3 이벤트 알림을 구성합니다.**

- **최소한의 운영 오버헤드 (가장 중요한 이유):**
    - **Amazon AppFlow**는 SaaS 애플리케이션과 AWS 서비스 간의 데이터 전송을 자동화하는 **완전 관리형(Fully Managed) 서비스**입니다.
    - EC2 인스턴스, 컨테이너, Auto Scaling 그룹 등을 전혀 관리할 필요가 없습니다. 코드를 작성하거나 서버를 패치하고 확장하는 등의 운영 부담이 **전혀 없습니다.**
    - 단순히 콘솔에서 몇 번의 클릭으로 소스(SaaS)와 대상(S3)을 연결하는 '흐름(Flow)'만 설정하면 됩니다. 이는 '최소한의 운영 오버헤드'라는 요구사항에 가장 부합합니다.

**성능 개선 및 아키텍처 디커플링:**

- 기존에는 EC2 인스턴스가 데이터 수집, 처리, 업로드, 알림 발송까지 모든 것을 담당하는 **강한 결합(Tightly Coupled)** 구조였습니다.
- B 솔루션은 이 기능들을 명확하게 분리(디커플링)합니다.
    - **데이터 전송:** Amazon AppFlow가 전담합니다. AWS가 관리하는 확장성 높은 인프라를 사용하므로 성능이 보장됩니다.
    - **데이터 저장:** Amazon S3가 담당합니다.
    - **알림 발송:** S3 이벤트 알림과 Amazon SNS가 담당합니다. 데이터가 S3에 업로드되면 자동으로 이벤트가 발생하여 SNS로 알림을 보냅니다. 이는 **이벤트 기반 아키텍처(Event-Driven Architecture)**의 모범 사례입니다.
- 이렇게 각 작업을 가장 잘 수행할 수 있는 전문 관리형 서비스에 맡김으로써 전체적인 성능과 안정성이 크게 향상됩니다.

**A, C, D가 적절하지 않은 이유:**

**A. EC2 인스턴스가 확장할 수 있도록 Auto Scaling 그룹을 생성합니다. S3 버킷에 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 S3 이벤트 알림을 구성합니다.**

**C. 각 SaaS 소스에 대해 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 출력 데이터를 보냅니다. S3 버킷을 규칙의 대상으로 구성합니다. S3 버킷에 업로드가 완료되면 이벤트를 전송하는 두 번째 EventBridge(Cloud Watch Events) 규칙을 생성합니다. Amazon Simple Notification Service(Amazon SNS) 주제를 두 번째 규칙의대상으로 구성합니다.**

**D. EC2 인스턴스 대신 사용할 Docker 컨테이너를 생성합니다. Amazon Elastic Container Service (Amazon ECS)에서 컨테이너화된 애플리케이션을 호스팅합니다. S3 버킷에 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 Amazon CloudWatch Container Insights 를 구성합니다.**

- 이 문제는 AWS 클라우드의 핵심 가치인 **"관리 부담이 적은 솔루션을 우선적으로 고려하라"**는 원칙을 잘 보여줍니다. EC2나 컨테이너로 직접 구현하기 전에, 해당 작업을 위해 특별히 설계된 **완전 관리형 서비스(Amazon AppFlow)**가 있는지 먼저 검토해야 합니다.

# 42

회사는 단일 VPC 의 Amazon EC2 인스턴스에서 고가용성 이미지 처리 애플리케이션을 실행합니다. EC2 인스턴스는 여러 가용 영역의 여러 서브넷 내에서 실행됩니다. EC2 인스턴스는 서로 통신하지 않습니다. 그러나 EC2 인스턴스는 Amazon S3 에서 이미지를 다운로드하고 단일 NAT 게이트웨이를 통해 Amazon S3 에 이미지를 업로드합니다. 회사는 데이터 전송 요금에 대해 우려하고 있습니다.
회사가 지역 데이터 전송 요금을 피할 수 있는 가장 비용 효율적인 방법은 무엇입니까?

**C. Amazon S3용 게이트웨이 VPC 엔드포인트를 배포합니다.** 

- AWS 내부 사설망으로 라우팅하여 **NAT 게이트웨이 비용과 가용 영역(AZ) 간 데이터 전송 비용을 모두 제거**하는 가장 비용 효율적인 방법이기 때문입니다.
- S3 게이트웨이 엔드포인트(Gateway VPC Endpoint)의 해결책
    
    S3 게이트웨이 엔드포인트는 VPC 내의 EC2 인스턴스가 인터넷, NAT 게이트웨이, VPN 연결 등을 거치지 않고 **AWS 내부 네트워크를 통해 S3에 비공개로 직접 연결**할 수 있도록 해주는 기능입니다.
    
    - **비용 효율성:**
        - **엔드포인트 자체 비용 없음:** S3 게이트웨이 엔드포인트는 생성 및 사용에 대한 시간당 요금이나 데이터 처리 요금이 **없습니다(무료)**.
        - **NAT 게이트웨이 비용 절감:** S3로 향하는 트래픽이 더 이상 NAT 게이트웨이를 통과하지 않으므로, 해당 트래픽에 대한 **NAT 게이트웨이 데이터 처리 비용이 발생하지 않습니다.**
        - **AZ 간 데이터 전송 비용 없음:** 트래픽이 AWS 백본 네트워크를 통해 S3로 직접 라우팅되므로, **엔드포인트를 사용한 S3 통신에는 AZ 간 데이터 전송 요금이 부과되지 않습니다.**
    - **아키텍처 변경:**
        - 엔드포인트를 생성하고 VPC의 라우팅 테이블에 S3로 가는 트래픽을 이 엔드포인트로 향하도록 경로를 추가하기만 하면 됩니다.
        - 트래픽 경로는 `EC2(모든 AZ) -> S3 게이트웨이 엔드포인트 -> S3`로 변경되어 매우 효율적이고 안전해집니다.

**A, B, D가 적절하지 않은 이유**

**A. 각 가용 영역에서 NAT 게이트웨이를 시작합니다.**

- 이 방법은 AZ 간 데이터 전송 요금 문제(EC2 -> NAT 게이트웨이)는 해결할 수 있습니다. 각 AZ의 EC2가 동일한 AZ 내의 NAT 게이트웨이를 사용하게 되기 때문입니다. S3는 해결불가능
- **비용 증가:** NAT 게이트웨이는 개수만큼 시간당 요금이 부과됩니다. 여러 AZ에 각각 NAT 게이트웨이를 두면 고정 비용이 크게 증가합니다.
- **근본 문제 미해결:** S3 트래픽은 여전히 NAT 게이트웨이를 통과하므로, **NAT 게이트웨이 데이터 처리 비용은 계속 발생**합니다. 따라서 비용 효율적이지 않습니다.

**B. NAT 게이트웨이를 NAT 인스턴스로 교체합니다.**

- NAT 인스턴스는 사용자가 직접 관리하는 EC2 인스턴스로, NAT 게이트웨이의 대안이 될 수 있습니다.
- **동일한 문제 발생:** 단일 NAT 인스턴스를 사용하면 여전히 AZ 간 데이터 전송 비용이 발생합니다.
- **근본 문제 미해결:** 트래픽은 여전히 인터넷을 통해 S3로 나가므로 근본적인 데이터 전송 경로가 바뀌지 않습니다. NAT 인스턴스의 데이터 전송 비용이 발생합니다.
- **관리 부담:** NAT 인스턴스는 패치, 업데이트, 고가용성 구성 등 사용자가 직접 관리해야 하는 부담이 있습니다.
- 비용 효율성이 NAT 게이트웨이보다 나을 수는 있지만(작은 인스턴스 사용 시), S3 게이트웨이 엔드포인트의 '무료'라는 장점에는 비할 수 없습니다.

D. EC2 인스턴스를 실행할 EC2 전용 호스트를 프로비저닝합니다.

- EC2 전용 호스트(Dedicated Host)는 사용자 전용 물리 서버를 제공하는 서비스입니다.
- **관련성 없음:** 이 옵션은 소프트웨어 라이선스 규정 준수나 특정 규제 요건을 충족하기 위해 사용됩니다. **네트워크 트래픽 경로와 데이터 전송 요금과는 전혀 관련이 없습니다.** 문제의 본질을 해결하지 못하는, 완전히 동떨어진 보기입니다.

# 43

회사에 Amazon S3 에 백업되는 시간에 민감한 대량의 데이터를 생성하는 온프레미스 애플리케이션이 있습니다. 애플리케이션이 성장했고 인터넷 대역폭 제한에 대한 사용자 불만이 있습니다. 솔루션 설계자는 Amazon S3 에 대한 적시 백업을 허용하고 내부 사용자의 인터넷 연결에 미치는 영향을 최소화하는 장기 솔루션을 설계해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

**B. 새 AWS Direct Connect 연결을 설정하고 이 새 연결을 통해 백업 트래픽을 직접 연결합니다.**

- **AWS Direct Connect**는 온프레미스 데이터 센터에서 AWS로의 **전용 프라이빗 네트워크 연결**을 설정하는 서비스입니다. 이 방식이 정답인 이유는 다음과 같습니다.
    - **인터넷 대역폭 문제 해결**: Direct Connect는 회사의 기존 공용 인터넷 회선과 완전히 분리된 별도의 전용 회선을 사용합니다. 따라서 대용량 백업 트래픽이 이 전용선을 통해 S3로 전송되는 동안, 내부 사용자들은 기존 인터넷을 아무런 속도 저하 없이 사용할 수 있습니다. 문제의 핵심 요구사항인 '내부 사용자의 인터넷 연결에 미치는 영향을 최소화'를 완벽하게 충족합니다.
    - **안정적이고 예측 가능한 성능**: 공용 인터넷은 트래픽 양에 따라 성능이 변동될 수 있지만, Direct Connect는 일관된 처리량과 낮은 지연 시간(latency)을 보장합니다. 이는 '시간에 민감한' 대량의 데이터를 안정적으로 백업해야 하는 요구사항에 매우 적합합니다.
    - **장기적인 솔루션**: Direct Connect는 한번 설정해두면 지속적으로 사용할 수 있는 견고하고 장기적인 하이브리드 클라우드 연결 솔루션입니다.

**A, C, D가 적절하지 않은 이유**

**A. AWS VPN 연결을 설정하고 VPC 게이트웨이 엔드포인트를 통해 모든 트래픽을 프록시합니다.**

- **근본적인 문제를 해결하지 못함**: AWS Site-to-Site VPN은 암호화된 터널을 제공하여 보안을 강화하지만, 데이터 전송 자체는 결국 회사의 **기존 공용 인터넷 회선**을 통해 이루어집니다. 따라서 VPN을 사용하더라도 대용량 백업은 여전히 내부 사용자와 동일한 인터넷 대역폭을 놓고 경쟁하게 되므로, 사용자들의 인터넷 속도 저하 문제는 해결되지 않습니다.
- **VPC 게이트웨이 엔드포인트의 오용**: VPC 게이트웨이 엔드포인트는 VPC *내의* 리소스(예: EC2 인스턴스)가 S3에 접근할 때 인터넷을 거치지 않게 해주는 기능입니다. 온프레미스 애플리케이션이 이 엔드포인트를 직접 사용할 수는 없습니다. (프록시 서버를 VPC 내에 두는 복잡한 구성을 할 수는 있지만, 그래도 VPN 트래픽은 공용 인터넷을 사용합니다.)

**C. 매일 AWS Snowball 디바이스를 주문합니다. Snowball 디바이스에 데이터를 로드하고 디바이스를 매일 AWS로 반환합니다.**

- **'시간에 민감한' 요구사항 위배**: AWS Snowball은 물리적인 스토리지 디바이스를 배송받아 데이터를 복사한 후, 다시 AWS로 배송하는 방식입니다. 이 과정은 주문, 배송, 데이터 복사, 반송, AWS 데이터 센터 업로드까지 며칠 이상이 소요됩니다. '시간에 민감한(time-sensitive)' 데이터를 '적시에(timely)' 백업해야 한다는 요구사항을 전혀 충족시키지 못합니다.
- **비현실적인 운영**: 매일 대량의 데이터를 백업하기 위해 매일 Snowball을 주문하고 배송하는 것은 운영상 매우 비효율적이고 비현실적입니다. Snowball은 보통 페타바이트(PB)급의 대규모 데이터를 한 번에 마이그레이션할 때 사용하는 솔루션입니다.

**D. AWS Management 콘솔을 통해 지원 티켓을 제출합니다. 계정에서 S3 서비스 제한 제거를 요청합니다.** 

- **문제의 원인 오판**: 이 문제의 병목 현상(bottleneck)은 AWS의 S3 서비스 자체에 있는 것이 아닙니다. S3는 거의 무제한의 처리량을 감당할 수 있도록 설계되어 있습니다. 문제의 원인은 데이터를 AWS로 보내는 회사 **자체의 인터넷 회선 대역폭**이 부족한 것입니다.
- **효과 없는 조치**: 따라서 AWS 측의 S3 서비스 제한을 해제해달라고 요청하더라도, 데이터를 보내는 통로(인터넷 회선)가 좁기 때문에 문제 해결에는 아무런 도움이 되지 않습니다.

# 44

회사에 중요한 데이터가 포함된 Amazon S3 버킷이 있습니다. 회사는 우발적인 삭제로부터 데이터를 보호 야 합니다.이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 취해야 합니까?

**A. S3 버킷에서 버전 관리를 활성화합니다. (Enable Versioning)**

- 사용자가 객체를 **삭제**하면, 실제 데이터가 사라지는 것이 아니라 '삭제 마커(Delete Marker)'라는 표시가 최신 버전으로 추가됩니다.
- 사용자에게는 객체가 삭제된 것처럼 보이지만, 실제로는 이전 데이터 버전이 그대로 저장되어 있어 언제든지 복원할 수 있습니다.
- 실수로 객체를 **덮어쓰더라도** 새로운 내용이 최신 버전으로 추가될 뿐, 이전 버전은 그대로 남아있어 원상 복구가 가능합니다.

**B. S3 버킷에서 MFA 삭제를 활성화합니다. (Enable MFA Delete)**

MFA(Multi-Factor Authentication) 삭제는 버킷의 특정 작업을 수행할 때, 일반적인 자격 증명(Access Key, Secret Key) 외에 MFA 디바이스의 인증 코드(일회용 비밀번호)를 추가로 요구하는 기능입니다.

**C, D, E가 적절하지 않은 이유**

**C. S3 버킷에 버킷 정책을 생성합니다.**

- **목적:** 버킷 정책은 '누가(Principal) 무엇을(Action) 할 수 있는지'를 정의하는 **접근 제어(Access Control)** 수단입니다. 예를 들어, 특정 IP 주소에서만 접근을 허용하거나 특정 사용자에게 삭제 권한(`s3:DeleteObject`)을 부여하지 않을 수 있습니다.
- 이 방법은 '권한이 없는' 사용자의 삭제를 막을 수는 있지만, '권한을 가진' 사용자의 '실수'를 막아주지는 못합니다. 정당한 삭제 권한을 가진 개발자가 실수로 중요한 파일을 삭제하는 상황은 버킷 정책만으로는 방지할 수 없으며, 삭제된 데이터를 복구할 수도 없습니다.

**D. S3 버킷에서 기본 암호화를 활성화합니다.**

- **목적 :** S3 기본 암호화는 버킷에 업로드되는 모든 객체를 자동으로 암호화하여 **저장된 데이터(Data at Rest)를 보호**하는 기능입니다. 누군가 물리적인 스토리지에 접근하더라도 데이터를 읽을 수 없게 만듭니다.
- 암호화는 데이터의 **기밀성(Confidentiality)**을 위한 것이지, 삭제 방지와는 전혀 관련이 없습니다. 암호화된 객체도 권한만 있으면 얼마든지 삭제할 수 있습니다.

**E. S3 버킷의 객체에 대한 수명 주기 정책을 생성합니다.**

- **목적:** 수명 주기 정책은 객체의 생명 주기를 관리하여 **비용을 최적화**하는 기능입니다. 예를 들어, '객체 생성 후 30일이 지나면 저렴한 스토리지 클래스(S3 Glacier)로 이동시키고, 365일이 지나면 영구적으로 삭제하라'와 같은 규칙을 자동화합니다.
- 이 기능의 주 목적은 데이터 보호가 아니라 관리 및 비용 절감이며, 오히려 설정이 잘못될 경우 의도치 않은 **대규모 데이터 삭제를 유발**할 수 있습니다. 즉, 데이터를 보호하는 것이 아니라 오히려 삭제를 자동화하는 기능에 가깝습니다.

# 45

회사에는 다음으로 구성된 데이터 수집 워크플로가 있습니다.
• 새로운 데이터 전송에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 주제
• 데이터를 처리하고 메타데이터를 기록하는 AWS Lambda 함수
회사는 네트워크 연결 문제로 인해 수집 워크플로가 때때로 실패하는 것을 관찰했습니다.
이러한 장애가 발생하면 회사에서 수동으로 작업을 다시 실행하지 않는 한 Lambda 함수는 해당 데이터를 수집하지 않습니다.
Lambda 함수가 향후 모든 데이터를 수집하도록 하려면 솔루션 설계자가 취해야 하는 작업조합은 무엇입니까?

- 현재 아키텍처의 가장 큰 문제점은 **메시지의 내구성(Durability)이 부족하다는 것**입니다.
    
    **현재 아키텍처:** `SNS Topic` -> `Lambda 함수`
    

**B. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성하고 SNS 주제를 구독합니다.**

- 이 단계는 SNS와 Lambda 사이에 **버퍼(Buffer) 역할을 하는 SQS 대기열을 추가**하는 과정입니다.
- SNS 토픽에 메시지가 발행되면, SNS는 이 메시지를 구독자인 SQS 대기열로 안정적으로 전달합니다. SQS는 메시지를 수신하면 삭제되기 전까지 **최대 14일간 안전하게 보관**합니다. 이로써 Lambda가 일시적으로 실패하더라도 원본 데이터에 대한 알림(메시지)이 유실되지 않습니다.

**E. Amazon Simple Queue Service(Amazon SQS) 대기열에서 읽도록 Lambda 함수를 수정합니다.**

- 이 단계는 Lambda 함수의 트리거(Trigger)를 SNS에서 SQS로 변경하는 과정입니다.
- Lambda는 이제 SQS 대기열을 주기적으로 폴링(Polling)하여 메시지를 가져와 처리합니다.
- **핵심적인 장점:** 만약 Lambda 함수가 네트워크 문제로 실행에 실패하면, Lambda는 SQS에게 메시지를 성공적으로 처리했다고 알리지 않습니다. 그러면 해당 메시지는 **'표시 제한 시간(Visibility Timeout)'이 지난 후에 다시 대기열에 나타나게 되고, Lambda는 이 메시지를 다시 가져와 재처리**를 시도합니다. 이 과정이 자동으로 반복되므로, 일시적인 네트워크 문제가 해결되면 결국 모든 데이터가 성공적으로 처리됩니다.

**A, C, D가 적절하지 않은 이유**

**A. 여러 가용 영역에 Lambda 함수를 배포합니다.**

- Lambda는 AWS가 관리하는 서비스로, 기본적으로 **별도의 설정 없이도 여러 가용 영역(Multi-AZ)에 걸쳐 코드를 배포하고 실행하여 높은 가용성을 제공**합니다.

**C. Lambda 함수에 할당된 CPU와 메모리를 늘립니다.**

- Lambda의 메모리를 늘리면 CPU 성능도 비례하여 향상됩니다. 하지만 이 조치는 **계산 집약적(CPU-bound)이거나 메모리 부족(Memory-bound) 문제를 해결**할 때 유용합니다.

**D. Lambda 함수에 대해 프로비저닝된 처리량을 늘립니다.**

- 프로비저닝된 동시성(Provisioned Concurrency)은 **대규모의 트래픽이 갑자기 몰려올 때 Lambda 함수가 지연 없이 즉시 확장(Scale-out)되도록 보장**하는 기능입니다.

# 46

회사에 매장에 마케팅 서비스를 제공하는 애플리케이션이 있습니다. 서비스는 매장 고객의 이전 구매를 기반으로 합니다. 상점은 SFTP 를 통해 거래 데이터를 회사에 업로드하고 데이터를 처리 및 분석하여 새로운 마케팅 제안을 생성합니다. 일부 파일의 크기는 200GB 를 초과할 수 있습니다.
최근에 회사는 일부 상점에서 포함되어서는 안 되는 개인 식별 정보(PII)가 포함된 파일을 업로드했음을 발견했습니다. 회사는 PII 가 다시 공유될 경우 관리자에게 경고를 주기를 원합니다. 회사는 또한 문제 해결을 자동화하기를 원합니다. 최소한의 개발 노력으로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야
합니까?

**B. Amazon S3 버킷을 보안 전송 지점으로 사용합니다. Amazon Macie를 사용하여 버킷의 객체를 스캔합니다. 객체에 PII가 포함된 경우 Amazon Simple Notification Service(Amazon SNS)를 사용하여 관리자에게 PII가 포함된 객체를 제거하라는 알림을 트리거합니다.**

- **보안 전송 지점 (Secure Transfer Point):**
    - SFTP를 직접 운영하는 대신, **AWS Transfer Family**를 사용하여 SFTP 엔드포인트를 제공하고 파일을 **Amazon S3** 버킷에 직접 업로드하도록 구성할 수 있습니다. S3는 내구성과 확장성이 뛰어난 안전한 저장소이므로 이 요구사항을 완벽히 만족합니다.
- **PII(개인 식별 정보) 탐지:**
    - **Amazon Macie**는 바로 이 목적을 위해 만들어진 서비스입니다. Macie는 기계 학습(ML)과 패턴 매칭을 사용하여 S3에 저장된 데이터에서 PII, 금융 정보 등 민감한 데이터를 자동으로 탐지하고 분류하는 **완전 관리형 데이터 보안 서비스**입니다. 200GB가 넘는 대용량 파일도 효과적으로 스캔할 수 있습니다.
- **최소한의 개발 노력 (Minimal Development Effort):**
    - Macie는 관리형 서비스이므로, 개발자가 직접 PII 탐지 로직을 코드로 작성할 필요가 없습니다. AWS 콘솔에서 몇 번의 클릭으로 Macie 작업을 설정하고 실행할 수 있습니다. 이는 "최소한의 개발 노력"이라는 핵심 요구사항을 가장 잘 만족시키는 방법입니다.
- **관리자 경고 및 자동화된 문제 해결:**
    - Macie가 PII를 탐지하면 'Finding(결과)'을 생성하고, 이 결과는 **Amazon EventBridge**로 전송됩니다. EventBridge에서 규칙을 설정하여 이벤트를 감지하고, **Amazon SNS(Simple Notification Service)** 주제(topic)를 트리거할 수 있습니다. 관리자는 이 SNS 주제를 구독하여 이메일, SMS 등 원하는 방식으로 즉시 알림을 받을 수 있습니다.
    - 나아가, EventBridge가 SNS 대신 **AWS Lambda 함수를 트리거**하여 해당 파일을 격리하거나 삭제하도록 구성하면 **문제 해결을 완전히 자동화**할 수 있습니다. 따라서 이 아키텍처는 자동화 요구사항을 충족하고 확장성도 뛰어납니다.

**A, C, D가 적절하지 않은 이유**

**A. Amazon S3 버킷을 보안 전송 지점으로 사용하십시오. Amazon Inspector 를 사용하여 버킷의 객체를 스캔합니다. 객체에 PII 가 포함된 경우 S3 수명 주기 정책을 트리거하여 PII 가 포함된 객체를 제거합니다.**

Amazon S3 + Amazon Inspector + S3 수명 주기 정책

- **Amazon Inspector :** **Amazon Inspector**는 EC2 인스턴스나 ECR에 저장된 컨테이너 이미지의 **소프트웨어 취약점 및 의도하지 않은 네트워크 노출을 평가**하는 서비스입니다. S3 버킷에 저장된 파일의 내용을 스캔하여 PII를 찾는 기능은 없습니다. 따라서 근본적으로 잘못된 도구를 선택했습니다.
- **S3 수명 주기 정책 :** **S3 수명 주기 정책**은 객체의 생성 시간이나 버전에 따라 객체를 다른 스토리지 클래스로 이동하거나 삭제하는 **시간 기반 규칙**입니다. 객체의 *내용*(PII 포함 여부)을 기반으로 동작을 트리거할 수는 없습니다.

**C. AWS Lambda 함수에서 사용자 지정 스캔 알고리즘을 구현합니다. 객체가 버킷에 로드될 때 함수를 트리거합니다. 객체에 PII 가 포함된 경우 Amazon Simple Notification Service(Amazon SNS)를 사용하여 관리자에게 PII 가 포함된 객체를 제거하라는 알림을 트리거합니다.
D. AWS Lambda 함수에서 사용자 지정 스캔 알고리즘을 구현합니다. 객체가 버킷에 로드될 때 함수를 트리거합니다. 객체에 PII가 포함된 경우 Amazon Simple Email Service(Amazon SES)를 사용하여 관리자에게 알림을 트리거하고 S3 수명 주기 정책을 트리거하여 PII 가 포함된 객체를 제거합니다.**

- **사용자 지정 스캔 알고리즘**을 Lambda 함수로 직접 구현하는 것은 "최소한의 개발 노력"이라는 요구사항에 정면으로 위배됩니다. 다양한 유형의 PII(주민등록번호, 여권번호, 신용카드 번호 등)를 정확하게 탐지하는 정규식이나 알고리즘을 만드는 것은 매우 복잡하고 유지보수도 어렵습니다.
- **대용량 파일 처리의 어려움:** AWS Lambda는 실행 시간(최대 15분)과 메모리 제한이 있습니다. 200GB가 넘는 파일을 단일 Lambda 함수로 처리하는 것은 사실상 불가능합니다.
- **알림 서비스 (Amazon SES):** Amazon SES(Simple Email Service)는 이메일 발송 서비스이지만, 시스템 경고나 애플리케이션 알림에는 **Amazon SNS**가 더 적합합니다. SNS는 이메일뿐만 아니라 SMS, 모바일 푸시, Lambda, SQS 등 다양한 엔드포인트로 메시지를 발행(publish)할 수 있는 유연한 pub/sub 서비스이기 때문입니다.

# 47

회사는 1 주일 동안 진행될 예정된 이벤트를 위해 특정 AWS 리전의 3 개의 특정 가용 영역에서 보장된 Amazon EC2 용량이 필요합니다. EC2 용량을 보장하기 위해 회사는 무엇을 해야 합니까?

**D. 필요한 지역과 3개의 가용 영역을 지정하는 온디맨드 용량 예약을 생성합니다.** 

- **온디맨드 용량 예약(On-Demand Capacity Reservations)**은 사용자가 특정 가용 영역(AZ)에서 특정 인스턴스 유형에 대한 EC2 용량을 미리 예약해 두는 서비스입니다.
    - **용량 보장**: 온디맨드 용량 예약의 가장 핵심적인 기능입니다. 예약을 생성하면 해당 AZ에서는 다른 어떤 수요보다 우선하여 예약된 만큼의 EC2 인스턴스를 **항상 시작할 수 있음을 보장**받습니다. 이는 '예정된 이벤트'처럼 실패 없이 인스턴스를 실행해야 할 때 필수적입니다.
    - **가용 영역(AZ) 지정 가능**: 용량 예약은 특정 AZ를 대상으로 생성됩니다. 따라서 문제의 요구사항처럼 **3개의 특정 가용 영역에 대해 각각 용량 예약을 생성**하여 고가용성 아키텍처를 구성할 수 있습니다.
    - **유연한 사용 기간**: '온디맨드'라는 이름처럼 **최소 약정 기간이 없습니다.** 필요할 때 예약을 생성하고, 이벤트가 끝나는 1주일 후에 즉시 취소할 수 있습니다. 사용한 만큼만 비용을 지불하므로 단기 이벤트에 가장 비용 효율적이고 적합한 방식입니다.

**A, B, C가 적절하지 않은 이유**

**A. 필요한 리전을 지정하는 예약 인스턴스를 구매합니다.**

- **용량 보장 안 됨**: 리전(Region) 범위의 예약 인스턴스(RI)는 주로 **비용 할인**에 목적이 있습니다. 특정 AZ를 지정하지 않았기 때문에, 해당 리전 내 어느 AZ에서든 인스턴스를 시작할 수 있지만 **용량을 보장해주지는 않습니다.** 만약 특정 AZ에 용량이 부족하면 인스턴스를 시작하지 못할 수 있습니다.
- **부적합한 계약 기간**: RI는 최소 1년 또는 3년의 장기 약정이 필요합니다. 1주일짜리 단기 이벤트를 위해 1년짜리 계약을 하는 것은 매우 비효율적입니다.

**B. 필요한 지역을 지정하는 온디맨드 용량 예약을 생성합니다.**

- **기술적으로 불가능**: 온디맨드 용량 예약은 **반드시 특정 가용 영역(AZ)을 지정해야만 생성할 수 있습니다.** 리전(Region) 단위로 생성하는 기능 자체가 존재하지 않습니다. 따라서 이 보기는 기술적으로 틀린 설명입니다.

**C. 필요한 리전과 3개의 가용 영역을 지정하는 예약 인스턴스를 구매합니다.**

- **부적합한 계약 기간**: 특정 AZ를 지정하는 RI는 해당 AZ의 용량을 보장해 주는 장점이 있습니다. 하지만 A와 마찬가지로 최소 1년 또는 3년의 **장기 약정이 필수**입니다. 1주일간의 보장을 위해 1년 치 비용을 내는 것은 합리적이지 않습니다. 단기적인 용량 보장이 필요할 때는 온디맨드 용량 예약이 훨씬 적합한 솔루션입니다.

# 48

회사 웹 사이트는 항목 카탈로그에 Amazon EC2 인스턴스 스토어를 사용합니다. 회사는 카탈로그의 가용성이 높고 카탈로그가 내구성 있는 위치에 저장되기를 원합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**D. 카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동합니다.** 

- **고가용성 충족:**
    - Amazon EFS는 **리전(Region) 서비스**입니다. 즉, 파일 시스템을 생성하면 데이터가 해당 리전 내의 **여러 가용 영역(AZ)에 걸쳐 자동으로 복제 및 저장**됩니다.
    - 따라서 하나의 가용 영역에 장애가 발생해도 다른 가용 영역의 데이터를 통해 서비스를 중단 없이 제공할 수 있습니다.
    - 또한, **여러 EC2 인스턴스에서 동시에 EFS 파일 시스템을 마운트(연결)하여 사용**할 수 있습니다. 이를 통해 Auto Scaling 그룹으로 웹 서버를 구성하여 트래픽에 따라 인스턴스 수를 조절하면서도 모든 인스턴스가 동일한 카탈로그 데이터에 접근하게 할 수 있어 고가용성 아키텍처를 쉽게 구현할 수 있습니다.
- **내구성 충족:**
    - EFS에 저장된 데이터는 EC2 인스턴스와 생명주기가 분리되어 있습니다. 즉, **EC2 인스턴스를 중지하거나 종료하더라도 EFS의 데이터는 그대로 유지**됩니다.
    - 여러 가용 영역에 데이터가 복제되므로 매우 높은 수준의 내구성을 보장합니다.

**A, B, C가 적절하지 않은 이유**

**A. 카탈로그를 Redis용 Amazon ElastiCache로 이동합니다.** 

- **부적절한 용도:** Amazon ElastiCache for Redis는 **인메모리 캐시 서비스**입니다. 주 목적은 데이터베이스나 스토리지에서 자주 조회되는 데이터를 메모리에 임시 저장하여 응답 속도를 높이는 것입니다.
- **내구성 부족:** Redis는 기본적으로 데이터를 메모리에 저장하므로, 노드에 장애가 발생하면 데이터가 유실될 수 있습니다. 물론 백업 및 복제 기능(Multi-AZ)으로 가용성을 높일 수는 있지만, 영구적인 데이터를 저장하기 위한 **기본 스토리지(Primary Storage)로 사용하기에는 적합하지 않습니다.** 내구성이 보장되는 데이터베이스나 EFS, S3 같은 스토리지를 후단에 두고 캐시 용도로 사용해야 합니다.

**B. 더 큰 인스턴스 스토어로 더 큰 EC2 인스턴스를 배포합니다.** 

- **근본적인 문제 미해결:** 인스턴스 크기를 키우고 인스턴스 스토어 용량을 늘리는 것은 **근본적인 문제를 전혀 해결하지 못합니다.**
- **고가용성 및 내구성 미충족:** 여전히 스토리지는 **임시(ephemeral)**적이며, 해당 EC2 인스턴스에 종속됩니다. 인스턴스가 중지/종료되면 데이터는 사라지고(내구성 X), 인스턴스에 장애가 발생하면 서비스가 중단됩니다(고가용성 X). 이것은 단일 장애 지점(Single Point of Failure)을 그대로 두는 것입니다.

**C. 인스턴스 스토어에서 Amazon S3 Glacier Deep Archive로 카탈로그를 이동합니다.** 

- **부적절한 가용성:** Amazon S3 Glacier Deep Archive는 **장기 보관 및 아카이빙**을 위한 스토리지 클래스입니다. 데이터의 내구성은 매우 높지만, 데이터를 검색(retrieval)하는 데 **수 시간이 소요**됩니다.
- **실시간 접근 불가:** 웹사이트 카탈로그는 사용자가 요청하는 즉시 보여주어야 하는 **실시간 데이터**입니다. 데이터 접근에 몇 시간씩 걸리는 Glacier Deep Archive는 웹사이트의 백엔드 스토리지로 절대 사용할 수 없습니다.

# 49

회사는 매월 통화 기록 파일을 저장합니다. 사용자는 통화 후 1 년 이내에 파일에 무작위로 액세스하지만 1 년 이후에는 파일에 자주 액세스하지 않습니다. 이 회사는 사용자에게 1 년 미만의 파일을 가능한 한 빨리 쿼리하고 검색할 수 있는 기능을 제공하여 솔루션을 최적화하려고 합니다. 오래된 파일을 검색하는 데 있어 지연은 허용됩니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

**B. Amazon S3 Intelligent-Tiering 에 개별 파일을 저장합니다. S3 수명 주기 정책을 사용하여 1 년 후 파일을 S3 Glacier Flexible Retrieval 로 이동합니다. Amazon Athena 를 사용하여 Amazon S3 에 있는 파일을 쿼리하고 검색합니다. S3 Glacier Select 를 사용하여 S3 Glacier 에 있는 파일을 쿼리하고 검색합니다.**

- **초기 저장 및 1년 미만 데이터 관리: `Amazon S3 Intelligent-Tiering`**
    - **기능:** S3 Intelligent-Tiering은 **액세스 패턴을 알 수 없거나 예측하기 어려운 데이터**에 가장 적합한 스토리지 클래스입니다. 문제에서 "무작위로 액세스한다"고 했으므로 이와 정확히 일치합니다.
    - **비용 최적화:** 이 스토리지 클래스는 객체에 대한 액세스를 모니터링하여, 자주 액세스하는 데이터는 **Frequent Access Tier (S3 Standard와 동일한 성능 및 가격)**에, 30일 이상 액세스하지 않은 데이터는 **Infrequent Access Tier (S3 Standard-IA와 유사한 저렴한 가격)**로 **자동으로** 이동시켜 줍니다. 이를 통해 사용자는 별도의 작업 없이도 1년 동안의 스토리지 비용을 자동으로 최적화할 수 있습니다.
    - **성능:** Frequent Access Tier에 있는 동안에는 밀리초 단위의 빠른 검색이 가능하므로 "가능한 한 빨리 쿼리하고 검색"해야 하는 요구사항을 완벽하게 만족합니다.
- **1년 이상 데이터 아카이빙: `S3 수명 주기 정책` + `S3 Glacier Flexible Retrieval`**
    - **기능:** S3 수명 주기 정책은 정해진 규칙에 따라 객체를 다른 스토리지 클래스로 자동 전환하거나 삭제하는 기능입니다. "1년 후에"라는 명확한 기준이 있으므로 수명 주기 정책을 사용하는 것이 가장 적합합니다.
    - **비용 효율성:** `S3 Glacier Flexible Retrieval`은 장기 보관용 데이터에 적합한 저렴한 아카이브 스토리지입니다. "지연은 허용된다"는 요구사항에 부합하며, 일반적으로 몇 분에서 몇 시간 내에 데이터를 검색할 수 있습니다. 이는 거의 액세스하지 않는 데이터를 매우 저렴한 비용으로 보관하는 데 최적화되어 있습니다.
- **데이터 쿼리 및 검색: `Amazon Athena` 및 `S3 Glacier Select`**
    - **Athena (1년 미만 데이터):** Athena는 S3에 저장된 데이터를 표준 SQL을 사용하여 직접 쿼리할 수 있는 **서버리스** 서비스입니다. 별도의 데이터베이스를 구축할 필요 없이 S3에 있는 통화 기록 파일을 즉시 분석하고 필요한 파일을 찾아낼 수 있어 매우 효율적이고 비용 효과적입니다.
    - **Glacier Select (1년 이상 데이터):** `S3 Glacier Flexible Retrieval`에 보관된 객체도 전체를 복원하지 않고 `S3 Glacier Select`를 사용해 필요한 데이터만 필터링하여 추출할 수 있습니다. 이는 아카이브된 대용량 파일에서 특정 정보만 찾아야 할 때 매우 유용하며 비용과 시간을 절약해 줍니다.

**A, C, D가 적절하지 않은 이유**

**A. Amazon S3 Glacier Instant Retrieval에 태그가 있는 개별 파일을 저장합니다.**

- **문제점:** 처음부터 `S3 Glacier Instant Retrieval`에 저장하는 것이 문제입니다. 이 스토리지 클래스는 이름처럼 검색은 빠르지만(밀리초 단위), **액세스 빈도가 낮은(분기당 1회 정도) 데이터**를 위해 설계되었습니다. 1년 미만의 **자주 액세스하는 데이터**를 이곳에 저장하면 S3 Standard나 Intelligent-Tiering에 비해 **데이터 액세스 비용이 훨씬 비싸져** 비용 효율성이 떨어집니다.

**C. Amazon S3 Standard 스토리지에 태그가 있는 개별 파일을 저장합니다. S3 수명 주기 정책을 사용하여 1년 후에 파일을 S3 Glacier Instant Retrieval로 이동합니다.**

- **문제점 1 (비용 최적화 부족):** `S3 Standard`는 액세스 빈도와 상관없이 동일한 비용이 부과됩니다. B의 `S3 Intelligent-Tiering`처럼 액세스 빈도에 따라 자동으로 비용을 최적화해주지 못하므로, 1년 동안 액세스가 뜸해진 파일에 대해서도 비싼 요금을 내야 합니다.
- **문제점 2 (아카이브 비용):** 1년 후 이동하는 `S3 Glacier Instant Retrieval`은 `S3 Glacier Flexible Retrieval`(B안)보다 **스토리지 저장 비용이 더 비쌉니다**. 문제에서 "지연은 허용된다"고 명시했으므로, 굳이 더 비싼 Instant Retrieval을 사용할 필요가 없습니다. 따라서 B안이 더 비용 효율적입니다.
- **문제점 3 (쿼리 방식):** "메타데이터를 검색하여 파일을 쿼리한다"는 방식은 Athena를 사용하는 것보다 비효율적이고 구현이 복잡할 수 있습니다.

**D. Amazon S3 Standard 스토리지에 개별 파일을 저장합니다. S3 수명 주기 정책을 사용하여 1년 후에 파일을 S3 Glacier Deep Archive로 이동합니다. Amazon RDS에 검색 메타데이터를 저장합니다.**

- **문제점 1 (쿼리 솔루션의 복잡성 및 비용):** 검색 메타데이터를 위해 `Amazon RDS` 데이터베이스를 별도로 구축하고 운영하는 것은 매우 비효율적입니다. RDS는 서버를 프로비저닝하고 관리해야 하므로 비용과 관리 부담이 큽니다. S3 데이터를 쿼리하는 데는 서버리스 서비스인 `Amazon Athena`가 훨씬 간단하고 비용 효율적인 솔루션입니다. (SAA 시험에서 S3 데이터 쿼리에 RDS를 쓰는 선택지는 대부분 오답일 확률이 높습니다.)
- **문제점 2 (지나치게 느린 아카이브):** `S3 Glacier Deep Archive`는 S3에서 가장 저렴한 스토리지이지만, 데이터 검색에 **최소 12시간**이 소요됩니다. "지연은 허용된다"고 했지만 이 정도의 지연은 일반적인 "가끔 액세스" 시나리오에는 과도할 수 있습니다. 이 스토리지 클래스는 거의 액세스하지 않는 규정 준수용 데이터를 7~10년 이상 보관하는 데 적합합니다. `S3 Glacier Flexible Retrieval`(몇 분~몇 시간)이 문제의 시나리오에 더 적합한 균형을 제공합니다.

# 50

회사에 1,000 개의 Amazon EC2 Linux 인스턴스에서 실행되는 프로덕션 워크로드가 있습니다. 워크로드는 타사 소프트웨어에 의해 구동됩니다. 회사는 중요한 보안 취약성을 수정하기 위해 가능한 한 빨리 모든 EC2 인스턴스에서 타사 소프트웨어를 패치해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**D. AWS Systems Manager Run Command를 사용하여 모든 EC2 인스턴스에 패치를 적용하는 사용자 지정 명령을 실행합니다.**

- AWS Systems Manager의 **Run Command**는 지정된 EC2 인스턴스 그룹에 대해 **즉시, 주문형(on-demand)으로** 원격 명령이나 스크립트를 실행할 수 있는 기능입니다.
- **즉시성(Immediacy):** '가능한 한 빨리'라는 요구사항에 가장 부합합니다. 관리자가 필요하다고 판단하는 즉시 명령을 실행하여 1,000개의 모든 인스턴스에 패치 스크립트를 동시에 적용할 수 있습니다.
- **유연성(Flexibility):** 타사 소프트웨어 패치는 OS 기본 패키지 관리자(yum, apt 등)로 간단히 처리되지 않을 수 있습니다. 특정 스크립트 실행, 파일 다운로드 후 설치 등 복잡한 작업이 필요할 수 있는데, Run Command는 `AWS-RunShellScript`와 같은 문서를 통해 원하는 모든 사용자 지정 스크립트를 실행할 수 있어 매우 유연합니다.
- **확장성(Scalability):** 1,000개는 물론 수만 개의 인스턴스도 태그, 리소스 그룹 등을 기반으로 손쉽게 타겟팅하여 한 번에 관리할 수 있습니다.

**A, B, C가 적절하지 않은 이유**

**A. AWS Lambda 함수를 생성하여 모든 EC2 인스턴스에 패치를 적용합니다.**

- **복잡성 및 부적절한 사용 사례:** Lambda 함수로 이 작업을 구현하려면, 함수 내에서 AWS SDK를 사용하여 1,000개 인스턴스 목록을 가져오고, 각 인스턴스에 접속하여(예: SSH) 명령을 실행하는 로직을 직접 코드로 작성해야 합니다. 이는 매우 복잡하며, 인스턴스 접근을 위한 키 관리 등 보안적으로도 부담이 큽니다. Systems Manager라는 훨씬 간단하고 안전하며 적합한 서비스가 있는데 굳이 Lambda를 사용할 이유가 없습니다. AWS 시험에서는 항상 가장 적합한 서비스를 선택해야 합니다.

**B. 모든 EC2 인스턴스에 패치를 적용하도록 AWS Systems Manager Patch Manager를 구성합니다.**

- **목적의 차이:** **Patch Manager**는 주로 **운영 체제(OS) 및 특정 애플리케이션의 정기적인 패치 관리**를 자동화하는 데 사용됩니다. 예를 들어 "매주 화요일에 모든 'Critical' 등급의 보안 패치를 적용하라"와 같은 규칙(Patch Baseline)을 설정하고 이를 준수하도록 관리하는 데 특화되어 있습니다.
- **긴급성 및 특수성 부족:** 시나리오의 작업은 정기적인 패치 준수 확인이 아니라, **특정 타사 소프트웨어**에 대한 **일회성의 긴급 패치**입니다. Patch Manager를 사용하려면 이 타사 소프트웨어의 패치를 위한 리포지토리를 설정하고 베이스라인을 수정하는 등 사전 준비가 필요할 수 있으며, **'즉시 실행'보다는 '규칙 기반 자동화'**에 더 가깝습니다. Run Command가 훨씬 더 직접적이고 빠릅니다.

**C. AWS Systems Manager 유지 관리 기간을 예약하여 모든 EC2 인스턴스에 패치를 적용합니다.**

- **목적의 정반대:** 유지 관리 기간(Maintenance Window)은 서비스 중단을 최소화하기 위해 미리 지정된 시간(예: 주말 새벽)에만 패치나 업데이트 같은 작업을 수행하도록 "예약"하는 기능입니다. '가능한 한 빨리'라는 긴급한 요구사항과 정면으로 배치됩니다. 중요한 보안 취약점이 발견되었는데 다음 유지 관리 기간까지 기다리는 것은 매우 위험한 결정입니다.

# 51

회사는 REST API 로 검색하기 위해 주문 배송 통계를 제공하는 애플리케이션을 개발 중입니다. 이 회사는 배송 통계를 추출하고 데이터를 읽기 쉬운 HTML 형식으로 구성하고 매일 아침 여러 이메일 주소로 보고서를 보내려고 합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 취해야 합니까?

**D. AWS Lambda 함수를 호출하여 데이터에 대한 애플리케이션의 API를 쿼리하는 Amazon EventBridge (Amazon CloudWatch Events) 예약 이벤트를 생성합니다.**

- **정해진 시간에 작업 시작 (매일 아침)**: **Amazon EventBridge (CloudWatch Events)**를 사용해 스케줄링 규칙(예: `cron(0 9 * * ? *)` - 매일 아침 9시)을 생성합니다.
    - '매일 아침'이라는 주기적인 요구사항은 **EventBridge의 예약 이벤트**로 완벽하게 해결할 수 있습니다.
- **데이터 추출 및 가공**: EventBridge 규칙이 **AWS Lambda** 함수를 트리거합니다. 이 Lambda 함수는 다음을 수행합니다.
    - 애플리케이션의 REST API를 호출하여 주문 배송 통계 데이터(보통 JSON 형식)를 가져옵니다.
    - 가져온 데이터를 파싱하고 가공하여 사람이 읽기 쉬운 **HTML 형식으로 변환**합니다.

**B. Amazon Simple Email Service(Amazon SES)를 사용하여 데이터 형식을 지정하고 보고서를 이메일로 보냅니다.**

- **보고서 이메일 발송**: Lambda 함수 내에서 **Amazon Simple Email Service (SES)** API를 호출하여, 생성된 HTML 본문을 여러 이메일 주소로 발송합니다.
- **Amazon SES**는 대량의 이메일을 안정적으로 발송하기 위해 특별히 설계된 서비스입니다. 특히, 일반 텍스트뿐만 아니라 서식이 있는 **HTML 이메일**을 손쉽게 보낼 수 있어 '읽기 쉬운 HTML 형식'이라는 요구사항을 충족하는 데 가장 적합합니다. Lambda가 데이터를 HTML로 만든 후, SES를 통해 발송하는 것이 정석적인 방법입니다.

**A, C, E가 적절하지 않은 이유**

**A. 데이터를 Amazon Kinesis Data Firehose 로 보내도록 애플리케이션을 구성합니다.**

- **Kinesis Data Firehose**는 실시간으로 발생하는 대규모 **스트리밍 데이터**를 수집하여 S3나 Redshift 같은 데이터 웨어하우스로 전송하는 데 사용되는 서비스입니다. 이 시나리오의 요구사항은 실시간 데이터 스트림 처리가 아니라, 하루에 한 번 API를 호출(Pull)하여 데이터를 가져오는 배치(Batch) 작업입니다. 따라서 서비스의 목적과 맞지 않습니다.

**C. AWS Glue 작업을 호출하여 데이터에 대한 애플리케이션의 API 를 쿼리하는 Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다.**

- **AWS Glue**는 대규모 데이터 세트에 대한 **ETL(추출, 변환, 로드)** 작업을 위한 완전 관리형 서비스입니다. 간단한 REST API를 호출하고 그 결과를 처리하기 위해 Glue 작업을 사용하는 것은 기능적으로 가능할 수는 있으나, 훨씬 무겁고 비용이 많이 드는 방식입니다. "대포로 파리를 잡는 격"입니다. 이 정도 규모의 작업에는 경량의 서버리스 컴퓨팅 서비스인 **Lambda가 훨씬 효율적이고 경제적**입니다.

**E. Amazon S3 에 애플리케이션 데이터를 저장합니다. 보고서를 이메일로 보낼 S3 이벤트 대상으로 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다.**

- **데이터 추출 방법 부재**: 어떻게 API에서 데이터를 가져와 S3에 저장할 것인지에 대한 설명이 빠져있습니다.
- **불필요한 복잡성**: 굳이 데이터를 S3에 파일로 저장하고, S3 이벤트를 트리거하여 알림을 보낼 필요가 없습니다. Lambda가 데이터를 가져온 즉시 SES로 이메일을 보내면 과정이 훨씬 단순해집니다.
- **부적합한 이메일 발송 서비스**: **Amazon SNS**도 이메일 발송 기능이 있지만, 주로 시스템 알림이나 간단한 텍스트 기반 메시지를 다수의 구독자(SMS, 이메일, SQS 등)에게 전달하는 **Pub/Sub 메시징 서비스**입니다. 서식이 있는 HTML 보고서를 보내는 데는 이메일 발송에 특화된 **SES가 더 적합**합니다.

# 52

회사에서 온프레미스 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 애플리케이션은 수십 기가바이트에서 수백 테라바이트까지 다양한 크기의 출력 파일을 생성합니다. 애플리케이션 데이터는 표준 파일 시스템 구조로 저장되어야 합니다. 회사는 자동으로 확장되는 솔루션을 원합니다. 고가용성이며 최소한의 운영 오버헤드가 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

**C. 다중 AZ Auto Scaling 그룹의 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션합니다. 스토리지에 Amazon Elastic File System(Amazon EFS)을 사용합니다.**

- **표준 파일 시스템 구조:**
    - **Amazon EFS (Elastic File System)**는 NFS(Network File System) 프로토콜을 사용하는 완전 관리형 파일 스토리지 서비스입니다. 기존 온프레미스 애플리케이션이 일반적으로 사용하는 **표준 파일 시스템 인터페이스를 그대로 제공**하므로, 애플리케이션 코드 수정 없이 마이그레이션이 가능합니다.
- **자동으로 확장되는 솔루션:**
    - **스토리지:** EFS는 사용량에 따라 **자동으로 스토리지 용량이 확장되고 축소**됩니다. 수십 기가바이트에서 수백 테라바이트(실제로는 페타바이트급)까지 별도의 관리 작업 없이 원활하게 확장됩니다.
    - **컴퓨팅:** **다중 AZ Auto Scaling 그룹**의 EC2 인스턴스는 부하에 따라 인스턴스 수를 자동으로 늘리거나 줄여 컴퓨팅 파워를 유연하게 조절합니다.
- **고가용성 (High Availability):**
    - **스토리지:** EFS(표준 스토리지 클래스)는 생성 시 리전 내의 **여러 가용 영역(Multi-AZ)에 데이터를 자동으로 복제**하여 저장합니다. 따라서 하나의 AZ에 장애가 발생해도 데이터 유실 없이 스토리지 서비스를 계속 사용할 수 있습니다.
    - **컴퓨팅:** **다중 AZ(Multi-AZ) Auto Scaling 그룹**은 여러 가용 영역에 걸쳐 EC2 인스턴스를 분산 배치합니다. 한 AZ에 문제가 생기면 다른 AZ의 인스턴스가 서비스를 계속 이어받아 애플리케이션의 가용성을 보장합니다.
- **최소한의 운영 오버헤드:**
    - **EFS**는 파일 서버 구축, 스토리지 용량 계획, 패치, 백업 등 복잡한 관리 작업을 AWS가 대신 처리해주는 **완전 관리형 서비스**입니다. 사용자는 파일 시스템을 생성하고 EC2에 마운트하기만 하면 됩니다.
    - **Auto Scaling 그룹** 역시 트래픽에 따른 확장/축소, 인스턴스 헬스체크 및 교체를 자동화해주므로 운영 부담을 크게 줄여줍니다.

**A, B, D가 적절하지 않은 이유**

| 선택지 | 스토리지 유형 | 특징 및 문제점 |
| --- | --- | --- |
| A. ECS + S3 | 객체 스토리지 | S3는 객체스토리지임, 표준 파일 시스템이 아니므로 애플리케이션 수정 필요 |
| B. EKS + EBS | 블록 스토리지 | 여러 인스턴스/파드에서 동시 공유 불가, 단일 AZ에 종속 |
| D. EC2 + EBS | 블록 스토리지 | 여러 인스턴스에서 동시 공유 불가 |

# 53

회사는 Amazon S3 에 회계 기록을 저장해야 합니다. 기록은 1 년 동안 즉시 액세스할 수 있어야 하며 그 후 추가로 9 년 동안 보관해야 합니다. 관리자 및 루트 사용자를 포함하여 회사의 그 누구도 전체 10 년 동안 기록을 삭제할 수 없습니다. 기록은 최대한의 복원력으로 저장해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

**C. S3 수명 주기 정책을 사용하여 1년 후에 S3 Standard에서 S3 Glacier Deep Archive로 레코드를 전환합니다. 10년 동안 규정 준수 모드에서 S3 Object Lock을 사용합니다.** 

- **즉시 액세스**
    - 처음 1년 동안 데이터를 **S3 Standard**에 저장합니다. S3 Standard는 밀리초 단위의 매우 빠른 액세스 속도를 제공하므로 '즉시 액세스' 요구사항을 충족합니다.
- **장기 보관**
    - **S3 수명 주기 정책**을 사용하면 1년이 지난 객체를 자동으로 **S3 Glacier Deep Archive**로 이동시킬 수 있습니다. S3 Glacier Deep Archive는 장기 보관을 위한 가장 저렴한 스토리지 클래스이므로, 9년 동안의 아카이빙 요구사항에 비용 효율적으로 부합합니다.
- **삭제 절대 불가**
    - **S3 Object Lock**의 규정 준수 모드(Compliance Mode)는 이 문제의 핵심입니다. 규정 준수 모드로 객체를 잠그면 **그 누구도 (루트 계정 포함)** 보존 기간이 만료되기 전에는 객체를 덮어쓰거나 삭제할 수 없습니다. 보존 기간을 단축하는 것 또한 불가능합니다. 이는 문제의 '그 누구도 기록을 삭제할 수 없다'는 가장 강력한 요구사항을 만족시키는 유일한 방법입니다.
- **최대의 복원력**
    - S3 Standard와 S3 Glacier Deep Archive는 모두 데이터를 여러 가용 영역(AZ)에 걸쳐 자동으로 복제하여 저장합니다. 이를 통해 99.999999999% (Eleven 9s)의 매우 높은 내구성을 제공하여 '최대의 복원력' 요구사항을 충족합니다.

**A, B, D가 적절하지 않은 이유**

**A. 전체 10년 동안 S3 Glacier에 기록을 저장합니다. 접근통제 정책을 사용하여 10년 동안 기록 삭제를 거부합니다.**

- **액세스 시간:** 처음 1년간 '즉시 액세스'가 필요하지만, S3 Glacier는 데이터 검색에 몇 분에서 몇 시간까지 소요될 수 있는 아카이브용 스토리지입니다. 따라서 즉시 액세스 요구사항을 위반합니다.
- **삭제 방지:** 접근 통제 정책(IAM 정책 또는 버킷 정책)은 `Administrator`나 `root` 사용자가 권한이 있다면 언제든지 변경하거나 삭제할 수 있습니다. 문제에서는 루트 사용자도 삭제할 수 없어야 한다고 명시했으므로, IAM 정책만으로는 이 요구사항을 충족할 수 없습니다.

**B. S3 Intelligent-Tiering 을 사용하여 레코드를 저장합니다. IAM 정책을 사용하여 레코드 삭제를 거부합니다. 10년 후 삭제를 허용하도록 IAM 정책을 변경합니다.**

- **삭제 방지:** A와 마찬가지로, IAM 정책은 권한 있는 사용자가 수정할 수 있으므로 '절대 삭제 불가'라는 요구사항을 만족시키지 못합니다. 이것이 가장 결정적인 오답 이유입니다.
- S3 Intelligent-Tiering은 액세스 패턴을 알 수 없거나 예측할 수 없을 때 자동으로 비용을 최적화해주는 좋은 기능이지만, 이 문제처럼 '1년간 자주 액세스 후 9년간 보관'이라는 명확한 패턴이 있는 경우에는 수명 주기 정책이 더 직접적이고 적합한 솔루션입니다.

**D. S3 수명 주기 정책을 사용하여 1 년 후 레코드를 S3 Standard 에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 10 년 동안 거버넌스 모드에서 S3 Object Lock 을 사용합니다.**

- **복원력:** **S3 One Zone-IA**는 이름에서 알 수 있듯이 데이터를 **단일 가용 영역(Single AZ)**에만 저장합니다. 해당 가용 영역에 장애가 발생하면 데이터가 손실될 수 있습니다. 이는 '최대의 복원력' 요구사항을 정면으로 위반합니다.
- **삭제 방지:** S3 Object Lock의 **거버넌스 모드(Governance Mode)**는 특정 권한(`s3:BypassGovernanceRetention`)을 가진 사용자에게는 보존 기간 중에도 객체를 삭제하거나 설정을 변경할 수 있는 권한을 부여합니다. 문제에서는 관리자조차 삭제할 수 없어야 한다고 했으므로, 거버넌스 모드는 부적합합니다.

# 54

회사는 AWS 에서 여러 Windows 워크로드를 실행합니다. 회사 직원은 두 개의 Amazon EC2 인스턴스에서 호스팅되는 Windows 파일 공유를 사용합니다. 파일 공유는 서로 간에 데이터를 동기화하고 중복 복사본을 유지합니다. 이 회사는 사용자가 현재 파일에 액세스하는 방식을 보존하는 고가용성 및 내구성 스토리지 솔루션을 원합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**C. 다중 AZ 구성을 사용하여 파일 공유 환경을 Windows 파일 서버용 Amazon FSx 로 확장합니다. 모든 데이터를 Windows 파일 서버용 FSx로 마이그레이션합니다.**

- **완벽한 호환성 및 사용자 경험 유지**: 문제의 핵심 요구사항은 **"사용자가 현재 파일에 액세스하는 방식을 보존"**하는 것입니다. 기존 환경은 Windows 파일 공유, 즉 **SMB(Server Message Block) 프로토콜**을 사용하고 있습니다. **Amazon FSx for Windows File Server**는 완전 관리형 네이티브 Windows 파일 시스템으로, SMB 프로토콜, Windows NTFS 파일 권한, Active Directory(AD) 통합 등을 완벽하게 지원합니다. 따라서 사용자는 기존과 동일한 방식으로 네트워크 드라이브를 연결하여 파일에 접근할 수 있어, 아무런 변화를 느끼지 못합니다.
- **고가용성(High Availability) 및 내구성(Durability)**: **'다중 AZ(Multi-AZ)'** 구성 옵션은 Amazon FSx의 핵심 기능입니다. 이 옵션을 선택하면 주 파일 서버와 예비 파일 서버가 서로 다른 가용 영역(AZ)에 자동으로 프로비저닝되고, 데이터가 두 서버 간에 동기적으로 복제됩니다. 한쪽 AZ에 장애가 발생하면 AWS가 자동으로 예비 파일 서버로 트래픽을 전환(Failover)하여 서비스 중단을 최소화합니다. 이를 통해 요구사항인 고가용성과 내구성을 완벽하게 만족시킵니다.
- **관리 부담 감소**: 기존 방식처럼 EC2 인스턴스에 직접 Windows Server를 설치하고 파일 공유를 설정/동기화할 필요가 없습니다. Amazon FSx는 AWS가 하드웨어 프로비저닝, 소프트웨어 패치, 백업, 장애 조치 등을 모두 알아서 처리해주는 **완전 관리형 서비스**이므로 운영 부담이 크게 줄어듭니다.

AWS SAA 시험 문제에서 'Windows 파일 공유(Windows file share)', 'SMB 프로토콜', 'Active Directory 통합'과 같은 키워드가 보이면 90% 이상은 Amazon FSx for Windows File Server가 정답일 확률이 높습니다.

다만, 10%의 예외적인 경우를 위해 다음 사항도 함께 고려하시면 완벽합니다.

항상 FSx for Windows가 정답은 아닐 수 있습니다. 문제에 다음과 같은 **추가적인 조건이나 맥락**이 있는지 확인해 보세요.

1. **"온프레미스(On-premises)" 환경과의 "하이브리드(Hybrid)" 연결이 강조될 때**
    - **키워드:** `온프레미스 데이터 센터`, `하이브리드 클라우드`, `클라우드로 확장`, `S3를 백엔드로 사용`
    - **가능성 있는 다른 답:** **AWS Storage Gateway (File Gateway)**
    - **이유:** 온프레미스 환경에 있는 애플리케이션이나 사용자가 기존 SMB 프로토콜을 그대로 사용하면서, 데이터는 클라우드(S3)에 비용 효율적으로 저장하고 싶을 때 File Gateway가 더 적합한 솔루션일 수 있습니다.
2. **데이터를 "마이그레이션하는 과정" 자체를 물어볼 때**
    - **키워드:** `대규모 데이터 이전`, `온라인 데이터 전송`, `마이그레이션 자동화`
    - **가능성 있는 다른 답:** **AWS DataSync**
    - **이유:** DataSync는 온프레미스 파일 서버와 AWS의 스토리지 서비스(FSx for Windows, EFS, S3 등) 간의 데이터 전송을 가속하고 자동화하는 서비스입니다. "어떻게 마이그레이션할 것인가?"를 묻는다면 DataSync가 정답의 일부 또는 전체가 될 수 있습니다.

# 55

솔루션 설계자는 여러 서브넷을 포함하는 VPC 아키텍처를 개발 중입니다. 아키텍처는 Amazon EC2 인스턴스 및 Amazon RDS DB 인스턴스를 사용하는 애플리케이션을 호스팅합니다. 아키텍처는 2개의 가용 영역에 있는 6개의 서브넷으로 구성됩니다. 각 가용 영역에는 퍼블릭 서브넷, 프라이빗 서브넷 및 데이터베이스용 전용 서브넷이 포함됩니다. 프라이빗 서브넷에서 실행되는 EC2 인스턴스만 RDS 데이터베이스에 액세스할 수 있습니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

**C. 프라이빗 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 허용하는 보안 그룹을 생성합니다. 보안 그룹을 DB 인스턴스에 연결합니다.**

이것이 정답인 이유는 AWS **보안 그룹(Security Group)**의 가장 강력하고 핵심적인 기능을 활용하기 때문입니다.

1. **보안 그룹의 역할**: 보안 그룹은 EC2 인스턴스나 RDS DB 인스턴스와 같은 리소스에 대한 **상태 저장(Stateful) 가상 방화벽** 역할을 합니다. 인바운드(Inbound) 및 아웃바운드(Outbound) 트래픽을 제어합니다.
2. **소스(Source) 지정 방식**: 보안 그룹의 인바운드 규칙을 설정할 때, 트래픽을 허용할 소스로 특정 IP 주소(CIDR 블록)뿐만 아니라 **다른 보안 그룹의 ID를 지정**할 수 있습니다.
3. **해결 과정**:
    - 프라이빗 서브넷의 모든 EC2 인스턴스에 `sg-app`이라는 보안 그룹을 할당합니다.
    - DB 서브넷의 RDS 인스턴스에 `sg-db`라는 보안 그룹을 할당합니다.
    - `sg-db` 보안 그룹의 **인바운드 규칙**을 다음과 같이 설정합니다.
        - **유형(Type):** 데이터베이스 포트 (예: MySQL/Aurora의 경우 3306, PostgreSQL의 경우 5432)
        - **프로토콜(Protocol):** TCP
        - **소스(Source):** `sg-app` 보안 그룹의 ID
    
    이렇게 설정하면, `sg-app` 보안 그룹이 연결된 모든 리소스(즉, 프라이빗 서브넷의 EC2 인스턴스)에서 오는 3306 포트 트래픽만 `sg-db`에 연결된 RDS 인스턴스로 들어오는 것이 허용됩니다. 퍼블릭 서브넷의 인스턴스나 다른 어떤 곳에서의 접근도 기본적으로 차단됩니다.
    

이 방식은 IP 주소 대신 논리적인 그룹(보안 그룹)을 사용하므로, 프라이빗 서브넷에 EC2 인스턴스가 추가되거나 삭제되어 IP가 바뀌더라도 보안 규칙을 수정할 필요가 없어 매우 유연하고 확장성이 뛰어납니다. AWS에서 권장하는 모범 사례입니다.

**A, B, D가 적절하지 않은 이유**

**A. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 새 라우팅 테이블을 생성합니다. 라우팅 테이블을 데이터베이스 서브넷과 연결합니다.**

- **라우팅 테이블(Route Table)**은 트래픽을 어디로 보낼지 **경로를 지정**하는 역할을 하지, 트래픽을 **필터링(허용/차단)하는 방화벽 역할**을 하지 않습니다. VPC 내의 모든 서브넷은 기본적으로 `local` 경로를 통해 서로 통신할 수 있으며, 이 `local` 경로는 수정하거나 삭제할 수 없습니다. 따라서 라우팅 테이블로는 서브넷 간의 통신을 차단할 수 없습니다. 이 역할은 보안 그룹이나 네트워크 ACL이 담당합니다.

**B. 퍼블릭 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 거부하는 보안 그룹을 생성합니다. 보안 그룹을 DB 인스턴스에 연결합니다.**

- **보안 그룹에는 '거부(Deny)' 규칙이 없습니다.** 보안 그룹은 기본적으로 모든 인바운드 트래픽을 차단하고, **'허용(Allow)' 규칙만 추가**할 수 있는 'Allow-Only' 방식입니다. 특정 소스의 트래픽을 명시적으로 거부하는 기능 자체가 없습니다. (참고로, '거부' 규칙은 서브넷 수준의 방화벽인 **네트워크 ACL(Network ACL, NACL)**에서 사용합니다.)

**D. 퍼블릭 서브넷과 프라이빗 서브넷 사이에 새로운 피어링 연결을 생성합니다. 프라이빗 서브넷과 데이터베이스 서브넷 간에 다른 피어링 연결을 만듭니다.**

- **VPC 피어링(VPC Peering)**은 **서로 다른 두 개의 VPC를 비공개적으로 연결**하기 위한 기술입니다. 문제의 시나리오는 **하나의 VPC 내에 있는 서브넷 간의 통신**에 대한 것이므로 VPC 피어링은 전혀 관련이 없습니다. 같은 VPC 내의 서브넷들은 피어링 없이도 서로 통신이 가능합니다.

# 56

회사는 Amazon Route 53 에 도메인 이름을 등록했습니다. 이 회사는 ca-central-1 리전의 Amazon API Gateway를 백엔드 마이크로서비스 API의 공용 인터페이스로 사용합니다. 타사 서비스는 API를 안전하게 사용합니다. 회사는 타사 서비스에서 HTTPS를 사용할 수 있도록 회사의 도메인 이름 및 해당 인증서로 API 게이트웨이 URL을 설계하려고 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

1. 현재 상태:
       * 우리 회사는 mycompany.com 같은 도메인 이름을 가지고 있습니다 (Route 53에 등록).
       * 우리 회사의 API는 API Gateway에서 작동하고 있습니다.
       * API Gateway가 제공하는 기본 주소는 https://ab12cd34ef.execute-api.ca-central-1.amazonaws.com/prod 처럼 매우 길고 복잡합니다.


   2. 원하는 목표 (요구사항):
       * 요구사항 1: 커스텀 도메인 사용
           * 외부 파트너사(타사 서비스)가 저렇게 길고 복잡한 주소 대신, https://api.mycompany.com 처럼 전문적이고 기억하기 쉬운 우리 회사 도메인으로 API를 호출하게 하고 싶습니다.

	* 요구사항 2: HTTPS 보안 적용
    	이 새로운 주소(https://api.mycompany.com)로 통신할 때, 데이터가 암호화되어야 합니다 (HTTPS 사용). 이를 위해서는 api.mycompany.com이라는 주소가 우리 회사 소유가 맞다는 것을 증명하는 SSL/TLS 인증서가 반드시 필요하고, API Gateway에 적용되어야 합니다.
           
따라서 이 문제는 "API Gateway에 우리 회사 소유의 커스텀 도메인 이름을 연결하고, 그 도메인에 맞는 HTTPS 인증서를 발급받아 적용하여, 외부에서 안전하고 전문적인 주소로 우리 API를 호출할 수 있도록 만드는 방법"을 묻고 있는 것입니다.

**C. 리전 API 게이트웨이 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사의 도메인 이름과 연결합니다. 회사의 도메인 이름과 연결된 공인 인증서를 동일한 리전의 AWS Certificate Manager(ACM)로 가져옵니다. API Gateway 엔드포인트에 인증서를 연결합니다. API Gateway 엔드포인트로 트래픽을 라우팅하도록 Route 53을 구성합니다.**

- **리전 API 게이트웨이 엔드포인트 생성:** 문제에서 이미 `ca-central-1` 리전에 API Gateway를 사용 중이라고 명시했습니다. 이는 **리전(Regional)** 엔드포인트 유형에 해당합니다.
- **API Gateway 엔드포인트를 회사의 도메인 이름과 연결:** API Gateway 서비스 내의 '사용자 지정 도메인 이름(Custom Domain Names)' 기능에서 이 작업을 수행합니다. 여기서 사용할 도메인 이름(예: `api.mycompany.com`)을 생성합니다.
- **공인 인증서를 동일한 리전의 ACM으로 가져오기:** 이것이 **핵심 포인트**입니다.
    - **리전(Regional) API Gateway** 엔드포인트에 커스텀 도메인을 사용하려면, SSL/TLS 인증서가 **반드시 API Gateway와 동일한 리전**에 있어야 합니다.
    - 문제에서 API Gateway는 `ca-central-1`에 있으므로, ACM 인증서도 `ca-central-1`에 생성하거나 가져와야 합니다.
- **API Gateway 엔드포인트에 인증서 연결:** 위에서 생성한 '사용자 지정 도메인 이름'에 `ca-central-1` 리전의 ACM 인증서를 연결합니다.
- **Route 53 구성:** Route 53에서 회사의 도메인에 대한 DNS 레코드를 생성합니다. 이때 **별칭(Alias) 레코드**를 사용하여 `api.mycompany.com`이 API Gateway의 사용자 지정 도메인 이름 엔드포인트(예: `d-xxxx.execute-api.ca-central-1.amazonaws.com`)를 가리키도록 설정합니다.

**A, B, D가 적절하지 않은 이유**

**A. API Gateway 에서 Name="Endpoint-URL" 및 Value="Company Domain Name"으로 단계 변수를 생성하여 기본 URL 을 덮어씁니다. 회사의 도메인 이름과 연결된 공인 인증서를 AWS Certificate Manager (ACM) 로 가져옵니다.**

- **"단계 변수(Stage Variable)를 생성하여 기본 URL을 덮어쓴다"**는 설명이 완전히 잘못되었습니다.
- 단계 변수는 API의 특정 배포 단계(예: dev, prod)에서만 사용되는 동적인 설정값(예: 백엔드 Lambda 함수 이름, 외부 API 주소 등)을 관리하기 위한 기능입니다. API Gateway의 기본 호출 URL(`{api-id}.execute-api.{region}.amazonaws.com`) 자체를 변경하는 기능이 아닙니다. 커스텀 도메인을 설정하려면 반드시 API Gateway의 '사용자 지정 도메인 이름' 기능을 사용해야 합니다.

**B. 회사의 도메인 이름으로 Route 53 DNS 레코드를 생성합니다. 별칭 레코드가 리전 API 게이트웨이 단계 엔드포인트를 가리키도록 합니다. 회사의 도메인 이름과 연결된 공인 인증서를 us-east-1 리전의 AWS Certificate Manager(ACM)로 가져옵니다.**

- **"인증서를 us-east-1 리전의 ACM으로 가져옵니다"**라는 부분이 결정적인 오류입니다.
- 인증서를 `us-east-1` 리전에 두어야 하는 경우는 **엣지 최적화(Edge-Optimized) API Gateway** 엔드포인트를 사용할 때입니다. 엣지 최적화 엔드포인트는 내부적으로 Amazon CloudFront 배포를 사용하기 때문에, CloudFront의 요구사항에 따라 인증서가 반드시 `us-east-1`에 있어야 합니다.
- 하지만 이 문제에서는 `ca-central-1`의 **리전(Regional)** 엔드포인트를 사용하므로, 인증서는 반드시 같은 리전인 `ca-central-1`에 있어야 합니다.

**D. 리전 API 게이트웨이 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사의도메인 이름과 연결합니다. 회사의 도메인 이름과 연결된 공인 인증서를 us-east-1 리전의AWS Certificate Manager(ACM)로 가져옵니다. API Gateway API 에 인증서를 연결합니다.회사의 도메인 이름으로 Route 53 DNS 레코드를 생성합니다. A 레코드가 회사의 도메인이름을 가리키도록 합니다.**

- **"인증서를 us-east-1 리전의 ACM으로 가져옵니다"**: B와 동일한 오류입니다. 리전 엔드포인트에는 맞지 않는 설정입니다.
- **"A 레코드가 회사의 도메인 이름을 가리키도록 합니다"**: 이 DNS 설정은 잘못되었습니다.
    - `A 레코드`는 도메인 이름을 특정 IP 주소에 매핑할 때 사용합니다. API Gateway와 같은 AWS 관리형 서비스는 IP 주소가 동적으로 변경될 수 있어 A 레코드로 직접 지정하는 것은 올바른 방법이 아닙니다.
    - Route 53에서 API Gateway 같은 AWS 리소스를 가리키도록 설정할 때는 IP 주소 대신 리소스의 DNS 이름을 직접 연결할 수 있는 **별칭(Alias) 레코드**를 사용해야 합니다.

# 57

한 회사에서 인기 있는 소셜 미디어 웹사이트를 운영하고 있습니다. 웹사이트는 사용자에게 이미지를 업로드하여 다른 사용자와 공유할 수 있는 기능을 제공합니다. 회사는 이미지에 부적절한 콘텐츠가 포함되지 않았는지 확인하고 싶습니다. 회사는 개발 노력을 최소화하는 솔루션이 필요합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**B. Amazon Rekognition**

**Amazon Rekognition**은 기계 학습 기반의 **이미지 및 비디오 분석 서비스**입니다. 이 서비스는 별도의 모델 개발이나 훈련 없이, API 호출만으로 바로 사용할 수 있는 다양한 기능을 제공합니다.

- **정확한 서비스 선택:** Rekognition의 핵심 기능 중 하나는 **콘텐츠 조정(Content Moderation)**입니다. `DetectModerationLabels` API를 사용하면 이미지나 비디오에서 폭력적이거나 노골적인 콘텐츠 등 부적절한 항목을 자동으로 탐지할 수 있습니다. 이는 문제의 '이미지에서 부적절한 콘텐츠 탐지' 요구사항과 정확히 일치합니다.
- **개발 노력 최소화:** Rekognition은 AWS에서 미리 훈련시킨 모델을 사용하는 **완전 관리형 서비스**입니다. 따라서 개발자는 복잡한 기계 학습 모델을 직접 만들고, 훈련시키고, 배포할 필요가 없습니다. 단순히 API를 호출하고 반환된 신뢰도 점수(Confidence Score)를 기반으로 비즈니스 로직을 처리하면 되므로 **개발 노력이 최소화**됩니다.
- **인적 검토(Human Review) 연계:** Rekognition은 탐지 결과에 대한 신뢰도 점수를 제공합니다. 이 점수를 기준으로 "신뢰도가 80% 미만인 이미지는 관리자 검토 대상으로 분류"하는 식의 워크플로우를 쉽게 구현할 수 있습니다. 이는 **Amazon Augmented AI (A2I)**와 연동하여 더욱 체계적인 인적 검토 파이프라인을 구축할 수도 있습니다.

결론적으로, Rekognition은 **이미지 분석**이라는 특정 목적에 완벽하게 부합하며, **관리형 서비스**이므로 개발 노력을 최소화하라는 요구사항까지 모두 만족시키는 최적의 솔루션입니다.

**A, C, D가 적절하지 않은 이유**

**A. Amazon Comprehend:**

- Amazon Comprehend는 **자연어 처리(NLP) 서비스**입니다. 즉, 텍스트 데이터에서 인사이트(핵심 구문, 개체, 감정 등)를 추출하는 데 사용됩니다. 이 문제의 대상은 **이미지**이므로, 텍스트 분석 서비스인 Comprehend는 애초에 사용 목적에 맞지 않습니다.

**C. Amazon SageMaker:**

- Amazon SageMaker는 **사용자 지정 기계 학습 모델을 구축, 훈련, 배포**하기 위한 포괄적인 플랫폼입니다. SageMaker를 사용하면 매우 정교하고 특화된 이미지 분류 모델을 만들 수 있습니다. 하지만 이는 대규모 데이터셋을 수집하고, 레이블을 지정(정답 데이터 생성)하고, 모델을 설계하고, 하이퍼파라미터를 튜닝하는 등 **상당한 개발 노력과 전문 지식을 필요**로 합니다. 따라서 '개발 노력을 최소화'하라는 핵심 요구사항에 정면으로 위배됩니다. Rekognition과 같이 이미 준비된 서비스를 사용하는 것이 훨씬 효율적입니다.

**D. AWS Fargate + 사용자 지정 기계 학습 모델:**

- 이 보기는 C와 근본적으로 같은 문제를 안고 있습니다. 핵심은 **'사용자 지정 기계 학습 모델'을 개발해야 한다**는 점입니다**. AWS Fargate는 서버리스 컨테이너 실행 환경으로, 모델을 배포하는 인프라 역할을 할 뿐**입니다. 모델 자체를 개발하는 데 드는 막대한 노력은 그대로 남아있습니다. 즉, 이 역시 '개발 노력을 최소화'하라는 요구사항을 충족하지 못합니다. C와 마찬가지로, 이미 완성된 Rekognition 서비스를 두고 굳이 직접 모델을 개발하여 Fargate에 배포하는 것은 비효율적인 접근 방식입니다.

# 58

회사는 확장성 및 가용성에 대한 요구 사항을 충족하기 위해 컨테이너에서 중요한 응용 프로그램을 실행하려고 합니다. 회사는 중요한 응용 프로그램의 유지 관리에 집중하는 것을 선호합니다. 회사는 컨테이너화된 워크로드를 실행하는 기본 인프라의 프로비저닝 및 관리에 대한 책임을 원하지 않습니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**C. AWS Fargate에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.** 

- **AWS Fargate**는 Amazon ECS와 EKS를 위한 **서버리스(Serverless) 컴퓨팅 엔진**입니다. '서버리스'라는 말은 개발자나 운영자가 서버(EC2 인스턴스)를 직접 프로비저닝하거나 관리할 필요가 없다는 의미입니다.
    - **인프라 관리 책임 없음**: Fargate를 사용하면 AWS가 컨테이너를 실행하는 데 필요한 기본 인프라(서버)의 모든 것을 관리합니다. 사용자는 EC2 인스턴스를 선택하거나, 클러스터 용량을 관리하거나, 서버를 패치하거나, 보안 그룹을 구성할 필요가 없습니다. 이는 문제의 핵심 요구사항인 "기본 인프라 관리에 대한 책임을 원하지 않음"과 정확히 일치합니다.
    - **애플리케이션 집중**: 인프라 관리에 대한 부담이 없으므로, 회사는 오직 컨테이너화된 애플리케이션의 빌드, 배포, 유지 관리에만 집중할 수 있습니다.
    - **확장성 및 가용성**: ECS는 컨테이너 오케스트레이션 서비스로서, Fargate와 함께 사용하면 트래픽에 따라 컨테이너를 자동으로 확장하고 여러 가용 영역에 배포하여 높은 가용성을 보장할 수 있습니다.

**A, B, D가 적절하지 않은 이유**

**A. Amazon EC2 인스턴스를 사용하고 인스턴스에 Docker를 설치합니다.**

- 이것은 가장 원시적이고 관리 부담이 큰 방법입니다. EC2 인스턴스를 직접 생성하고, 운영 체제를 관리하고, Docker를 설치하고, 보안 패치를 적용하고, 컨테이너를 수동으로 관리해야 합니다. ECS와 같은 오케스트레이션 도구가 없으므로 확장성과 가용성을 확보하기도 매우 어렵습니다. 이는 문제의 모든 요구사항에 위배됩니다.

**B. Amazon EC2 작업자 노드에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.**

- 이 방법은 ECS의 'EC2 시작 유형'을 의미합니다. ECS가 컨테이너의 배포와 스케줄링은 자동화해주지만, 컨테이너가 실행될 **EC2 인스턴스(작업자 노드)의 클러스터는 여전히 고객이 직접 프로비저닝하고 관리**해야 합니다. 즉, EC2 인스턴스의 OS 업데이트, 보안 패치, 스케일링(Cluster Auto Scaling) 등을 직접 책임져야 합니다. 이는 "인프라 관리 책임을 원하지 않음"이라는 핵심 요구사항에 명백히 위배됩니다.

**D. Amazon Elastic Container Service(Amazon ECS)에 최적화된 Amazon 머신 이미지(AMI)의 Amazon EC2 인스턴스를 사용합니다.**

- 이 선택지는 B와 거의 동일한 이야기입니다. 'ECS에 최적화된 AMI'는 EC2 인스턴스를 ECS 클러스터의 작업자 노드로 더 쉽게 설정할 수 있도록 Docker, ecs-agent 등이 미리 설치된 이미지일 뿐입니다. AMI를 사용하면 초기 설정이 편리해지지만, 일단 EC2 인스턴스가 생성된 후에는 **그 인스턴스에 대한 관리 책임은 여전히 고객에게 있습니다.** B와 마찬가지로 "인프라 관리 책임을 원하지 않음"이라는 요구사항을 충족시키지 못합니다.

# 59

회사는 300 개 이상의 글로벌 웹사이트 및 애플리케이션을 호스팅합니다. 이 회사는 매일 30TB 이상의 클릭스트림 데이터를 분석할 플랫폼이 필요합니다. 솔루션 설계자는 클릭스트림 데이터를 전송하고 처리하기 위해 무엇을 해야 합니까?

**D. Amazon Kinesis Data Streams 에서 데이터를 수집합니다. Amazon Kinesis Data Firehose 를 사용하여 Amazon S3 데이터 레이크로 데이터를 전송합니다. 분석을 위해 Amazon Redshift 에 데이터를 로드합니다.**

이 아키텍처는 **대규모(일 30TB 이상)의 실시간 클릭스트림 데이터**를 처리하기 위한 AWS의 모범 사례(Best Practice)에 가장 가깝습니다. 각 서비스가 명확하고 효율적인 역할을 수행합니다.

1. **Amazon Kinesis Data Streams (데이터 수집):**
    - **목적:** 전 세계 300개 이상의 웹사이트와 애플리케이션에서 발생하는 대규모 스트리밍 데이터를 실시간으로 안정적으로 수집하기 위해 설계되었습니다.
    - **장점:** 데이터가 폭증해도 손실 없이 받아내는 버퍼 역할을 하며, 데이터 생산자(웹사이트)와 소비자(처리 시스템)를 분리(Decoupling)하여 시스템 전체의 안정성을 높입니다.
2. **Amazon Kinesis Data Firehose (데이터 전송 및 변환):**
    - **목적:** Kinesis Data Streams로부터 받은 데이터를 S3와 같은 목적지로 거의 실시간으로, 완전 관리형으로 전송합니다.
    - **장점:** 코딩 없이 간단한 설정만으로 데이터를 S3에 최적화된 형태로 저장할 수 있습니다. 예를 들어, 작은 데이터 조각들을 모아 큰 파일로 묶고(Batching), 압축(Compression)하여 S3 저장 비용과 추후 분석 비용을 모두 절감해 줍니다.
3. **Amazon S3 (데이터 레이크로 저장):**
    - **목적:** 처리된 대용량 원시(raw) 데이터를 저렴한 비용으로 안전하고 영구적으로 저장하는 중앙 리포지토리 역할을 합니다.
    - **장점:** 내구성과 확장성이 뛰어나며, 다양한 분석 서비스가 S3의 데이터를 직접 활용할 수 있습니다.
4. **Amazon Redshift (데이터 분석):**
    - **목적:** S3 데이터 레이크에 저장된 페타바이트(PB) 규모의 정형/반정형 데이터를 대상으로 복잡한 쿼리를 빠르게 실행하여 비즈니스 인사이트를 얻는 데이터 웨어하우스(DW)입니다.
    - **장점:** 클릭스트림 데이터와 같은 대용량 데이터의 집계 및 분석에 최적화되어 있습니다.

이처럼 D는 **수집 → 전송/변환 → 저장 → 분석**의 각 단계에 가장 적합하고 확장성 높은 AWS 관리형 서비스를 조합한 이상적인 아키텍처입니다.

# 60

회사에 AWS 에서 호스팅되는 웹 사이트가 있습니다. 웹 사이트는 HTTP 와 HTTPS 를 별도로 처리하도록 구성된 ALB(Application Load Balancer) 뒤에 있습니다. 회사는 요청이 HTTPS 를 사용하도록 모든 요청을 웹사이트로 전달하려고 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**C. ALB에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS로 리디렉션합니다.** 

이 방법은 AWS에서 권장하는 가장 표준적이고 효율적인 방법입니다. ALB는 **Layer 7 (애플리케이션 계층)**에서 작동하기 때문에 HTTP/HTTPS 프로토콜의 내용을 이해할 수 있습니다.

- **리스너(Listener)의 역할**: ALB에는 특정 포트와 프로토콜로 들어오는 클라이언트 요청을 수신하는 '리스너'가 있습니다. 일반적으로 다음과 같이 구성합니다.
    - **HTTP 리스너**: 프로토콜 `HTTP`, 포트 `80`
    - **HTTPS 리스너**: 프로토콜 `HTTPS`, 포트 `443`
- **리디렉션 규칙(Redirect Rule) 설정**: 문제의 요구사항을 충족시키기 위해, **HTTP(80번 포트) 리스너**에 규칙을 추가합니다.
    - 이 규칙은 들어오는 모든 HTTP 요청에 대해 특정 '작업(Action)'을 수행하도록 설정할 수 있습니다.
    - 이때 작업 유형을 '리디렉션(Redirect)'으로 선택합니다.
    - 리디렉션 대상을 `HTTPS`, 포트 `443`으로 지정합니다.
- **동작 방식**:
    - 사용자가 `http://example.com`으로 접속합니다.
    - 요청은 ALB의 80번 포트(HTTP 리스너)로 들어옵니다.
    - ALB는 설정된 규칙에 따라, 사용자 브라우저에게 "이 주소는 `https://example.com`으로 영구적으로 이동했으니(HTTP 상태 코드 301), 그쪽으로 다시 요청하세요"라는 응답을 보냅니다.
    - 사용자 브라우저는 이 응답을 받고 자동으로 `https://example.com`으로 다시 요청을 보냅니다.

**A, B, D가 적절하지 않은 이유**

**A. HTTPS 트래픽만 허용하도록 ALB의 네트워크 ACL을 업데이트합니다.**

- 네트워크 ACL(NACL)은 **Layer 3/4 (네트워크/전송 계층)**에서 작동하는 서브넷 수준의 방화벽입니다. NACL에서 HTTP(80번 포트) 트래픽을 차단(DENY)하면, 사용자의 HTTP 요청은 ALB에 도달하기 전에 그냥 **차단(drop)**됩니다. 사용자 브라우저는 '연결 시간 초과' 또는 '사이트에 연결할 수 없음'과 같은 오류를 보게 됩니다.
- **핵심**: 이 방법은 트래픽을 **리디렉션(전환)**하는 것이 아니라, 단순히 **차단**하는 것이므로 요구사항을 충족시키지 못하며 사용자 경험을 해칩니다. 리디렉션을 하려면 일단 HTTP 요청을 받은 후에 처리해야 합니다.

**B. URL의 HTTP를 HTTPS로 바꾸는 규칙을 만듭니다.**

- **틀린 이유**: 이 설명은 매우 모호하며 기술적으로 부정확합니다. "규칙을 만든다"는 주체가 명시되어 있지 않습니다.
    - 만약 이 규칙을 **웹 서버**(예: Apache, Nginx)에서 만든다면 가능은 하지만 ALB라는 더 좋은 솔루션을 두고 웹 서버마다 개별적으로 설정을 관리해야 하므로 좋은 아키텍처가 아닙니다.
    - 만약 **ALB**에서 만드는 규칙을 의미한다면, C에서 설명한 '리스너 규칙'과 '리디렉션 작업'이 훨씬 더 정확하고 구체적인 표현입니다. B는 ALB의 기능(Redirect Action)을 정확하게 설명하지 못하고 있습니다. 따라서 가장 정확한 설명을 고르는 시험의 특성상 C가 정답입니다.

**D. ALB를 SNI(서버 이름 표시)를 사용하도록 구성된 Network Load Balancer로 교체합니다.**

- **NLB(Network Load Balancer)는 Layer 4 (전송 계층)에서 작동**합니다. NLB는 TCP/UDP 트래픽을 단순히 전달할 뿐, 그 안의 내용물인 HTTP 프로토콜(헤더, URL 등)을 이해하지 못합니다. HTTP 리디렉션(HTTP 301/302 응답)은 Layer 7의 기능이므로, **NLB는 HTTP 리디렉션을 수행할 수 없습니다.**
- SNI(Server Name Indication)는 하나의 IP 주소에서 여러 개의 SSL/TLS 인증서를 호스팅할 수 있게 해주는 기술입니다. 이 기술은 리디렉션과는 직접적인 관련이 없습니다. (참고로 ALB와 NLB 모두 SNI를 지원합니다.)
- 따라서 요구사항을 해결하기 위해 ALB를 NLB로 교체하는 것은 아키텍처를 다운그레이드하는 것과 같습니다.