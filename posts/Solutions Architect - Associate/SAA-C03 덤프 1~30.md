# SAA-C03 덤프 1~30

게시일: 2025-07-02T13:28:09.553Z
시리즈: Solutions Architect - Associate

---

# 1

회사는 여러 대륙에 걸쳐 도시의 온도, 습도 및 대기압에 대한 데이터를 수집합니다.
회사가 매일 각 사이트에서 수집하는 데이터의 평균 볼륨은 500GB 입니다. 각 사이트에는 고속 인터넷 연결이 있습니다.
이 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**A. 대상 S3 버킷에서 S3 Transfer Acceleration 을 켭니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다.**

- **속도:** S3 Transfer Acceleration은 AWS의 고속 전송 네트워크를 활용하여 장거리에서 S3 버킷으로 데이터를 전송하는 속도를 향상시킵니다. 이는 전 세계 여러 대륙의 사이트에서 데이터를 빠르게 집계해야 한다는 요구 사항을 충족합니다. 멀티파트 업로드는 큰 파일을 더 작고 병렬적으로 업로드할 수 있도록 하여 업로드 속도와 안정성을 높입니다.
- **운영 복잡성 최소화:** 데이터를 각 사이트에서 단일 대상 S3 버킷으로 직접 업로드하므로 여러 중간 단계를 관리할 필요가 없습니다. 이는 다른 옵션에 비해 운영 복잡성을 크게 줄입니다.
- **고속 인터넷 연결 활용:** 각 사이트에 고속 인터넷 연결이 있다는 점을 고려할 때, S3 Transfer Acceleration은 이러한 연결을 최대한 활용하여 데이터 전송 속도를 최적화할 수 있습니다.

**B, C, D가 적절하지 않은 이유:**

**B. 각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다.**

- **추가적인 단계 및 비용:** 이 솔루션은 각 사이트의 데이터를 먼저 지역별 S3 버킷에 업로드한 다음 교차 리전 복제를 사용하여 대상 버킷으로 복사하는 추가 단계를 포함합니다. 이는 시간과 비용을 증가시키고 운영 복잡성을 높입니다.
- **데이터 제거의 복잡성:** 원본 S3 버킷에서 데이터를 제거하는 단계를 추가하면 관리해야 할 프로세스가 늘어납니다.

**C. AWS Snowball Edge Storage Optimized 디바이스 작업을 매일 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다.**

- **불필요한 물리적 장치 및 물류:** 매일 Snowball Edge 장치를 배송하고 관리하는 것은 매우 복잡하고 비용이 많이 드는 작업입니다. 각 사이트에 고속 인터넷 연결이 있다는 점을 고려할 때 네트워크를 통한 데이터 전송이 훨씬 효율적입니다.
- **지연 시간:** 물리적 장치를 배송하는 데는 상당한 시간이 소요되므로 데이터를 즉시 집계해야 한다는 요구 사항을 충족하지 못합니다.

**D. 각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스로 업로드합니다. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS 스냅샷을 만들어 대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다.**

- **과도한 복잡성 및 관리 오버헤드:** 이 솔루션은 EC2 인스턴스, EBS 볼륨, 스냅샷 및 복원을 관리해야 하므로 운영 복잡성이 매우 높습니다.
- **비용 효율성:** EC2 인스턴스를 실행하고 EBS 볼륨을 저장하는 데 드는 비용은 S3로 직접 업로드하는 것보다 훨씬 높을 수 있습니다.
- **성능 병목 현상 가능성:** EC2 인스턴스의 네트워크 대역폭 및 EBS 볼륨의 I/O 성능이 데이터 수집 속도에 병목 현상을 일으킬 수 있습니다.

**A** 옵션이 속도, 운영 복잡성 및 기존 인프라(고속 인터넷 연결) 활용 측면에서 가장 효율적이고 비용 효율적인 솔루션입니다.

# 2

회사는 독점 애플리케이션의 로그 파일을 분석할 수 있는 능력이 필요합니다. 
로그는 Amazon S3 버킷에 JSON 형식으로 저장됩니다. 쿼리는 간단하고 주문형으로 실행됩니다.
솔루션 설계자는 기존 아키텍처에 대한 최소한의 변경으로 분석을 수행해야 합니다.
솔루션 설계자는 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 무엇을 해야합니까?

**C. Amazon S3와 함께 Amazon Athena를 직접 사용하여 필요에 따라 쿼리를 실행합니다.**

- **기존 아키텍처 변경 최소화**: Athena는 **Amazon S3에 저장된 데이터를 직접 쿼리**할 수 있습니다. 이미 로그가 S3에 저장되어 있기 때문에, 로그를 다른 곳으로 옮기거나 수집 방식을 변경할 필요가 없습니다. 이는 '최소한의 변경'이라는 요구사항에 완벽하게 부합합니다.
- **최소한의 운영 오버헤드**: Athena는 **서버리스(Serverless)** 서비스입니다. 즉, 사용자가 서버나 클러스터를 프로비저닝하거나 관리할 필요가 없습니다. 쿼리를 실행할 때만 비용을 지불하고 (스캔한 데이터 양 기준), 인프라 관리에 대한 부담이 전혀 없습니다. 이는 '최소한의 운영 오버헤드'에 정확히 들어맞습니다.
- **주문형 쿼리 및 JSON 지원**: Athena는 SQL을 사용하여 S3의 JSON 데이터를 온디맨드 방식으로 쉽게 쿼리할 수 있도록 설계되었습니다. 원하는 때에만 쿼리를 실행하고 결과를 얻을 수 있습니다.
- **비용 효율성**: 간단하고 주문형 쿼리의 경우, 사용한 만큼만 비용을 지불하는 Athena가 다른 복잡한 솔루션보다 훨씬 비용 효율적일 수 있습니다.

**A, B, D가 적절하지 않은 이유:**

**A. Amazon Redshift 를 사용하여 모든 콘텐츠를 한 곳에 로드하고 필요에 따라 SQL 쿼리를 실행합니다.**

- **아키텍처 변경 및 운영 오버헤드 증가**: Redshift는 데이터 웨어하우스 솔루션으로, 데이터를 Redshift 클러스터로 **로드(load)**해야 합니다. 이는 S3에서 Redshift로 데이터를 이동시키는 ETL(Extract, Transform, Load) 프로세스를 구축해야 함을 의미합니다. 이 과정에서 추가적인 설정과 관리가 필요하며, Redshift 클러스터 자체를 관리하는 운영 오버헤드가 발생합니다. 이는 '최소한의 변경'과 '최소한의 운영 오버헤드' 요구사항에 맞지 않습니다.
- **과도한 솔루션**: Redshift는 대규모의 복잡한 분석 워크로드에 더 적합합니다. 간단한 온디맨드 로그 분석에는 너무 강력하고 비용이 많이 들 수 있습니다.

**B. Amazon CloudWatch Logs 를 사용하여 로그를 저장합니다. Amazon CloudWatch 콘솔에서 필요에 따라 SQL 쿼리를 실행합니다.**

- **아키텍처 변경 필요**: 이 옵션은 로그 저장 위치를 S3에서 **CloudWatch Logs**로 변경해야 함을 의미합니다. 이는 기존 로그 수집 파이프라인에 상당한 변경을 가해야 합니다. '최소한의 변경'이라는 요구사항에 위배됩니다.
- **잠재적 비용 문제**: 모든 애플리케이션 로그를 CloudWatch Logs에 저장하는 것은 대용량 로그의 경우 S3에 저장하는 것보다 비용이 더 많이 들 수 있습니다.
- **기존 로그 분석 대상 불일치**: 문제의 핵심은 **S3에 있는 로그를 분석**하는 것입니다. CloudWatch Logs는 S3에 있는 기존 로그와는 별개의 시스템입니다.

**D. AWS Glue 를 사용하여 로그를 분류합니다. Amazon EMR 에서 임시 Apache Spark 클러스터를 사용하여 필요에 따라 SQL 쿼리를 실행합니다.**

- **높은 운영 오버헤드**: AWS Glue Data Catalog(Athena도 이를 활용)는 데이터 분류에 유용하지만, Apache Spark 클러스터를 **Amazon EMR에서 실행**하는 것은 상당한 운영 오버헤드를 동반합니다. 임시 클러스터라고 해도 클러스터를 시작하고 관리하며 종료하는 과정이 필요합니다. 이는 '최소한의 운영 오버헤드'에 맞지 않습니다.
- **과도한 솔루션**: EMR은 빅데이터 처리 및 복잡한 ETL 워크로드에 강력한 도구이지만, 단순히 S3에 저장된 JSON 로그를 SQL로 쿼리하는 데는 너무 복잡하고 자원 소모적인 솔루션입니다. Athena와 같은 서버리스 옵션이 훨씬 효율적입니다

Amazon Athena는 기존 S3 저장소를 그대로 활용하고, 서버리스 아키텍처로 운영 부담을 최소화하며, 온디맨드 쿼리 요구사항을 충족시키므로 주어진 시나리오에 가장 적합한 솔루션입니다.

# 3

회사는 AWS Organizations 를 사용하여 여러 부서의 여러 AWS 계정을 관리합니다. 
관리계정에는 프로젝트 보고서가 포함된 Amazon S3 버킷이 있습니다. 
회사는 이 S3 버킷에 대한 액세스를 AWS Organizations의 조직 내 계정 사용자로만 제한하려고 합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

**A. 조직 ID 에 대한 참조와 함께 aws PrincipalOrgID 전역 조건 키를 S3 버킷 정책에 추가합니다.**

- **AWS Organizations와의 직접적인 통합:** `aws:PrincipalOrgID` 조건 키는 AWS Organizations의 핵심 개념인 조직 ID를 직접적으로 활용합니다. 버킷 정책에서 조직 ID를 지정하면 해당 조직에 속한 모든 AWS 계정의 보안 주체(사용자, 역할 등)에게만 S3 버킷에 대한 액세스 권한이 부여됩니다.
- **최소한의 운영 오버헤드:**
    - **자동 적용:** 조직에 새로운 계정이 추가되거나 기존 계정이 조직에서 제거될 때, 별도의 정책 업데이트 없이 자동으로 액세스 권한이 관리됩니다. 관리자는 조직 구조 변경에 따라 S3 버킷 정책을 수동으로 수정할 필요가 없습니다.
    - **중앙 집중식 관리:** 액세스 제어가 관리 계정의 S3 버킷 정책에서 중앙 집중적으로 관리됩니다. 각 개별 계정에 정책을 적용할 필요가 없어 관리 부담을 줄입니다.
    - **단순성:** 버킷 정책에 단일 조건 키와 조직 ID 값만 추가하면 되므로 설정이 간단하고 이해하기 쉽습니다.

**B, C, D가 적절하지 않은 이유:**

- **B. 각 부서에 대한 조직 단위(OU)를 만들고 `aws:PrincipalOrgPaths` 전역 조건 키를 S3 버킷 정책에 추가합니다.**
    - **운영 오버헤드 증가:** OU 구조를 관리하고 변경 사항이 있을 때마다 S3 버킷 정책을 업데이트해야 합니다. 부서 구조가 자주 변경되는 경우 관리 부담이 커집니다.
    - **유연성 부족:** 특정 OU 내의 일부 계정에만 액세스를 허용해야 하는 경우, OU 구조를 재설계하거나 더 복잡한 정책을 만들어야 할 수 있습니다. `aws:PrincipalOrgPaths`는 지정된 OU 경로 아래의 모든 계정에 권한을 부여하므로 세밀한 제어가 어려울 수 있습니다.
- **C. AWS CloudTrail을 사용하여 `CreateAccount`, `InviteAccountToOrganization`, `LeaveOrganization` 및 `RemoveAccountFromOrganization` 이벤트를 모니터링하고 그에 따라 S3 버킷 정책을 업데이트합니다.**
    - **높은 운영 오버헤드 및 지연:** CloudTrail 이벤트를 모니터링하고 이에 따라 S3 버킷 정책을 업데이트하는 자동화 시스템을 구축하고 유지 관리해야 합니다. 이는 복잡하고 오류가 발생하기 쉬우며, 계정 변경 사항이 정책에 반영되기까지 지연이 발생할 수 있습니다.
    - **실시간 적용 어려움:** 계정 변경 이벤트 발생 후 정책 업데이트가 완료될 때까지 일시적으로 액세스 권한이 잘못 부여되거나 거부될 수 있습니다.
    - **간접적인 접근 방식:** AWS Organizations의 기능을 직접 활용하는 것이 아니라 이벤트 기반으로 정책을 관리하므로 효율성이 떨어집니다.
- **D. S3 버킷에 액세스해야 하는 각 사용자에 태그를 지정하고 `aws:PrincipalTag` 전역 조건 키를 S3 버킷 정책에 추가합니다.**
    - **매우 높은 운영 오버헤드:** 각 사용자를 식별하고 태그를 관리해야 합니다. 조직 내 사용자 수가 많거나 자주 변경되는 경우 태그 관리가 매우 번거롭고 오류가 발생하기 쉽습니다.
    - **확장성 문제:** 새로운 사용자가 S3 버킷에 액세스해야 할 때마다 해당 사용자를 찾아서 태그를 추가해야 합니다. 이는 확장성이 떨어지는 방식입니다.
    - **조직 구조와의 분리:** 사용자 태그는 AWS Organizations의 계정 구조와 직접적으로 연결되어 있지 않으므로 조직 전체의 액세스 제어를 관리하기 어렵습니다.

 AWS Organizations의 조직 구조를 직접 활용하여 최소한의 관리 노력으로 조직 내 계정에만 S3 버킷 액세스를 제한하는 가장 효율적이고 유지 관리가 용이한 솔루션입니다.

# 4

애플리케이션은 VPC 의 Amazon EC2 인스턴스에서 실행됩니다. 
애플리케이션은 AmazonS3 버킷에 저장된 로그를 처리합니다. 
EC2 인스턴스는 인터넷 연결 없이 S3 버킷에액세스해야 합니다.
Amazon S3에 대한 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까?

**A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.**

- **프라이빗 연결 제공:** 게이트웨이 VPC 엔드포인트는 VPC와 Amazon S3 간에 직접적인 프라이빗 네트워크 연결을 설정합니다.
- **인터넷 불필요:** 이 연결을 통해 EC2 인스턴스는 인터넷 게이트웨이, NAT 디바이스, VPN 연결 또는 AWS Direct Connect 연결 없이 안전하게 S3 버킷에 액세스할 수 있습니다.
- **AWS 네트워크 내 통신:** 모든 트래픽은 안전하고 안정적인 AWS 네트워크 내에서 유지됩니다.
- EC2 인스턴스는 VPC 내부에 있습니다.게이트웨이 VPC 엔드포인트를 통해 S3와 VPC가 연결됩니다.이때 **게이트웨이 VPC 엔드포인트**를 생성하면, 마치 S3 서비스가 VPC 내부에 있는 것처럼, VPC와 S3 서비스 간에 **직접적이고 프라이빗한 연결 통로**가 생깁니다. 이 통로는 인터넷을 거치지 않습니다.게이트웨이 VPC 엔드포인트가 바로 그 "S3와 VPC를 연결하는 다리" 역할

**B, C, D가 적절하지 않은 이유:**

- **B. Amazon CloudWatch Logs 로 로그를 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.**
    - CloudWatch Logs는 로그 관리 및 모니터링 서비스이며, S3로 내보내는 기능은 있지만 EC2 인스턴스와 S3 간의 직접적인 프라이빗 연결을 제공하지 않습니다.
    - 초기 로그 스트리밍 과정에서 인터넷 연결이 필요할 수 있습니다.
- **C. Amazon EC2에 인스턴스 프로파일을 생성하여 S3 액세스를 허용합니다.**
    - 인스턴스 프로파일은 EC2 인스턴스에 AWS 서비스에 대한 권한을 부여하지만, 네트워크 연결 자체를 제공하지 않습니다.
    - 여전히 S3 엔드포인트에 도달하기 위한 네트워크 경로가 필요하며, 기본적으로는 퍼블릭 인터넷을 사용합니다.
- **D. S3 엔드포인트에 액세스하기 위한 프라이빗 링크가 있는 Amazon API Gateway API 를 생성합니다.**
    - AWS PrivateLink는 프라이빗 연결을 제공하지만, API Gateway를 중간에 두는 방식은 S3에 대한 직접적인 연결이 아닙니다.
    - 설정이 더 복잡하며, 문제의 요구 사항인 EC2 인스턴스와 S3 간의 직접적인 프라이빗 연결에는 게이트웨이 VPC 엔드포인트가 더 적합하고 간단한 솔루션입니다.

# 5

회사는 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS 에서 웹 애플리케이션을 호스팅하고 있습니다. 
더 나은 확장성과 가용성을 위해 이 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하여 Application Load Balancer 뒤에 배치했습니다. 
이 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서의 일부 또는 다른 하위 집합을 볼 수 있지만 모든 문서를 동시에 볼 수는 없다고 보고했습니다.
솔루션 설계자는 사용자가 모든 문서를 한 번에 볼 수 있도록 무엇을 제안해야 합니까?

**C. 두 EBS 볼륨의 데이터를 Amazon EFS 로 복사합니다. 새 문서를 Amazon EFS 에 저장하도록 애플리케이션을 수정합니다.**

사용자가 웹 사이트를 새로 고칠 때마다 문서의 일부 또는 다른 하위 집합을 보는 문제는 각 EC2 인스턴스가 서로 다른 EBS 볼륨을 가지고 있기 때문에 발생합니다. Application Load Balancer는 들어오는 트래픽을 여러 인스턴스에 분산시키므로, 사용자의 요청이 어떤 인스턴스로 전달되느냐에 따라 접근할 수 있는 문서가 달라지는 것입니다. 사용자는 모든 문서를 동시에 볼 수 있어야 하므로, 모든 인스턴스가 동일한 문서 집합에 접근할 수 있도록 중앙 집중식 스토리지 솔루션이 필요합니다.

Amazon EFS(Elastic File System)는 여러 EC2 인스턴스에서 동시에 액세스할 수 있는 확장 가능하고 탄력적인 네트워크 파일 시스템입니다. 따라서 다음 단계를 따르면 사용자는 모든 문서를 한 번에 볼 수 있게 됩니다.

1. **두 EBS 볼륨의 데이터를 Amazon EFS로 복사:** 기존 문서 데이터를 중앙 집중식 EFS 파일 시스템으로 마이그레이션합니다.
2. **새 문서를 Amazon EFS에 저장하도록 애플리케이션을 수정:** 애플리케이션이 문서를 로컬 EBS 볼륨 대신 EFS 파일 시스템에 저장하도록 변경합니다.
3. **각 EC2 인스턴스에서 Amazon EFS 마운트:** 두 EC2 인스턴스 모두 EFS 파일 시스템을 마운트하여 동일한 문서 데이터에 접근할 수 있도록 합니다.

이렇게 하면 Application Load Balancer가 어떤 인스턴스로 트래픽을 라우팅하든, 사용자는 항상 EFS를 통해 모든 문서에 접근할 수 있게 됩니다. 또한 EFS는 확장성과 가용성이 뛰어나므로 향후 트래픽 증가나 인스턴스 장애 발생 시에도 안정적인 문서 접근을 보장합니다.

**A, B, D가 적절하지 않은 이유:**

- **A. 두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다.**
    - 이 방법은 각 인스턴스에 중복된 데이터를 저장하므로 스토리지 비용이 증가하고, 데이터 일관성 문제가 발생할 수 있습니다. 예를 들어, 한 인스턴스에서 문서가 업데이트되면 다른 인스턴스의 문서도 동일하게 업데이트해야 하지만, 이 과정에서 오류가 발생할 가능성이 있습니다. 또한, 새로운 인스턴스를 추가할 때마다 데이터를 복사하는 번거로움이 있습니다.
- **B. 문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer를 구성합니다.**
    - 이는 로드 밸런서의 기본적인 작동 방식에 어긋납니다. 로드 밸런서는 트래픽을 여러 인스턴스에 분산시켜 가용성과 확장성을 높이는 역할을 합니다. 특정 사용자를 특정 서버로 고정하면 로드 밸런싱의 이점을 활용할 수 없게 되고, 해당 서버에 장애가 발생하면 사용자는 문서에 접근할 수 없게 됩니다.
- **D. 두 서버 모두에 요청을 보내도록 Application Load Balancer 를 구성합니다. 올바른 서버에서 각 문서를 반환합니다.**
    - 이 방법은 각 요청마다 두 서버에 모두 접근해야 하므로 불필요한 네트워크 트래픽과 서버 부하를 유발합니다. 또한, 각 서버에서 문서를 취합하여 사용자에게 반환하는 복잡한 로직이 필요하며, 이 과정에서 성능 저하가 발생할 수 있습니다. 사용자의 요청이 증가하면 이러한 비효율성은 더욱 심화될 것입니다.

# 6

회사는 NFS 를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 저장합니다. 각 비디오 파일의 크기 범위는 1MB 에서 500GB 입니다. 총 스토리지는 70TB 이며 더 이상 증가하지 않습니다. 
회사는 비디오 파일을 Amazon S3 로마이그레이션하기로 결정합니다. 
회사는 가능한 한 최소한의 네트워크 대역폭을 사용하면서가능한 한 빨리 비디오 파일을 마이그레이션해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**B. AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 장치로 데이터를 전송합니다. AWS 가 데이터를 Amazon S3로 가져올 수 있도록 디바이스를 반환합니다.**

- **빠른 마이그레이션:** 70TB의 데이터를 인터넷을 통해 전송하는 것은 상당한 시간이 소요될 수 있습니다. Snowball Edge는 물리적 운송과 병렬 처리를 통해 대규모 데이터 세트의 마이그레이션 속도를 크게 향상시킵니다. 특히 대역폭이 제한적인 환경에서 더욱 효과적입니다.
- **최소한의 네트워크 대역폭 사용:** Snowball Edge는 물리적 장치를 사용하여 데이터를 전송하므로, 대량의 데이터를 인터넷을 통해 직접 전송하는 것보다 네트워크 대역폭 사용을 최소화합니다. 이는 "최소한의 네트워크 대역폭 사용"이라는 요구사항을 직접적으로 충족합니다.

**A, C, D가 적절하지 않은 이유:**

- **A. S3 버킷을 생성합니다. S3 버킷에 대한 쓰기 권한이 있는 IAM 역할을 생성합니다. AWS CLI 를 사용하여 모든 파일을 S3 버킷에 로컬로 복사합니다.**
    - 이 방법은 모든 데이터를 인터넷을 통해 직접 전송해야 합니다. 70TB라는 대용량 데이터를 전송할 경우 상당한 네트워크 대역폭을 사용하고, 전송 시간이 매우 오래 걸릴 수 있습니다. "최소한의 네트워크 대역폭 사용" 및 "가능한 한 빨리"라는 요구사항을 충족하기 어렵습니다.
- **C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 서비스 엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.**
    - S3 파일 게이트웨이는 온프레미스 애플리케이션이 S3에 저장된 객체에 NFS 또는 SMB 프로토콜을 사용하여 액세스할 수 있도록 하는 서비스입니다. 이는 기존 데이터를 S3로 "마이그레이션"하기 위한 주된 솔루션이라기보다는, 온프레미스 시스템에서 S3 데이터를 파일 시스템처럼 사용할 때 적합합니다. 물론 S3 파일 게이트웨이를 통해 데이터를 S3로 "복사"할 수는 있지만, 70TB의 초기 대규모 마이그레이션에 있어서는 여전히 인터넷 대역폭에 의존하므로 "가능한 한 빨리"라는 요구사항을 충족하기 어렵고, "최소한의 네트워크 대역폭"이라는 측면에서도 Snowball Edge보다 효율적이지 않습니다. 특히 퍼블릭 엔드포인트를 사용하면 인터넷을 통해 데이터를 전송하게 됩니다.
- **D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 공용 VIF(가상 인터페이스)를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.**
    - Direct Connect는 온프레미스 네트워크와 AWS 간에 전용 네트워크 연결을 제공하여 네트워크 대역폭 사용 측면에서는 A나 C보다는 낫습니다. 하지만 Direct Connect를 "설정"하는 데 시간이 걸리고, 초기 구축 비용이 발생하며, "가능한 한 빨리"라는 요구사항에 즉시 부합하지 않을 수 있습니다. 70TB의 대량 데이터를 일회성으로 빠르게 마이그레이션하는 데에는 Snowball Edge가 훨씬 더 효율적인 경우가 많습니다. 또한, Direct Connect가 "최소한의 네트워크 대역폭"을 사용한다는 의미는 아니며, 단순히 "전용" 회선을 통해 대역폭을 확보하는 것을 의미합니다. Snowball Edge는 아예 네트워크를 사용하지 않고 물리적으로 데이터를 옮깁니다.

# 7

회사에 들어오는 메시지를 수집하는 응용 프로그램이 있습니다. 
그러면 수십 개의 다른애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비합니다. 
메시지 수는급격하게 변하며 때로는 초당 100,000 개로 갑자기 증가하기도 합니다. 
이 회사는 솔루션을 분리하고 확장성을 높이고자 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**D. 여러 Amazon Simple Queue Service(Amazon SOS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. 대기열의 메시지를 처리하도록 소비자 애플리케이션을 구성합니다.**

- **뛰어난 분리 (Decoupling):**
    - **Amazon SNS (Simple Notification Service):** 메시지를 **발행(Publish)**하고, 이 메시지를 받고 싶은 모든 **구독자(Subscribers)**에게 메시지를 **푸시(Push)**하는 서비스입니다. "일대다(one-to-many)" 또는 "팬아웃(fan-out)" 통신에 최적화되어 있습니다.
    발행/구독(Publish/Subscribe) 서비스입니다. 메시지를 수집하는 애플리케이션은 SNS 토픽에 메시지를 발행하기만 하면 됩니다. 이로써 메시지 생산자(수집 애플리케이션)는 누가, 몇 개의 소비자가 있는지 알 필요 없이 메시지를 보낼 수 있습니다.
    - **Amazon SQS (Simple Queue Service):** 메시지를 **대기열(Queue)에 저장**하고, 이 메시지를 소비자가 **가져갈(Poll)** 때까지 보관하는 서비스입니다. "일대일(one-to-one)" 또는 "일대다(one-to-many) 비동기 처리"에 최적화되어 있습니다.
    SNS 토픽에 여러 SQS 대기열을 구독시킬 수 있습니다. 각 소비자 애플리케이션 또는 마이크로서비스는 자신만의 SQS 대기열을 가질 수 있습니다. SNS 토픽에 메시지가 발행되면, 해당 메시지의 사본이 구독된 *모든* SQS 대기열로 전송됩니다.
- **탁월한 확장성 (Scalability):**
    - **SQS의 확장성:** SQS는 매우 확장성이 뛰어나고 탄력적입니다. 초당 수백만 개의 메시지 처리량을 지원하며, 서버를 프로비저닝하거나 관리할 필요 없이 들어오는 메시지 볼륨에 자동으로 확장됩니다.
    - **소비자 확장성:** 각 소비자 애플리케이션은 전용 SQS 대기열에 있는 메시지를 기반으로 독립적으로 처리량을 확장할 수 있습니다. 한 소비자가 지연되더라도 다른 소비자에게는 영향을 미치지 않습니다.
- **다중 소비자 지원 (Multiple Consumers):** SNS의 팬아웃(Fan-out) 패턴(하나의 SNS 토픽이 여러 SQS 대기열로 발행)은 여러 독립적인 소비자가 동일한 메시지를 처리해야 하는 시나리오를 위해 특별히 설계되었습니다. 각 소비자는 자신의 SQS 대기열에서 메시지 사본을 받습니다.
- **높은 신뢰성 (Reliability):** SQS 대기열은 메시지 내구성을 제공하여, 메시지가 소비자에 의해 처리될 때까지 안정적으로 저장됩니다.

**A, B, C가 적절하지 않은 이유:**

**A. Amazon Kinesis Data Analytics에 대한 메시지를 유지합니다. 메시지를 읽고 처리하도록 소비자 애플리케이션을 구성합니다.**

- **Kinesis Data Analytics의 주요 목적:** Kinesis Data Analytics는 주로 스트리밍 데이터의 *실시간 처리 및 분석*을 위한 서비스이며, SQL이나 Flink를 사용합니다. 메시지를 단순히 저장하고 여러 다양한 소비자 애플리케이션이 독립적으로 읽어가는 용도로는 적합하지 않습니다.
- **직접적인 분리/팬아웃 부재:** Kinesis Data Analytics는 스트림에서 데이터를 처리합니다. 수십 개의 다른 애플리케이션이 Kinesis Data Analytics에서 메시지를 빠르고 독립적으로 소비하려면 또 다른 계층이 필요하거나, 분석 애플리케이션의 동일한 출력에 대해 모두 경쟁하게 될 것입니다. 일반적인 다중 소비자용 메시지 큐 시스템이 아닙니다.
- **주요 수집/배포 메커니즘 아님:** Kinesis Data Analytics는 처리 계층이며, 이 특정 사용 사례에서 초기 수집 및 배포 계층으로는 적합하지 않습니다.

**B. Auto Scaling 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포하여 CPU 지표를 기반으로 EC2 인스턴스 수를 확장합니다.**

- **수집 애플리케이션 확장만 다룸:** 이 솔루션은 CPU 사용량에 따라 EC2 인스턴스를 추가하여 *수집 애플리케이션 자체*의 확장성만 다룹니다.
- **분리 부재:** 수집 애플리케이션과 소비자 애플리케이션 간의 분리를 제공하지 않습니다. 수집 애플리케이션은 여전히 소비자에게 직접 메시지를 전달하거나, 분배 메커니즘이 필요한 공유 스토리지에 메시지를 써야 합니다.
- **소비자 확장성/팬아웃 부재:** 수십 개의 다른 소비자 애플리케이션이 메시지를 빠르고 독립적으로 수신하고 처리할 수 있는 메커니즘을 제공하지 않습니다. 이 접근 방식은 소비자 측에서 병목 현상을 유발하거나 EC2 인스턴스에서 각 소비자로의 복잡한 직접 통합을 필요로 할 수 있습니다.
- **관리 오버헤드:** EC2 인스턴스와 Auto Scaling 그룹을 관리하는 것은 자동화되어 있지만, SQS 및 SNS와 같은 완전 관리형 서비스보다 더 많은 운영 오버헤드를 수반합니다.

**C. 단일 샤드를 사용하여 Amazon Kinesis Data Streams에 메시지를 씁니다. AWS Lambda 함수를 사용하여 메시지를 사전 처리하고 Amazon DynamoDB 에 저장합니다. 메시지를 처리하기 위해 DynamoDB에서 읽도록 소비자 애플리케이션을 구성합니다.**

- **단일 샤드의 한계:** 단일 Kinesis Data Stream 샤드는 처리량 제한(쓰기의 경우 1MB/초 또는 1,000레코드/초)이 있습니다. 초당 100,000개의 메시지는 단일 샤드를 즉시 압도할 것입니다. 샤드를 더 많이 프로비저닝할 수 있지만, "단일 샤드"로 시작하는 것은 제시된 규모에 근본적으로 결함이 있습니다.
- **DynamoDB를 메시지 큐로 사용 (안티 패턴):** DynamoDB는 빠른 NoSQL 데이터베이스이지만, "수십 개의 다른 애플리케이션 및 마이크로서비스"가 메시지를 빠르게 소비하기 위한 주요 메시지 큐로 사용하는 것은 일반적으로 안티 패턴입니다.
    - **폴링 (Polling):** 소비자는 새로운 메시지를 위해 DynamoDB를 지속적으로 폴링해야 하므로 비효율적이고 비용이 많이 듭니다.
    - **중복 처리/복잡성:** 어떤 메시지가 어떤 소비자에 의해 처리되었는지 관리하고, 동시 읽기를 처리하며, 각 소비자가 고유한 사본을 얻도록(또는 필요에 따라 모두 사본을 얻도록) 보장하는 것이 매우 복잡해집니다.
    - **처리량 모드:** DynamoDB는 프로비저닝된 처리량을 가집니다. 확장할 수 있지만, 임시 메시징 패턴을 위해 관리하는 것은 전용 메시지 큐에 비해 강점이 아닙니다.
- **Lambda를 이용한 사전 처리:** Lambda를 이용한 사전 처리는 가능하지만, 전반적인 분배 아키텍처에 결함이 있습니다.
- **팬아웃 부재:** DynamoDB는 여러 독립적인 소비자가 메시지의 자체 사본을 받는 팬아웃 모델을 본질적으로 지원하지 않습니다. 소비자는 동일한 테이블에서 읽어야 하므로, 경쟁과 복잡한 메시지 관리가 발생합니다.

# 8

회사에서 분산 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 애플리케이션은 다양한워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성됩니다. 이 회사는 탄력성과 확장성을 극대화하는 솔루션으로 애플리케이션을 현대화하려고 합니다.
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까?

**B. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열 크기에 따라 EC2 Auto Scaling을 구성합니다.**

- **Amazon SQS (Simple Queue Service) 대기열 사용:**
    - **비동기 처리:** 분산 애플리케이션에서 다양한 워크로드를 처리할 때 SQS는 작업(메시지)을 비동기적으로 처리할 수 있게 해줍니다. 이는 송신자(작업을 생성하는 부분)와 수신자(작업을 처리하는 컴퓨팅 노드)의 결합도를 낮춰 시스템의 탄력성을 높입니다.
    - **작업 버퍼링:** 갑작스러운 트래픽 급증 시 SQS 대기열은 작업을 임시로 저장하는 버퍼 역할을 하여 컴퓨팅 노드가 과부하되는 것을 방지합니다.
    - **내결함성:** SQS는 메시지를 안전하게 저장하고 전달하므로, 컴퓨팅 노드에 문제가 발생해도 작업이 유실될 위험이 적습니다.
- **Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드 구현:**
    - **탄력성:** Auto Scaling 그룹은 정의된 정책에 따라 EC2 인스턴스의 수를 자동으로 조정합니다. 이는 갑작스러운 부하 증가에 유연하게 대응하여 애플리케이션이 항상 충분한 컴퓨팅 자원을 확보하도록 합니다.
    - **확장성:** 필요에 따라 인스턴스를 자동으로 추가하거나 제거함으로써 수동 개입 없이도 애플리케이션의 처리 능력을 확장할 수 있습니다.
    - **고가용성:** 인스턴스에 문제가 발생하면 Auto Scaling 그룹이 자동으로 새로운 인스턴스를 시작하여 애플리케이션의 가용성을 유지합니다.
- **대기열 크기에 따라 EC2 Auto Scaling 구성:**
    - **실시간 부하 반영:** SQS 대기열의 메시지 수(대기열 크기)는 처리해야 할 작업의 양을 직접적으로 나타냅니다. 이 지표를 기반으로 Auto Scaling을 구성하면, 대기열에 메시지가 많아지면(처리할 작업이 많아지면) 자동으로 EC2 인스턴스를 늘리고, 메시지가 줄어들면(처리할 작업이 줄어들면) 인스턴스를 줄여 리소스 효율성을 극대화할 수 있습니다. 이는 "탄력성과 확장성을 극대화"하려는 요구 사항에 가장 직접적으로 부합하는 방법입니다.

**A, C, D가 적절하지 않은 이유:**

- **A. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 예약된 조정을 사용하도록 EC2 Auto Scaling을 구성합니다.**
    - SQS와 EC2 Auto Scaling 그룹을 사용하는 것은 좋지만, "예약된 조정"은 정기적이고 예측 가능한 부하 패턴에 더 적합합니다. 애플리케이션의 워크로드가 다양하고 예측하기 어렵다면, 예약된 조정만으로는 갑작스러운 부하 변화에 실시간으로 대응하기 어렵습니다. 따라서 탄력성을 극대화하기에는 부족합니다.
- **C. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail 을 구성합니다. 기본 서버의 부하를 기반으로 EC2 Auto Scaling 을 구성합니다.**
    - **AWS CloudTrail 사용의 부적절성:** AWS CloudTrail은 AWS API 호출 기록을 로깅하는 서비스로, 작업의 대상으로 사용하기에는 적합하지 않습니다. SQS와 같이 메시지를 저장하고 전달하는 기능이 없습니다.
    - **기본 서버 부하 기반 확장:** '기본 서버'라는 개념이 레거시 시스템의 중앙 집중식 제어 방식을 연상시킵니다. 분산 애플리케이션에서는 중앙 집중식 서버의 부하보다는 실제 처리해야 할 작업의 양(예: 대기열의 메시지 수)에 따라 확장하는 것이 훨씬 효율적이고 탄력적입니다. 또한, 기본 서버 자체가 병목 지점이 될 수 있습니다.
- **D. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 컴퓨팅 노드의 부하를 기반으로 EC2 Auto Scaling을 구성합니다.**
    - **Amazon EventBridge 사용의 부적절성:** Amazon EventBridge는 다양한 AWS 서비스 및 SaaS 애플리케이션의 이벤트를 라우팅하고 처리하는 서비스입니다. 즉, 이벤트 기반 아키텍처에서 이벤트 소스와 대상을 연결하는 데 사용되지만, SQS처럼 작업(메시지)을 버퍼링하고 비동기적으로 처리하기 위한 대기열 서비스는 아닙니다. 메시지 안정성이나 재시도 메커니즘 등 큐의 핵심 기능을 제공하지 않습니다.
    - **컴퓨팅 노드의 부하 기반 확장:** 컴퓨팅 노드의 부하(예: CPU 사용률)를 기반으로 Auto Scaling을 구성하는 것은 일반적인 방법이지만, SQS 대기열의 메시지 수를 기반으로 하는 것보다 "선행 지표(leading indicator)"로서의 역할이 약합니다. 즉, 컴퓨팅 노드의 부하가 높아진다는 것은 이미 처리할 작업이 많아졌다는 것을 의미하므로, 미리 확장하여 병목 현상을 방지하는 데는 대기열 크기가 더 효과적입니다. 대기열의 메시지 수가 증가하면 컴퓨팅 노드의 부하가 높아지기 전에 미리 인스턴스를 추가할 수 있습니다.

# 9

회사는 데이터 센터에서 SMB 파일 서버를 실행하고 있습니다. 파일 서버는 파일이 생성된후 처음 며칠 동안 자주 액세스하는 대용량 파일을 저장합니다. 7 일이 지나면 파일에 거의액세스하지 않습니다.
총 데이터 크기가 증가하고 있으며 회사의 총 저장 용량에 가깝습니다. 솔루션 설계자는 가장 최근에 액세스한 파일에 대한 저지연 액세스를 잃지 않으면서 회사의 사용 가능한 저장 공간을 늘려야 합니다. 
솔루션 설계자는 향후 스토리지 문제를 방지하기 위해 파일 수명 주기 관리도 제공해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**B. Amazon S3 파일 게이트웨이를 생성하여 회사의 스토리지 공간을 확장합니다. S3 수명주기 정책을 생성하여 7일 후에 데이터를 S3 Glacier Deep Archive로 전환합니다.**

- **저장 공간 확장 및 비용 효율성:** Amazon S3 파일 게이트웨이는 온프레미스 SMB 파일 서버의 캐시로 작동하며, 실제 데이터는 확장성이 뛰어나고 비용 효율적인 클라우드 스토리지인 Amazon S3에 저장됩니다. 이를 통해 회사의 총 저장 용량 문제를 해결할 수 있습니다.
- **저지연 액세스 유지:** S3 파일 게이트웨이는 자주 액세스하는 파일(최근 며칠 동안의 파일)을 온프레미스 캐시에 보관하여 저지연 액세스를 제공합니다. 이는 사용자가 파일 생성 후 처음 며칠 동안 자주 액세스하는 요구 사항을 충족합니다.
- **파일 수명 주기 관리:** S3 수명 주기 정책을 사용하여 7일이 지난 파일을 자동으로 S3 Glacier Deep Archive와 같은 비용 효율적인 스토리지 클래스로 전환할 수 있습니다. 이는 "7일이 지나면 파일에 거의 액세스하지 않습니다"라는 요구 사항을 충족하며, 장기적인 스토리지 비용을 절감합니다. S3 Glacier Deep Archive는 매우 저렴한 비용으로 데이터를 보관할 수 있습니다.
- **향후 스토리지 문제 방지:** S3의 무제한 확장성은 향후 데이터 증가에 따른 스토리지 문제를 효과적으로 방지할 수 있도록 합니다.

**A,C,D가 적절하지 않은 이유:**

- **A. AWS DataSync 를 사용하여 SMB 파일 서버에서 AWS 로 7 일이 지난 데이터를 복사합니다.**
    - **부분적인 솔루션:** DataSync는 데이터를 AWS로 복사하는 데 유용하지만, 이는 일회성 또는 주기적인 복사 작업에 가깝습니다. 파일 수명 주기 관리 (예: 7일 후 자동으로 더 저렴한 스토리지 클래스로 전환)를 직접 제공하지 않습니다.
    - **액세스 복잡성:** 복사된 데이터에 온프레미스 SMB 경로를 통해 직접 액세스하기 어렵습니다. 새로운 액세스 방식을 구성해야 할 수 있습니다.
    - **캐싱 없음:** 저지연 액세스를 위한 온프레미스 캐싱 기능이 없어, 자주 액세스하는 파일에 대한 액세스 속도가 느려질 수 있습니다.
- **C. Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하여 회사의 저장 공간을 확장합니다.**
    - **온프레미스 SMB 서버와 직접적인 연동 어려움:** FSx for Windows File Server는 클라우드 기반의 완전 관리형 Windows 파일 서버입니다. 기존 온프레미스 SMB 파일 서버의 확장판으로 직접 연동하여 "저지연 액세스를 잃지 않으면서" 저장 공간을 확장하는 시나리오에 적합하지 않을 수 있습니다. 데이터를 FSx로 완전히 마이그레이션해야 할 수 있습니다.
    - **비용 효율성:** 대량의 데이터를 장기 보관하는 데 S3 Glacier Deep Archive만큼 비용 효율적이지 않을 수 있습니다. FSx는 성능이 중요한 작업에 더 적합하며, 장기 보관용으로는 비용 부담이 있을 수 있습니다.
    - **수명 주기 관리 부족:** 파일 수명 주기 정책을 FSx 내에서 직접적으로 S3 Glacier Deep Archive와 같이 세밀하게 제어하기 어렵습니다.
- **D. 각 사용자의 컴퓨터에 유틸리티를 설치하여 Amazon S3 에 액세스합니다. S3 수명 주기 정책을 생성하여 7일 후 데이터를 S3 Glacier Flexible Retrieval로 전환합니다.**
    - **사용자 경험 및 관리 복잡성:** 각 사용자의 컴퓨터에 유틸리티를 설치하여 S3에 직접 액세스하게 하는 것은 사용자 경험 측면에서 좋지 않고, 관리 및 보안 측면에서 복잡성을 야기합니다. 기존 SMB 파일 서버와 같은 익숙한 파일 공유 환경을 제공하지 못합니다.
    - **저지연 액세스 문제:** 파일 서버를 통하지 않고 S3에 직접 액세스하는 경우, 특히 자주 액세스하는 파일에 대한 저지연 액세스를 보장하기 어렵습니다. SMB 프로토콜을 통한 접근성을 잃게 됩니다.
    - **기존 SMB 환경 유지 어려움:** 기존 SMB 파일 서버 환경을 유지하면서 스토리지 문제를 해결해야 하는 요구 사항을 충족하지 못합니다.

# 10

회사는 AWS 에서 전자 상거래 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 처리할 Amazon API Gateway REST API에 새 주문에 대한 정보를 보냅니다. 회사는 주문이접수된 순서대로 처리되기를 원합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**B. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Queue Service (Amazon SQS) FIFO 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS FIFO 대기열을 구성합니다.**

- **Amazon SQS FIFO(First-In, First-Out) 대기열:** FIFO 대기열은 메시지가 **전송된 정확한 순서대로 수신 및 처리되도록 보장**하기 위해 특별히 설계되었습니다. 이는 "주문이 접수된 순서대로 처리"되어야 한다는 핵심 요구사항에 정확히 부합합니다.
- **API Gateway 통합:** API Gateway는 SQS와 직접 통합될 수 있으므로, API가 추가적인 중간 Lambda 함수 없이 직접 메시지를 대기열로 보낼 수 있습니다.
- **Lambda 트리거:** SQS 대기열은 AWS Lambda 함수를 트리거하도록 구성할 수 있습니다. Lambda는 SQS FIFO 대기열에서 메시지를 도착한 순서대로 가져와 처리하므로, 주문 처리 순서가 유지됩니다.

**A,C,D가 적절하지 않은 이유:**

**A. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. AWS Lambda 함수를 주제에 구독하여 처리를 수행합니다.**

- **Amazon SNS의 메시지 순서 보장:** Amazon SNS는 메시지 순서를 보장하지 않습니다. SNS는 여러 구독자에게 메시지를 효율적으로 분산하는 "팬아웃(fan-out)" 시나리오에 적합합니다. 메시지 전달 시 또는 재시도 시 순서가 뒤바뀔 수 있으므로, 엄격한 순서 보장이 필요한 주문 처리에는 적합하지 않습니다.

**C. API Gateway 권한 부여자를 사용하여 애플리케이션이 주문을 처리하는 동안 모든 요청을 차단합니다.**

- **요청 차단 및 확장성 문제:** 이 솔루션은 전자상거래 애플리케이션에 근본적으로 부적합합니다. 주문이 처리되는 동안 모든 요청을 차단한다는 것은 API가 전 세계적으로 단일 스레드 병목 현상이 되어 확장성을 심각하게 제한하고 사용자 경험을 저해합니다. 한 번에 하나의 주문만 처리할 수 있게 되므로, 실제 전자상거래 환경에서는 비현실적입니다.
- **권한 부여자의 역할:** API Gateway 권한 부여자(Authorizer)는 인증 및 인가(Authentication & Authorization)를 위한 것이지, 비즈니스 로직의 순차적 처리를 관리하기 위한 기능이 아닙니다.

**D. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS 표준 대기열을 구성합니다.**

- **Amazon SQS 표준 대기열의 순서 보장:** Amazon SQS 표준 대기열은 엄격한 메시지 순서를 보장하지 않습니다. 최선을 다해 순서를 지키려 노력하지만, 높은 부하가 걸리거나 오류가 발생할 경우 메시지가 순서 없이 전달될 수 있습니다. 이는 "주문이 접수된 순서대로 처리"되어야 한다는 요구사항에 직접적으로 위배됩니다. 표준 대기열은 높은 처리량과 최소 한 번의 전송(at-least-once delivery)이 중요한 많은 사용 사례에 적합하지만, 엄격한 순서 보장이 필요한 경우에는 적합하지 않습니다.

# 11

회사에 Amazon EC2 인스턴스에서 실행되고 Amazon Aurora 데이터베이스를 사용하는 애플리케이션이 있습니다. 
EC2 인스턴스는 파일에 로컬로 저장된 사용자 이름과 암호를 사용하여 데이터베이스에 연결합니다. 회사는 자격 증명 관리의 운영 오버헤드를 최소화하려고 합니다.
솔루션 설계자는 이 목표를 달성하기 위해 무엇을 해야 합니까?

**A. AWS Secrets Manager를 사용합니다. 자동 회전을 켭니다.**

**AWS Secrets Manager**는 **데이터베이스 자격 증명, API 키, 기타 비밀 정보**를 안전하게 저장하고 관리할 수 있는 **전용 서비스**입니다. 다음 기능들이 문제의 요구사항에 딱 맞습니다:

- **자격 증명 자동 회전(자동갱신)**: DB 자격 증명을 주기적으로 자동으로 변경해줄 수 있습니다.
- **IAM 연동**: EC2 인스턴스에 IAM 역할을 할당하면 애플리케이션이 자격 증명을 안전하게 Secrets Manager에서 받아올 수 있습니다.
- **운영 오버헤드 최소화**: 더 이상 사람이 수동으로 비밀번호를 관리하거나 갱신하지 않아도 됩니다.

즉, **비밀번호를 파일에 저장하는 위험을 제거하고**, **자격 증명 자동 회전을 통해 보안성과 효율성을 동시에 확보**할 수 있습니다.

**B,C,D가 적절하지 않은 이유:**

**B. AWS Systems Manager Parameter Store 를 사용합니다. 자동 회전을 켭니다.**

- Parameter Store는 비밀 값도 저장할 수는 있지만, 자동 회전 기능이 없습니다.
- 자격 증명을 안전하게 저장할 수는 있지만, Secrets Manager만큼 자격 증명 전용 기능(예: 자동 교체, DB 연동, 보안 감사)이 강력하지 않습니다.
- 따라서, 자격 증명 운영 오버헤드를 줄이는 데는 부족합니다.

**C. AWS Key Management Service(AWS KMS) 암호화 키로 암호화된 객체를 저장할 Amazon S3 버킷을 생성합니다. 자격 증명 파일을 S3 버킷으로 마이그레이션합니다. 애플리케이션이 S3 버킷을 가리키도록 합니다.**

S3 버킷에 암호화된 자격 증명 파일 저장

- 암호화하고 저장하는 것은 가능하지만, 자동 회전이 안 됩니다.
- 자격 증명을 EC2 애플리케이션이 S3에서 수동으로 다운로드해서 사용해야 하므로 보안성과 자동화 측면에서 미흡합니다.
- 결국 자격 증명을 주기적으로 갱신하고 업데이트하는 사람의 작업이 계속 필요합니다.

**D. 각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 새 EBS 볼륨을 각 EC2 인스턴스에 연결합니다. 자격 증명 파일을 새 EBS 볼륨으로 마이그레이션합니다. 애플리케이션이 새 EBS 볼륨을 가리키도록 합니다.**

암호화된 EBS 볼륨에 자격 증명 저장

- 저장소 자체는 안전할 수 있지만, 자격 증명을 파일에 저장하는 근본적인 구조는 바뀌지 않습니다.
- 회전, 버전 관리, 접근 제어 등 자동화 기능이 없음.
- 결국 사람이 수동으로 자격 증명을 갱신하고 배포해야 하므로 운영 오버헤드가 그대로입니다.

# 12

글로벌 회사는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다.
회사는 정적 데이터를 Amazon S3 버킷에 저장합니다. 회사는 정적 데이터 및 동적 데이터의 성능을 개선하고 대기 시간을 줄이기를 원합니다. 회사는 Amazon Route 53 에등록된 자체 도메인 이름을 사용하고 있습니다.
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**A. S3 버킷과 ALB 를 오리진으로 포함하는 Amazon CloudFront 배포를 생성합니다. CloudFront 배포로 트래픽을 라우팅하도록 Route 53 을 구성합니다.**

- **CloudFront의 기능:** Amazon CloudFront는 콘텐츠 전송 네트워크(CDN) 서비스로, 엣지 로케이션에 콘텐츠를 캐싱하여 사용자에게 더 가까운 곳에서 데이터를 제공함으로써 대기 시간을 줄이고 성능을 향상시킵니다.
- **정적 및 동적 데이터 처리:**
    - **정적 데이터 (S3):** S3 버킷을 오리진으로 CloudFront를 구성하면, 정적 데이터(예: 이미지, CSS, JavaScript 파일)가 CloudFront 엣지 캐시에 저장되어 사용자 요청 시 S3까지 가지 않고도 빠르게 전송됩니다.
    - **동적 데이터 (ALB):** ALB를 오리진으로 CloudFront를 구성하면, 동적 콘텐츠 요청도 CloudFront 엣지 로케이션을 통해 가장 가까운 ALB로 라우팅되어 네트워크 홉을 줄이고 전반적인 응답 시간을 개선할 수 있습니다. CloudFront는 동적 콘텐츠에 대해서도 TCP 연결 최적화, Keep-Alive, HTTP/2 지원 등을 통해 성능을 향상시킵니다.
- **Route 53 통합:** Route 53을 CloudFront 배포로 트래픽을 라우팅하도록 구성하면, 회사의 자체 도메인 이름을 사용하여 CloudFront를 통해 웹 애플리케이션에 접근할 수 있게 됩니다. 이는 사용자 친화적인 URL을 제공하며 DNS 레코드 관리를 용이하게 합니다.

**B,C,D가 적절하지 않은 이유:**

**B. ALB 가 오리진인 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. CloudFront 배포로 트래픽을 라우팅하도록 Route 53 을 구성합니다.**

ALB가 오리진인 CloudFront 배포 + S3 버킷을 엔드포인트로 포함하는 AWS Global Accelerator:

- AWS Global Accelerator는 주로 TCP/UDP 트래픽의 성능을 최적화하고 특정 리전 장애 시 페일오버를 지원하는 데 초점을 맞춘 서비스입니다. 웹 애플리케이션의 정적/동적 콘텐츠 전송에는 CloudFront가 더 적합합니다. Global Accelerator는 S3를 엔드포인트로 직접 연결하기보다, S3를 오리진으로 하는 CloudFront를 앞단에 두는 것이 일반적입니다. S3를 직접 Global Accelerator 엔드포인트로 사용하는 것은 정적 웹사이트 호스팅 시나리오에서 제한적으로 사용될 수 있지만, CloudFront가 제공하는 캐싱 기능은 없습니다.
- 정적 데이터를 S3에 두고 Global Accelerator를 사용하면 캐싱 이점을 얻을 수 없으므로 성능 개선에 제한적입니다.

**C. S3 버킷을 오리진으로 포함하는 Amazon CloudFront 배포를 생성합니다. ALB 및 CloudFront 배포를 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 만듭니다. 사용자 지정 도메인 이름을 웹 애플리케이션의 끝점으로 사용합니다.**

S3 버킷을 오리진으로 포함하는 CloudFront 배포 + ALB 및 CloudFront 배포를 엔드포인트로 포함하는 AWS Global Accelerator:

- 이 솔루션은 S3에 대한 CloudFront 배포는 올바르지만, ALB와 CloudFront 배포를 모두 Global Accelerator의 엔드포인트로 사용하는 것은 불필요하게 복잡합니다. CloudFront 자체가 ALB를 오리진으로 가질 수 있으므로, CloudFront 뒤에 Global Accelerator를 두는 것은 중복되거나 비효율적일 수 있습니다.
- 또한, "가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 만들고 웹 애플리케이션의 끝점으로 사용한다"는 부분은 CloudFront를 통한 단일 진입점 구성에 비해 복잡하며, 모든 웹 트래픽(정적/동적)을 CloudFront로 통합하는 A 옵션보다 효율성이 떨어집니다.

**D. ALB 가 오리진인 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 
두 개의 도메인 이름을만듭니다. 하나의 도메인 이름이 동적 콘텐츠의 CloudFront DNS 이름을 가리키도록 합니다.
다른 도메인 이름이 정적 콘텐츠에 대한 가속기 DNS 이름을 가리키도록 합니다. 도메인 이름을 웹 애플리케이션의 끝점으로 사용합니다.**

ALB가 오리진인 CloudFront 배포 + S3 버킷을 엔드포인트로 포함하는 AWS Global Accelerator + 두 개의 도메인 이름:

- 이 솔루션은 B와 유사하게 Global Accelerator의 부적절한 사용이 문제점입니다. 정적 콘텐츠에 Global Accelerator를 사용하면 캐싱 이점을 놓치게 됩니다.
- 두 개의 도메인 이름(하나는 동적, 다른 하나는 정적)을 사용하는 것은 사용자 경험 측면에서 좋지 않고, 웹 애플리케이션의 아키텍처를 복잡하게 만듭니다. 하나의 도메인 아래에서 CloudFront를 통해 정적/동적 콘텐츠를 모두 제공하는 것이 일반적이고 효율적인 방법입니다. CloudFront는 동작(behaviors)을 통해 다른 오리진(S3 또는 ALB)으로 요청을 라우팅할 수 있습니다.

B, C, D 옵션에서 "S3 버킷을 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다"라고 되어 있었던 것은, Global Accelerator가 S3 버킷으로 트래픽을 라우팅하여 성능을 개선하려는 시나리오를 가정한 것입니다. 하지만 웹 애플리케이션의 정적 콘텐츠 제공에는 CloudFront의 캐싱 기능이 훨씬 더 적합하기 때문에 해당 옵션들이 정답이 아니었던 것입니다.

# 13

회사는 AWS 인프라에 대한 월별 유지 관리를 수행합니다. 이러한 유지 관리 활동 중에 회사는 여러 AWS 리전에서 MySQL 용 Amazon RDS 데이터베이스에 대한 자격 증명을 교체해야 합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

**A. 자격 증명을 AWS Secrets Manager 에 암호로 저장합니다. 필요한 리전에 대해 다중 리전 비밀 복제를 사용합니다. 일정에 따라 보안 암호를 교체하도록 Secrets Manager 를 구성합니다.**

- **AWS Secrets Manager의 목적:** Secrets Manager는 데이터베이스 자격 증명, API 키 등과 같은 비밀을 안전하게 저장하고 관리하도록 특별히 설계된 서비스입니다. 비밀 관리에 필요한 모든 기능을 제공합니다.
- **자동 교체:** Secrets Manager는 내장된 자동 교체 기능을 제공하여 운영 오버헤드를 최소화합니다. RDS 자격 증명 교체를 위한 템플릿과 통합되어 있어 손쉽게 설정할 수 있습니다.
- **다중 리전 복제:** Secrets Manager는 다중 리전 비밀 복제를 지원하여 여러 AWS 리전에 걸쳐 비밀을 동기화할 수 있습니다. 이는 여러 리전에서 RDS 데이터베이스 자격 증명을 교체해야 하는 요구 사항을 직접적으로 충족합니다.
- **최소한의 운영 오버헤드:** Secrets Manager는 비밀의 저장, 교체, 감사 및 관리를 위한 완전 관리형 서비스를 제공하므로, 수동으로 스크립트를 작성하거나 추가적인 인프라를 구축할 필요 없이 운영 오버헤드가 매우 낮습니다.

**B,C,D가 적절하지 않은 이유:**

**B. 보안 문자열 파라미터를 생성하여 AWS Systems Manager 에 자격 증명을 보안 암호로 저장합니다. 필요한 리전에 대해 다중 리전 비밀 복제를 사용합니다. 일정에 따라 암호를 교체하도록 Systems Manager 를 구성합니다.**

- **Systems Manager Parameter Store의 제한:** Systems Manager Parameter Store는 일반적인 설정 데이터나 간단한 비밀을 저장하는 데 유용하지만, Secrets Manager만큼 강력한 비밀 관리 및 자동 교체 기능을 제공하지 않습니다. 특히 RDS 자격 증명의 자동 교체를 위한 기본 제공 통합 기능이 없습니다.
- **수동 설정 필요:** Parameter Store를 사용하여 자격 증명을 교체하려면 Lambda 함수 등을 사용하여 교체 로직을 직접 구현하고 관리해야 하므로 운영 오버헤드가 더 커집니다. Parameter Store는 다중 리전 복제 기능을 직접 제공하지 않으며, 이를 위해서는 추가적인 자동화 및 복제 메커니즘을 구성해야 합니다.

**C. 서버 측 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 호출하여 자격 증명을 교체합니다.**

- **비밀 관리의 목적에 부적합:** S3는 파일 저장에 적합한 서비스이지, 동적으로 교체해야 하는 민감한 비밀을 저장하고 관리하는 데 최적화된 서비스가 아닙니다. S3는 버전 관리를 지원하지만, Secrets Manager가 제공하는 비밀 라이프사이클 관리 기능(예: 사용 중인 비밀과 과거 비밀 관리)이 부족합니다.
- **높은 운영 오버헤드:** S3에 비밀을 저장하고 Lambda 함수를 통해 교체 로직을 직접 구현해야 하므로 상당한 개발 및 유지 보수 오버헤드가 발생합니다. 비밀의 암호화, 접근 제어, 감사, 그리고 특히 교체 로직까지 모두 직접 관리해야 합니다. 다중 리전에서 비밀을 동기화하는 것도 별도로 구현해야 합니다.

**D. AWS Key Management Service(AWS KMS) 다중 리전 고객 관리형 키를 사용하여 자격 증명을 비밀로 암호화합니다. Amazon DynamoDB 전역 테이블에 암호를 저장합니다. AWS Lambda 함수를 사용하여 DynamoDB 에서 암호를 검색합니다. RDS API 를 사용하여 비밀을 교체합니다.**

- **복잡하고 불필요한 아키텍처:** 이 솔루션은 KMS, DynamoDB, Lambda를 조합하여 비밀 관리 시스템을 직접 구축하는 것에 해당합니다. KMS는 암호화 서비스이며, DynamoDB는 NoSQL 데이터베이스입니다. 이들을 조합하여 비밀 관리 시스템을 구축하는 것은 과도하게 복잡하며, 이미 Secrets Manager라는 적절한 관리형 서비스가 존재합니다.
- **높은 운영 오버헤드:** 비밀을 암호화하고, DynamoDB에 저장하고, 다중 리전에서 DynamoDB 전역 테이블을 설정하고, Lambda 함수를 작성하여 비밀을 검색하고 RDS API를 호출하여 교체하는 모든 로직을 직접 구현하고 유지 보수해야 합니다. 이는 상당한 개발 및 운영 오버헤드를 수반하며, Secrets Manager가 제공하는 간편한 자동 교체 기능을 활용하지 못합니다.

# 14

회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 전자 상거래 애플리케이션을 실행합니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 CPU 사용률 메트릭을 기반으로 확장됩니다.
전자 상거래 애플리케이션은 대규모 EC2 인스턴스에서 호스팅되는 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장합니다. 애플리케이션 로드가 증가하면 데이터베이스의 성능이 빠르게 저하됩니다. 애플리케이션은 쓰기 트랜잭션보다 더 많은 읽기 요청을 처리합니다. 
이 회사는 고가용성을 유지하면서 예측할 수 없는 읽기 워크로드의 수요를 충족하도록 데이터베이스를 자동으로 확장하는솔루션을 원합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**C. 다중 AZ 배포와 함께 Amazon Aurora 를 사용합니다. Aurora 복제본을 사용하여 Aurora Auto Scaling 을 구성합니다.**

- **읽기 워크로드 확장:** Amazon Aurora는 최대 15개의 읽기 전용 Aurora 복제본을 지원하며, 이 복제본들은 동일한 기본 스토리지 볼륨을 공유합니다. 이를 통해 애플리케이션의 읽기 요청을 분산시켜 예측할 수 없는 읽기 워크로드의 수요를 효과적으로 충족할 수 있습니다.
- **고가용성:** 다중 AZ(Availability Zone) 배포는 데이터베이스 인스턴스가 여러 가용 영역에 분산되어 있어 한 가용 영역에 장애가 발생하더라도 서비스 중단 없이 애플리케이션을 계속 실행할 수 있도록 보장합니다. Aurora는 자동으로 복제본을 프로비저닝하고 관리하여 고가용성을 제공합니다.
- **자동 확장:** Aurora Auto Scaling은 정의된 지표(예: CPU 사용률, 연결 수)에 따라 자동으로 Aurora 복제본을 추가하거나 제거하여 워크로드 변화에 맞춰 데이터베이스를 유연하게 확장합니다. 이는 수동 개입 없이도 성능 저하를 방지하고 비용 효율성을 높이는 데 도움이 됩니다.
- **MySQL 호환성:** 기존 MySQL 8.0 데이터베이스를 사용하고 있으므로, MySQL과 호환되는 Amazon Aurora는 최소한의 변경으로 마이그레이션이 가능하여 전환 부담을 줄여줍니다.
- **쓰기 성능:** Aurora는 분산형, 자가 치유형 스토리지 시스템을 사용하여 뛰어난 쓰기 성능을 제공합니다. 이는 애플리케이션의 트랜잭션 데이터 요구 사항을 충족하는 데 중요합니다.

**A, B, D가 적절하지 않은 이유**

**A. 리더 및 컴퓨팅 기능을 위해 단일 노드와 함께 Amazon Redshift 를 사용하십시오.**

- **트랜잭션 데이터베이스 부적합:** Amazon Redshift는 데이터 웨어하우징 및 분석 워크로드에 최적화된 서비스입니다. OLTP(온라인 트랜잭션 처리)와 같은 실시간 트랜잭션 데이터 처리에는 적합하지 않습니다. 전자 상거래 애플리케이션은 트랜잭션 데이터를 저장하므로 Redshift는 올바른 선택이 아닙니다.
- **단일 노드:** 단일 노드는 고가용성을 제공하지 못하며, 노드에 장애가 발생할 경우 애플리케이션 가용성에 문제가 생길 수 있습니다.
- **확장성 부족:** 단일 노드로는 예측 불가능한 읽기 워크로드의 수요를 효과적으로 충족하기 어렵습니다.

**B. 단일 AZ 배포와 함께 Amazon RDS 사용 다른 가용 영역에 리더 인스턴스를 추가하도록 Amazon RDS 를 구성합니다.**

- **단일 AZ 배포의 고가용성 문제:** 단일 AZ 배포는 마스터 인스턴스가 한 가용 영역에만 존재하므로, 해당 가용 영역에 장애가 발생하면 데이터베이스가 중단되어 고가용성 요구 사항을 충족하지 못합니다. 다른 가용 영역에 리더 인스턴스를 추가하더라도 이는 읽기 확장성을 위한 것이며 마스터 인스턴스의 가용성 문제에 대한 근본적인 해결책이 될 수 없습니다.
- **수동 확장:** Amazon RDS 읽기 복제본은 읽기 워크로드를 분산하는 데 도움이 되지만, Aurora Auto Scaling처럼 자동으로 복제본을 추가하거나 제거하는 기능은 제공하지 않습니다. 즉, 예측 불가능한 워크로드 변화에 대한 자동 확장을 지원하지 않습니다.
- **성능 제한:** 일반 Amazon RDS는 Aurora만큼의 고성능 및 확장성을 제공하지 못할 수 있습니다.

**D. EC2 스팟 인스턴스와 함께 Memcached 용 Amazon ElastiCache 를 사용합니다.**

- **데이터베이스 솔루션 아님:** Amazon ElastiCache (Memcached 또는 Redis)는 인메모리 캐싱 서비스입니다. 이는 데이터베이스의 읽기 성능을 향상시키는 데 도움을 줄 수 있지만, 트랜잭션 데이터를 영구적으로 저장하는 데이터베이스 자체를 대체할 수 없습니다. 질문은 "데이터베이스를 자동으로 확장하는 솔루션"을 요구하고 있습니다.
- **스팟 인스턴스:** EC2 스팟 인스턴스는 비용 효율적이지만, 인스턴스가 언제든지 종료될 수 있다는 특성 때문에 데이터베이스와 같은 중요한 지속적인 서비스에 적합하지 않습니다. 고가용성이 요구되는 시나리오에는 부적합합니다.

결론적으로, Amazon Aurora는 뛰어난 읽기 확장성, 고가용성, 자동 확장 기능 및 MySQL 호환성을 제공하여 회사의 요구 사항을 가장 효과적으로 충족합니다.

# 15

최근에 AWS 로 마이그레이션한 회사가 프로덕션 VPC 로 들어오고 나가는 트래픽을 보호하는 솔루션을 구현하려고 합니다. 이 회사는 사내 데이터 센터에 검사 서버를 가지고 있었습니다. 검사 서버는 트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업을 수행했습니다. 
회사는 AWS 클라우드에서 동일한 기능을 갖기를 원합니다.어떤 솔루션이 이러한 요구 사항을 충족합니까?

**C. AWS 네트워크 방화벽을 사용하여 프로덕션 VPC 에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 생성합니다.**

- **포괄적인 네트워크 트래픽 검사 및 필터링:** AWS 네트워크 방화벽은 상태 저장(stateful) 및 비상태 저장(stateless) 패킷 검사를 모두 제공합니다. 이는 IP 주소, 포트, 프로토콜, 그리고 애플리케이션 계층 정보(예: 도메인 이름, URL)를 기반으로 트래픽을 필터링하고 검사하는 기능을 제공합니다. 이는 온프레미스 검사 서버가 수행했던 트래픽 흐름 검사 및 트래픽 필터링 작업을 AWS 환경에서 가장 유사하게 대체할 수 있는 서비스입니다.
- **VPC 트래픽 보호:** AWS 네트워크 방화벽은 VPC 내의 트래픽(Inbound, Outbound, 동서 트래픽)을 중앙에서 보호할 수 있도록 설계되었습니다. 이를 통해 프로덕션 VPC로 들어오고 나가는 모든 트래픽에 대한 심층적인 보안 검사를 적용할 수 있습니다.
- **관리 용이성 및 확장성:** AWS 네트워크 방화벽은 완전 관리형 서비스이므로, 인프라를 직접 프로비저닝하거나 관리할 필요 없이 높은 가용성과 확장성을 제공합니다. 보안 규칙을 유연하게 정의하고 관리할 수 있습니다.

**A, B, D가 적절하지 않은 이유:**

**A. 프로덕션 VPC에서 트래픽 검사 및 트래픽 필터링에 Amazon GuardDuty를 사용합니다.**

- Amazon GuardDuty는 지능형 위협 탐지 서비스입니다. VPC 흐름 로그, DNS 로그, AWS CloudTrail 이벤트와 같은 다양한 데이터 소스를 분석하여 비정상적이거나 악의적인 활동을 식별하고 경고를 생성합니다. 하지만 GuardDuty는 **능동적으로 트래픽을 검사하거나 필터링하는 방화벽 기능을 제공하지 않습니다.** 즉, 탐지는 하지만 차단은 직접 수행하지 않습니다. 회사의 요구 사항은 "트래픽 흐름 검사 및 트래픽 필터링"이므로, GuardDuty는 필터링 기능을 충족하지 못합니다.

**B. 트래픽 미러링을 사용하여 트래픽 검사 및 필터링을 위해 프로덕션 VPC 의 트래픽을 미러링합니다.**

- 트래픽 미러링은 특정 ENI(Elastic Network Interface)의 트래픽 사본을 지정된 대상(예: 네트워크 분석 어플라이언스)으로 전송하는 기능입니다. 이를 통해 트래픽을 검사하고 분석할 수 있지만, **직접적으로 트래픽을 필터링하거나 차단하는 기능을 제공하지는 않습니다.** 미러링된 트래픽을 수신하여 분석하는 별도의 검사 서버(가상 어플라이언스)를 구축해야 하며, 이 서버가 필터링 기능을 수행해야 합니다. 이는 온프레미스 검사 서버와 유사한 복잡성을 AWS 환경에서 다시 구축하는 방식이 될 수 있으며, 완전 관리형 솔루션으로서의 AWS Network Firewall만큼 효율적이지 않습니다.

**D. AWS Firewall Manager 를 사용하여 프로덕션 VPC 에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 생성합니다.**

- AWS Firewall Manager는 AWS Organizations 내에서 AWS WAF, AWS Shield Advanced, Amazon VPC 보안 그룹, 그리고 **AWS Network Firewall의 방화벽 규칙을 중앙에서 관리하고 배포하는 서비스입니다.** Firewall Manager 자체는 트래픽 검사 및 필터링 기능을 직접 수행하지 않습니다. 대신, AWS Network Firewall과 같은 다른 보안 서비스의 규칙을 여러 계정 및 VPC에 걸쳐 일관되게 적용하고 관리하는 데 사용됩니다. 즉, Firewall Manager는 Network Firewall의 **관리 도구**이지, Network Firewall 자체의 기능을 대체하는 것은 아닙니다. 회사의 요구 사항은 "트래픽 검사 및 트래픽 필터링에 필요한 규칙을 생성"하고 적용하는 것이므로, Firewall Manager는 이 규칙을 *어디에* 적용할지 관리하는 역할을 할 뿐, 실제 검사 및 필터링을 수행하는 서비스는 AWS Network Firewall입니다.

따라서 회사의 요구 사항인 트래픽 흐름 검사 및 트래픽 필터링 기능을 AWS 클라우드에서 구현하는 데 가장 적합한 직접적인 솔루션은 AWS Network Firewall입니다.

# 16

회사는 AWS 에서 데이터 레이크를 호스팅합니다. 데이터 레이크는 Amazon S3 및 PostgreSQL 용 Amazon RDS의 데이터로 구성됩니다. 
이 회사는 데이터 시각화를 제공하고 데이터 레이크 내의 모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. 
회사의 관리 팀만 모든 시각화에 대한 전체 액세스 권한을 가져야 합니다. 나머지 회사는 제한된 액세스
권한만 가져야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

**B. Amazon QuickSight 에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 사용자 및 그룹과 대시보드를 공유합니다.**

- **포괄적인 데이터 소스 지원:** Amazon QuickSight는 Amazon S3와 Amazon RDS for PostgreSQL 등 다양한 AWS 데이터 소스에 직접 연결할 수 있어, 데이터 레이크 내의 모든 데이터를 시각화하는 데 적합합니다.
- **강력한 시각화 기능:** QuickSight는 다양한 차트 유형과 대시보드 기능을 제공하여 데이터를 효과적으로 시각화할 수 있습니다.
- **세분화된 액세스 제어:** QuickSight는 사용자 및 그룹 수준에서 대시보드 공유 및 액세스 권한을 세밀하게 제어할 수 있습니다. 이를 통해 관리 팀에게는 모든 시각화에 대한 전체 액세스 권한을 부여하고, 나머지 직원에게는 제한된 액세스 권한을 부여하는 요구 사항을 충족할 수 있습니다.
- **보고 솔루션 적합성:** QuickSight는 데이터 시각화 및 대시보드 생성을 위한 전문 BI(Business Intelligence) 도구로, 보고 솔루션 요구 사항에 직접적으로 부합합니다.

**A, C, D가 적절하지 않은 이유:**

**A. Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 IAM 역할과 대시보드를 공유합니다.**

- QuickSight는 IAM 역할과 직접 대시보드를 공유하는 기능이 없습니다. QuickSight 내에서 사용자 및 그룹을 생성하여 권한을 관리하는 것이 일반적인 방법입니다. 따라서 이 옵션은 QuickSight의 권한 관리 방식과 일치하지 않습니다.

**C. Amazon S3의 데이터에 대한 AWS Glue 테이블 및 크롤러를 생성합니다. AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다.**

- 이 솔루션은 데이터 통합 및 처리에 중점을 둡니다. AWS Glue는 ETL 작업을 수행하고 데이터를 준비하는 데 유용하지만, 직접적인 "데이터 시각화 및 보고 솔루션"은 아닙니다.
- 보고서를 Amazon S3에 게시하고 S3 버킷 정책으로 액세스를 제한하는 것은 가능하지만, 이는 동적이고 상호작용적인 시각화가 아닌 정적인 보고서 파일을 제공할 가능성이 높습니다. 또한 시각화 및 보고 기능을 위해서는 별도의 BI 도구가 필요합니다.

**D. Amazon S3의 데이터에 대한 AWS Glue 테이블과 크롤러를 생성합니다. Amazon Athena 연합 쿼리를 사용하여 PostgreSQL 용 Amazon RDS 내의 데이터에 액세스합니다. Amazon Athena를 사용하여 보고서를 생성합니다. 보고서를 Amazon S3에 게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다.**

- 이 옵션은 AWS Glue와 Amazon Athena를 사용하여 데이터 레이크의 데이터를 쿼리하는 좋은 방법이지만, "데이터 시각화" 및 "보고 솔루션" 자체는 아닙니다.
- Amazon Athena는 쿼리 서비스이지 시각화 도구가 아닙니다. Athena로 쿼리한 결과를 시각화하려면 여전히 QuickSight와 같은 별도의 BI 도구가 필요합니다.
- C와 마찬가지로, S3에 보고서를 게시하고 버킷 정책으로 액세스를 제한하는 것은 동적인 시각화 요구 사항을 완전히 충족하기 어렵습니다.

따라서 데이터 시각화, 보고 솔루션, 그리고 세분화된 액세스 제어라는 요구사항을 모두 충족하는 데에는 Amazon QuickSight를 활용하는 B 옵션이 가장 적합합니다.

# 17

회사에서 새로운 비즈니스 애플리케이션을 구현하고 있습니다. 이 애플리케이션은 두 개의 Amazon EC2 인스턴스에서 실행되며 문서 저장을 위해 Amazon S3 버킷을 사용합니다. 솔루션 설계자는 EC2 인스턴스가 S3 버킷에 액세스할 수 있는지 확인해야 합니다.
솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

**A. S3 버킷에 대한 액세스 권한을 부여하는 IAM 역할을 생성합니다. 역할을 EC2 인스턴스에 연결합니다.**

- **보안 모범 사례:** AWS에서 EC2 인스턴스가 다른 AWS 서비스(예: S3)에 액세스해야 할 때, IAM 역할(IAM Role)을 사용하는 것이 가장 안전하고 권장되는 방법입니다. IAM 역할은 임시 보안 자격 증명을 제공하여 EC2 인스턴스가 필요한 리소스에 액세스할 수 있도록 합니다. 이는 장기적인 액세스 키를 관리할 필요가 없으므로 보안 위험을 줄여줍니다.
- **자격 증명 관리 용이성:** EC2 인스턴스에 IAM 역할을 연결하면, 인스턴스에서 실행되는 애플리케이션이 AWS SDK 또는 CLI를 사용하여 자동으로 역할의 임시 자격 증명을 획득할 수 있습니다. 별도로 액세스 키나 비밀 키를 인스턴스에 저장할 필요가 없습니다.
- **자격 증명 유출 위험 감소:** 액세스 키와 비밀 키를 인스턴스에 직접 저장하는 경우, 해당 키가 유출되면 심각한 보안 문제가 발생할 수 있습니다. IAM 역할은 이러한 위험을 제거합니다.

**B, C, D가 적절하지 않은 이유:**

**B. S3 버킷에 대한 액세스 권한을 부여하는 IAM 정책을 생성합니다. 정책을 EC2 인스턴스에 연결합니다.**

- IAM 정책(IAM Policy)은 권한을 정의하는 문서입니다. 정책 자체는 독립적으로 엔터티(사용자, 그룹, 역할)에 연결되어야만 효과를 발휘합니다. EC2 인스턴스에 직접 정책을 연결하는 방법은 없으며, **역할을 통해** 정책을 인스턴스에 부여하는 것입니다. 따라서 정책만으로는 EC2 인스턴스가 S3에 접근할 수 없습니다.

**C. S3 버킷에 대한 액세스 권한을 부여하는 IAM 그룹을 생성합니다. 그룹을 EC2 인스턴스에 연결합니다.**

- IAM 그룹(IAM Group)은 IAM 사용자(IAM User)들을 묶어 공통된 권한을 부여할 때 사용됩니다. EC2 인스턴스에 직접 IAM 그룹을 연결하는 개념은 존재하지 않습니다. EC2 인스턴스는 사용자가 아니므로 그룹의 멤버가 될 수 없습니다.

**D. S3 버킷에 대한 액세스 권한을 부여하는 IAM 사용자를 생성합니다. 사용자 계정을 EC2 인스턴스에 연결합니다.**

- IAM 사용자(IAM User)는 사람 또는 애플리케이션에 장기적인 자격 증명(액세스 키 및 비밀 키)을 제공하는 데 사용됩니다.  EC2 인스턴스에 "연결"한다는 건, 사실상 그 **EC2 인스턴스 안에 아이디와 비밀번호를 직접 저장**해 두는 것과 마찬가지라는 점 .EC2 인스턴스에서 IAM 사용자의 액세스 키를 구성하여 사용할 수는 있지만, 이는 보안상 권장되지 않는 방법입니다. 액세스 키가 인스턴스 내부에 하드코딩되거나 저장될 경우 유출 위험이 커지며, 키 관리가 어렵습니다. IAM 역할은 이러한 문제를 해결하기 위한 더 안전하고 유연한 대안입니다.

# 18

애플리케이션 개발 팀은 큰 이미지를 더 작은 압축 이미지로 변환하는 마이크로서비스를 설계하고 있습니다. 사용자가 웹 인터페이스를 통해 이미지를 업로드하면 마이크로 서비스는 이미지를 Amazon S3 버킷에 저장하고, AWS Lambda 함수로 이미지를 처리 및 압축하고, 다른 S3 버킷에 압축된 형태로 이미지를 저장해야 합니다.
솔루션 설계자는 내구성이 있는 상태 비저장 구성 요소를 사용하여 이미지를 자동으로처리하는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 작업 조합은 무엇입니까? (2개를 선택하세요.)

- 내구성이 있는 상태 비저장 구성 요소
    
    ### 1. 상태 비저장 (Stateless)
    
    **상태 비저장**이란 특정 구성 요소(예: 애플리케이션 서비스, 서버리스 함수 등)가 **과거의 요청이나 세션에 대한 정보를 저장하지 않는** 것을 의미합니다. 즉, 각 요청은 독립적으로 처리되며, 이전 요청의 결과나 상태에 의존하지 않습니다.
    
    - **확장성(Scalability):** 각 요청이 독립적이므로, 필요에 따라 동일한 구성 요소의 인스턴스를 손쉽게 늘리거나 줄일 수 있습니다. (예: Lambda 함수를 여러 개 동시에 실행)
    - **단순성(Simplicity):** 상태 관리에 대한 복잡성이 줄어들어 코드와 아키텍처가 더 단순해집니다.
    - **복원력(Resilience):** 특정 인스턴스에 문제가 발생하더라도, 다른 인스턴스가 문제없이 요청을 처리할 수 있습니다. 한 인스턴스의 실패가 전체 시스템에 영향을 미치지 않습니다.
    
    **예시:**
    
    - **웹 서버:** 각 HTTP 요청을 독립적으로 처리하며, 사용자의 로그인 상태나 장바구니 정보는 데이터베이스나 세션 스토어에 저장하고 웹 서버 자체는 이 정보를 직접 보유하지 않습니다.
    - **AWS Lambda 함수:** 함수가 호출될 때마다 완전히 새로운 환경에서 실행되며, 이전 호출의 데이터를 기억하지 않습니다.
    
    ### 2. 내구성 (Durable)
    
    **내구성**이란 구성 요소가 작동하는 동안이나 장애 발생 시에도 **데이터나 작업의 손실 없이 안정적으로 운영될 수 있는 능력**을 의미합니다. 이는 시스템이 어떤 문제가 발생하더라도 중요한 정보가 유실되지 않고, 작업을 재개하거나 완료할 수 있도록 보장하는 특성입니다.
    
    **상태 비저장 구성 요소에서 내구성을 확보하는 방법:**
    상태 비저장 구성 요소 자체는 데이터를 저장하지 않으므로, 내구성을 확보하려면 **외부의 내구성 있는 저장소**를 활용해야 합니다.
    
    - **데이터베이스:** 처리해야 할 정보나 처리 결과를 데이터베이스(예: Amazon DynamoDB, Amazon RDS)에 저장하여 영속성을 확보합니다.
    - **메시지 큐:** SQS와 같은 메시지 큐는 메시지를 안전하게 저장하고, 소비자가 메시지를 성공적으로 처리할 때까지 보존합니다. 이는 메시지가 손실되지 않고 처리될 수 있도록 보장합니다.
    - **객체 스토리지:** S3와 같은 객체 스토리지는 대량의 데이터를 안정적으로 저장하고, 필요할 때 접근할 수 있도록 합니다. (예: 원본 이미지, 압축된 이미지 저장)
    
    ---
    
    ### 조합의 의미: '내구성이 있는 상태 비저장 구성 요소'
    
    이 두 가지 개념을 결합하면, **"과거 상태를 기억하지 않으면서도, 외부의 내구성 있는 저장소를 통해 중요한 데이터를 안전하게 처리하고 보존할 수 있는 구성 요소"**를 의미합니다.
    
    처음 질문의 이미지 처리 마이크로서비스 예시에서,
    
    - **Lambda 함수**는 **상태 비저장 구성 요소**입니다. 각 이미지를 독립적으로 처리하고, 이전 이미지 처리의 상태를 기억하지 않습니다.
    - **SQS 대기열**과 **S3 버킷**은 **내구성을 제공하는 외부 저장소**입니다. SQS는 처리해야 할 이미지 정보를 안전하게 저장하고, S3는 원본 및 압축된 이미지를 영구적으로 보관합니다.
    
    따라서 Lambda 함수는 SQS와 S3의 도움을 받아 '내구성이 있는 상태 비저장' 방식으로 이미지를 자동으로 처리할 수 있게 됩니다. 만약 Lambda 함수에 오류가 발생하거나 잠시 작동이 중단되더라도, SQS에 있는 메시지는 사라지지 않으므로 나중에 다시 처리될 수 있습니다. S3에 저장된 이미지 또한 안전하게 보존됩니다.
    

**A. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 이미지가 S3 버킷에 업로드될 때 SQS 대기열에 알림을 보내도록 S3 버킷을 구성합니다.**

- **비동기 처리:** S3 버킷에 이미지가 업로드될 때 SQS 대기열에 알림을 보내도록 구성하면, 이미지 업로드와 이미지 처리(압축)를 비동기적으로 분리할 수 있습니다. 이는 시스템의 확장성과 내구성을 높여줍니다.
- **내구성 있는 상태 비저장:** SQS는 메시지를 안전하게 저장하므로, Lambda 함수가 즉시 이미지를 처리할 수 없는 상황(예: 일시적인 오류 또는 높은 부하)에서도 데이터 손실 없이 메시지를 보존할 수 있습니다.
- **마이크로서비스 아키텍처 적합:** 마이크로서비스는 독립적으로 배포 및 확장되어야 하므로, SQS를 사용하여 마이크로서비스 간의 느슨한 결합을 제공하는 것이 좋습니다.

**B. Amazon Simple Queue Service(Amazon SQS) 대기열을 호출 소스로 사용하도록 Lambda 함수를 구성합니다. SQS 메시지가 성공적으로 처리되면 대기열에서 메시지를 삭제합니다.**

- **자동 처리:** Lambda 함수가 SQS 대기열을 호출 소스로 사용하도록 구성하면, 대기열에 메시지가 추가될 때마다 Lambda 함수가 자동으로 트리거되어 이미지 처리 및 압축 작업을 수행합니다. 이는 '이미지를 자동으로 처리'하라는 요구 사항을 충족합니다.
- **상태 비저장 구성 요소:** Lambda 함수는 본질적으로 상태 비저장(stateless)이며, 각 호출은 독립적으로 실행됩니다. 이는 '내구성이 있는 상태 비저장 구성 요소'라는 요구 사항과 일치합니다.
- **강력한 통합:** SQS와 Lambda는 AWS에서 긴밀하게 통합되어 있으며, Lambda는 SQS 대기열을 폴링하고 메시지를 자동으로 처리하는 기능을 제공합니다. 성공적인 처리 후 메시지 삭제는 중복 처리 방지 및 대기열 관리에 필수적입니다.

**C, D, E가 적절하지 않은 이유:**

**C. 새 업로드에 대해 S3 버킷을 모니터링하도록 Lambda 함수를 구성합니다. 업로드된 이미지가 감지되면 메모리의 텍스트 파일에 파일 이름을 쓰고 텍스트 파일을 사용하여 처리된 이미지를 추적합니다.**

- **상태 저장 및 내구성 부족:** 메모리 내 텍스트 파일에 파일 이름을 쓰는 것은 '상태 비저장'이라는 요구 사항에 위배되며, Lambda 함수가 재시작되거나 다른 인스턴스에서 실행될 경우 이 정보가 손실될 수 있습니다. 이는 '내구성이 있는' 솔루션이 아닙니다.
- **확장성 문제:** 동시에 여러 이미지가 업로드되거나 처리될 때 메모리 내 텍스트 파일을 관리하는 것은 복잡하며 병목 현상을 유발할 수 있습니다.
- **재시도 및 오류 처리:** 처리 실패 시 재시도 메커니즘을 구현하기 어렵고, 오류 발생 시 어떤 이미지가 처리되었는지 또는 처리 중이었는지 추적하기 어렵습니다.

**D. Amazon EC2 인스턴스를 시작하여 Amazon Simple Queue Service(Amazon SQS) 대기열을 모니터링합니다. 항목이 대기열에 추가되면 EC2 인스턴스의 텍스트 파일에 파일 이름을 기록하고 Lambda 함수를 호출합니다.**

- **불필요한 복잡성 및 비용:** SQS 대기열을 모니터링하고 Lambda 함수를 호출하기 위해 전용 EC2 인스턴스를 사용하는 것은 불필요한 복잡성을 추가하며, EC2 인스턴스 유지 관리에 대한 추가 비용이 발생합니다. Lambda 함수는 SQS를 직접 호출 소스로 사용할 수 있어 EC2 인스턴스가 필요 없습니다.
- **상태 저장 문제:** EC2 인스턴스의 텍스트 파일에 파일 이름을 기록하는 것은 C와 유사하게 상태 저장 문제를 야기하고 내구성이 부족합니다.
- **관리 오버헤드:** EC2 인스턴스는 서버 관리(패치, 보안 등)에 대한 오버헤드가 있지만, Lambda는 서버리스이므로 이러한 오버헤드가 없습니다.

**E. Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 구성하여 S3 버킷을 모니터링합니다. 이미지가 업로드되면 추가 처리를 위해 애플리케이션 소유자의 이메일 주소와 함께 Amazon Simple Notification Service(Amazon SNS) 주제에 알림을 보냅니다.**

- **자동 처리 부족:** S3 버킷 업로드 이벤트를 EventBridge를 통해 SNS 주제로 보내는 것은 알림 기능에 가깝습니다. 이는 '이미지를 자동으로 처리'하라는 핵심 요구 사항을 직접적으로 충족하지 않습니다. SNS는 주로 메시지를 구독자에게 푸시하는 데 사용되며, 이미지 처리 로직을 실행하는 데는 적합하지 않습니다.
- **처리 로직 부재:** 이 솔루션은 이미지 처리 및 압축 로직이 어디서 실행될지에 대한 답변을 제공하지 않습니다. 최종 사용자에게 이메일 알림을 보내는 것만으로는 이미지가 압축되지 않습니다. SQS-Lambda 조합이 이미지 처리 로직을 실행하는 데 더 적합합니다.

# 19

회사에 AWS 에 배포된 3 계층 웹 애플리케이션이 있습니다. 웹 서버는 VPC 의 퍼블릭 서브넷에 배포됩니다. 애플리케이션 서버와 데이터베이스 서버는 동일한 VPC 의 프라이빗 서브넷에 배포됩니다. 
이 회사는 AWS Marketplace 의 타사 가상 방화벽 어플라이언스를 검사 VPC 에 배포했습니다. 어플라이언스는 IP 패킷을 수락할 수 있는 IP 인터페이스로 구성됩니다.
솔루션 설계자는 트래픽이 웹 서버에 도달하기 전에 애플리케이션에 대한 모든 트래픽을 검사하기 위해 웹 애플리케이션을 어플라이언스와 통합해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

- 검사 VPC (Inspection VPC)
 네트워크 트래픽을 집중적으로 검사하고 보안 기능을 적용하기 위해 특별히 설계됨. 쉽게 말해, 회사 네트워크의 모든 트래픽이 지나가는 **보안 검문소** 역할을 하는 공간이라고 생각하면 됨

방화벽, 침입 방지 시스템(IPS), 심층 패킷 검사(DPI) 도구 등 다양한 **보안 어플라이언스**들이 배포됩니다. 외부에서 들어오는 트래픽이든, 내부 VPC 간의 트래픽이든, 애플리케이션 서버로 도달하기 전에 이 검사 VPC를 거쳐서 안전한지 확인
    - **중앙 집중식 보안:** 모든 트래픽 검사를 한 곳에서 관리하여 보안 정책 적용 및 모니터링이 용이함
    - **보안 강화:** 트래픽이 목적지에 도달하기 전에 잠재적인 위협을 탐지하고 차단할 수 있음
    - **운영 효율성:** 보안 어플라이언스를 특정 VPC에 격리하여, 다른 VPC는 애플리케이션 개발 및 운영에 집중할 수 있도록 함
    
    요약하자면, 검사 VPC는 AWS 클라우드 환경에서 **보안을 강화하고 네트워크 트래픽을 안전하게 제어하기 위한 전용 구역**이라고 이해하시면 됩니다.
    

**D. 검사 VPC 에 게이트웨이 로드 밸런서를 배포합니다. 게이트웨이 로드 밸런서 엔드포인트를 생성하여 수신 패킷을 수신하고 패킷을 어플라이언스로 전달합니다.**

- **Gateway Load Balancer (GWLB)의 목적:** GWLB는 본질적으로 네트워크 트래픽을 검사, 보안, 모니터링 또는 기타 처리를 수행하는 타사 가상 어플라이언스로 효과적으로 리디렉션하고 다시 라우팅하기 위해 설계되었습니다. 이는 인라인으로 작동하여 트래픽 흐름을 끊지 않고 투명하게 어플라이언스로 전달하고 다시 애플리케이션으로 보냅니다.
- **투명성 및 최소 오버헤드:** GWLB는 IP 주소와 무관하게 작동하는 게이트웨이 로드 밸런서 엔드포인트(GWLBE)를 사용합니다. 이는 어플라이언스 자체가 트래픽의 소스 또는 대상 IP 주소를 변경할 필요 없이 원래의 IP 패킷을 수신하고 처리한 후 다시 애플리케이션으로 보낼 수 있게 합니다. 이는 네트워크 아키텍처에 최소한의 변경을 요구하고 운영 오버헤드를 줄입니다.
- **스케일링 및 고가용성:** GWLB는 여러 어플라이언스 인스턴스 간에 트래픽을 분산하여 스케일링 및 고가용성을 제공합니다. 이는 단일 장애 지점을 제거하고 트래픽 증가에 유연하게 대응할 수 있도록 합니다.

**A, B, C가 적절하지 않은 이유:**

**A. 애플리케이션 VPC의 퍼블릭 서브넷에 Network Load Balancer를 생성하여 패킷 검사를 위해 어플라이언스로 트래픽을 라우팅합니다.**

- NLB는 TCP/UDP 트래픽을 대상으로 로드 밸런싱하는 데 최적화되어 있습니다. 타사 방화벽 어플라이언스는 종종 IP 계층에서 직접 패킷을 검사해야 합니다. NLB를 어플라이언스 앞에 두면, 어플라이언스가 트래픽을 다시 웹 서버로 보낼 때 추가적인 라우팅 복잡성이 발생하거나, 어플라이언스 자체가 원래의 IP 정보를 유지하기 어려울 수 있습니다. 또한, NLB는 인라인 보안 어플라이언스를 위한 투명한 트래픽 삽입을 목적으로 설계되지 않았습니다.

**B. 애플리케이션 VPC의 퍼블릭 서브넷에 Application Load Balancer를 생성하여 패킷 검사를 위해 어플라이언스로 트래픽을 라우팅합니다.**

- ALB는 HTTP/HTTPS 트래픽에 대한 로드 밸런싱에 특화되어 있습니다. 이 시나리오의 방화벽은 IP 패킷 수준에서 작동하므로, ALB는 적절한 솔루션이 아닙니다. ALB는 애플리케이션 계층에서 작동하며, IP 계층에서 투명하게 트래픽을 전달하고 다시 라우팅하는 데는 적합하지 않습니다. 또한, ALB는 트래픽을 어플라이언스로 보낸 후, 어플라이언스에서 처리된 트래픽을 다시 웹 서버로 보내는 복잡한 라우팅 구성이 필요할 수 있습니다.

**C. 전송 게이트웨이를 통해 들어오는 패킷을 라우팅하도록 라우팅 테이블을 구성하는 검사 VPC에 전송 게이트웨이를 배포합니다.**

- Transit Gateway (TGW)는 여러 VPC와 온프레미스 네트워크 간의 연결을 중앙 집중화하는 데 사용됩니다. TGW 자체는 트래픽을 특정 보안 어플라이언스로 인라인으로 투명하게 전달하는 메커니즘을 제공하지 않습니다. TGW는 트래픽을 라우팅하는 데 사용될 수 있지만, 검사 VPC 내에서 어플라이언스로 트래픽을 효과적으로 "삽입"하고 다시 애플리케이션으로 보내는 "bump-in-the-wire" 기능을 제공하지 않습니다. 이 시나리오에서 TGW만으로는 웹 애플리케이션 트래픽이 방화벽을 거치도록 강제하기 어렵습니다. GWLB와 같은 서비스와 함께 사용될 때 더 효과적일 수 있습니다.

따라서, 최소한의 운영 오버헤드로 모든 트래픽을 타사 가상 방화벽 어플라이언스를 통해 검사하는 요구 사항을 가장 효율적이고 투명하게 충족하는 솔루션은 **D. 검사 VPC에 게이트웨이 로드 밸런서를 배포하고 게이트웨이 로드 밸런서 엔드포인트를 생성하여 수신 패킷을 수신하고 패킷을 어플라이언스로 전달하는 것**입니다.

# 20

회사에서 동일한 AWS 리전의 테스트 환경에 대량의 프로덕션 데이터를 복제하는 기능을 개선하려고 합니다. 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨의 Amazon EC2 인스턴스에 저장됩니다. 복제된 데이터를 수정해도 프로덕션 환경에 영향을 주지 않아야 합니다. 이 데이터에 액세스하는 소프트웨어는 일관되게 높은 I/O 성능을요구합니다.
솔루션 설계자는 프로덕션 데이터를 테스트 환경에 복제하는 데 필요한 시간을 최소화해야합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

- 프로덕션 환경
    
    테스트나 개발 작업을 하다가 실제 운영 중인 서비스에 오류를 일으키거나, 데이터를 망가뜨리거나, 속도를 느리게 만드는 등 어떠한 문제도 일으켜서는 안 된다
    

**D. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. EBS 스냅샷에서 EBS 빠른 스냅샷 복원 기능을 켭니다. 스냅샷을 새 EBS 볼륨으로 복원합니다. 테스트 환경의 EC2 인스턴스에 새 EBS 볼륨을 연결합니다.**

- **높은 I/O 성능 보장**: 일반적인 EBS 스냅샷 복원은 '레이지 로딩(lazy loading)' 방식으로 동작합니다. 즉, 볼륨이 생성된 직후에는 데이터가 백그라운드에서 S3로부터 천천히 로드되므로, 처음 데이터에 액세스할 때 I/O 지연이 발생합니다. 하지만 빠른 스냅샷 복원(FSR)을 사용하면 스냅샷으로부터 볼륨을 생성할 때 모든 데이터가 즉시 프로비저닝(완전히 로드)됩니다. 따라서 테스트 환경에서 데이터를 사용하는 소프트웨어는 **처음부터 지연 없이 일관되게 높은 I/O 성능**을 누릴 수 있습니다.
- **복제 시간 최소화**: FSR은 복원된 볼륨이 **즉시 최대 성능을 발휘**하도록 준비해 줍니다. 따라서 테스트 환경을 즉시 사용할 수 있게 되어, 전체적인 '데이터 복제 완료 후 테스트 가능 시점까지의 시간'을 최소화합니다.
- **완벽한 데이터 격리**: 프로덕션 볼륨의 스냅샷으로 **완전히 새로운 EBS 볼륨**을 생성했기 때문에, 테스트 환경에서 이 볼륨의 데이터를 아무리 수정해도 원본 프로덕션 볼륨에는 전혀 영향을 주지 않습니다.

**A, B, C가 적절하지 않은 이유**

**A. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 테스트 환경의 EC2 인스턴스 스토어 볼륨에 스냅샷을 복원합니다.**

- **기술적 오류**: EBS 스냅샷은 EBS 볼륨으로만 복원할 수 있으며, **EC2 인스턴스 스토어 볼륨으로는 복원할 수 없습니다.** 인스턴스 스토어는 임시 스토리지로, EBS와는 구조가 다릅니다. 따라서 이 선택지는 기술적으로 불가능합니다.

**B. EBS 다중 연결 기능을 사용하도록 프로덕션 EBS 볼륨을 구성합니다. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 테스트 환경의 EC2 인스턴스에 프로덕션 EBS 볼륨을연결합니다.**

EBS 다중 연결(Multi-Attach) 기능 사용

- **데이터 격리 실패**: 이 방법은 **원본 프로덕션 EBS 볼륨을 테스트 EC2 인스턴스에 직접 연결**하는 방식입니다. 이렇게 되면 테스트 환경에서 데이터를 수정할 경우 **실제 프로덕션 데이터가 직접 변경**되는 심각한 문제를 일으킵니다. 이는 "복제된 데이터를 수정해도 프로덕션 환경에 영향을 주지 않아야 한다"는 핵심 요구사항을 위반하는 가장 위험한 방법입니다.

**C. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 새 EBS 볼륨을 생성하고 초기화합니다. 프로덕션 EBS 스냅샷에서 볼륨을 복원하기 전에 테스트 환경의 EC2 인스턴스에 새 EBS 볼륨을 연결합니다.**

FSR 없이 새 EBS 볼륨으로 복원

- **초기 성능 저하**: 이 방법은 스냅샷으로 새 볼륨을 만들어 데이터 격리는 만족시킵니다. 하지만 FSR을 사용하지 않았기 때문에, 위에서 설명한 '레이지 로딩'으로 인해 **볼륨 생성 직후 I/O 성능이 매우 낮습니다.** "일관되게 높은 I/O 성능"을 요구하는 소프트웨어는 데이터 블록이 모두 로드될 때까지 심각한 성능 저하를 겪게 됩니다. 따라서 요구 사항을 완전히 충족하지 못합니다.

# 21

전자 상거래 회사는 AWS 에서 하루 1 회 웹 사이트를 시작하려고 합니다. 매일 24 시간 동안 정확히 하나의 제품을 판매합니다. 회사는 피크 시간 동안 밀리초 지연 시간으로 시간당 수백만 개의 요청을 처리할 수 있기를 원합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

**D. Amazon S3 버킷을 사용하여 웹 사이트의 정적 콘텐츠를 호스팅합니다. Amazon CloudFront 배포를 배포합니다. S3 버킷을 오리진으로 설정합니다. 백엔드 API 에 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. Amazon DynamoDB 에 데이터를 저장합니다.**

- **정적 콘텐츠 (S3 + CloudFront):**
    - **Amazon S3**: 웹사이트의 HTML, CSS, Javascript와 같은 정적 파일을 저장하기에 가장 비용 효율적이고 확장성이 뛰어난 서비스입니다.
    - **Amazon CloudFront**: 전 세계에 퍼져있는 엣지 로케이션에 콘텐츠를 캐싱하여 사용자에게 매우 빠른 속도(밀리초 지연 시간)로 콘텐츠를 제공합니다. S3 원본 서버의 부하를 덜어주어 수백만 요청을 처리하는 데 핵심적인 역할을 합니다.
- **백엔드 (API Gateway + Lambda):**
    - **Amazon API Gateway**: 수백만 개의 API 요청을 안정적으로 처리하고 관리할 수 있는 완전 관리형 서비스입니다.
    - **AWS Lambda**: 서버를 프로비저닝하거나 관리할 필요 없이 코드를 실행합니다. 요청이 있을 때만 실행되고 트래픽에 따라 자동으로 확장되므로, **'최소한의 운영 오버헤드'**라는 요구사항을 완벽하게 만족합니다. 하루 중 특정 시간에만 트래픽이 몰리는 시나리오에 가장 적합합니다.
- **데이터베이스 (Amazon DynamoDB):**
    - **Amazon DynamoDB**: 어떤 규모에서든 **한 자릿수 밀리초의 일관된 지연 시간**을 제공하는 NoSQL 데이터베이스입니다. 서버리스이며 자동 확장을 지원하므로, 급증하는 주문 데이터를 처리하고 저장하는 데 가장 적합하며 운영 부담이 없습니다.

**A, B, C가 적절하지 않은 이유**

**A. Amazon S3 를 사용하여 다른 S3 버킷에 전체 웹 사이트를 호스팅합니다. Amazon CloudFront 배포를 추가합니다. S3 버킷을 배포의 오리진으로 설정합니다. Amazon S3 에 주문 데이터를 저장합니다.**

**S3를 데이터베이스로 사용**

- **결정적 결함:** 주문 데이터를 S3에 직접 저장하는 것은 부적절합니다. S3는 객체 스토리지이지, 실시간으로 데이터를 읽고 쓰고 수정하는 트랜잭션 데이터베이스가 아닙니다. 동시 주문 처리나 데이터의 일관성을 보장하기 어렵고, 필요한 데이터를 빠르게 조회하는 데 성능 문제가 발생합니다.

**B. 여러 가용 영역의 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스에 전체 웹 사이트를 배포합니다. ALB(Application Load Balancer)를 추가하여 웹 사이트 트래픽을 분산합니다. 백엔드 API 에 대해 다른 ALB 를 추가하십시오. MySQL 용 Amazon RDS 에 데이터를 저장합니다.**

**전통적인 EC2 기반 아키텍처**

**운영 오버헤드:** Auto Scaling 그룹의 EC2 인스턴스를 사용하는 것은 확장성을 제공하지만, **'최소한의 운영 오버헤드'** 요구사항을 위반합니다.

- 운영체제(OS) 및 보안 패치
- 애플리케이션 배포 및 관리
- Auto Scaling 정책의 세부적인 튜닝 등 직접 관리해야 할 부분이 많습니다.

서버리스 방식에 비해 훨씬 많은 운영 노력이 필요합니다.

**C. 컨테이너에서 실행되도록 전체 애플리케이션을 마이그레이션합니다. Amazon Elastic Kubernetes Service(Amazon EKS)에서 컨테이너를 호스팅합니다. Kubernetes 클러스터 자동 확장 처리를 사용하여 트래픽 버스트를 처리할 포드 수를 늘리거나 줄입니다. MySQL 용 Amazon RDS에 데이터를 저장합니다.**

- **과도한 복잡성 및 운영 오버헤드:** 쿠버네티스(EKS)는 매우 강력하지만, 동시에 매우 복잡한 시스템입니다.
    - 클러스터, 노드, 파드(Pod) 등 관리해야 할 요소가 많습니다.
    - 애플리케이션을 컨테이너화하고 배포 파이프라인을 구축하는 데 상당한 전문 지식과 노력이 필요합니다.
- 단순한 요구사항에 비해 너무 과한(overkill) 솔루션이며, '최소한의 운영 오버헤드'와는 정반대의 접근 방식입니다.

# 22

솔루션 설계자는 Amazon S3 를 사용하여 새로운 디지털 미디어 애플리케이션의 스토리지 아키텍처를 설계하고 있습니다. 미디어 파일은 가용 영역 손실에 대한 복원력이 있어야 합니다. 일부 파일은 자주 액세스되는 반면 다른 파일은 예측할 수 없는 패턴으로 거의 액세스되지 않습니다. 솔루션 설계자는 미디어 파일을 저장하고 검색하는 비용을 최소화해야 합니다. 이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?

**B. S3 Intelligent-Tiering (S3 지능형 계층화)** 

**S3 Intelligent-Tiering**은 액세스 패턴을 알 수 없거나 예측할 수 없는 데이터에 가장 적합한 스토리지 클래스입니다. 문제의 요구사항을 완벽하게 충족합니다.

- **비용 최소화**: S3 Intelligent-Tiering은 객체의 액세스 패턴을 자동으로 모니터링합니다. 30일 동안 액세스하지 않은 파일은 **자주 액세스하는 티어(Frequent Access Tier)에서 비용이 저렴한 간헐적 액세스 티어(Infrequent Access Tier)로 자동 이동**시켜 스토리지 비용을 절감합니다. 자주 액세스하는 파일과 거의 액세스하지 않는 파일이 섞여 있고, 그 패턴을 예측할 수 없는 상황에서 수동 개입 없이 비용을 최적화할 수 있는 유일한 해결책입니다.
- **가용 영역 손실에 대한 복원력**: S3 Intelligent-Tiering은 기본적으로 여러 가용 영역(최소 3개)에 데이터를 분산 저장하여 가용 영역 하나에 장애가 발생해도 데이터를 안전하게 보호합니다.

**A, C, D가 정답이 아닌 이유**

**A. S3 Standard (S3 표준)**

- 여러 가용 영역에 데이터를 저장하여 복원력 요구사항은 충족합니다.
- 하지만 자주 액세스하지 않는 파일까지 비싼 S3 Standard 요금으로 저장해야 하므로, **비용 최소화 요구사항을 충족하지 못합니다.**

**C. S3 Standard-Infrequent Access (S3 Standard-IA)**

- 여러 가용 영역에 데이터를 저장하여 복원력 요구사항은 충족합니다.
- 하지만 이 스토리지 클래스는 처음부터 데이터가 거의 액세스되지 않을 것을 예상하고 저장할 때 사용합니다. 문제에서는 **일부 파일은 자주 액세스된다고** 했으므로, 이 파일들을 S3 Standard-IA에 저장하면 **데이터 검색 비용이 S3 Standard보다 비싸져** 전체 비용이 증가할 수 있습니다.

**D. S3 One Zone-Infrequent Access (S3 One Zone-IA)**

- 이름에서 알 수 있듯이 **단일 가용 영역(One Zone)에만 데이터를 저장**합니다. 따라서 **가용 영역 손실에 대한 복원력이 있어야 한다는 핵심 요구사항을 충족하지 못해** 가장 먼저 제외되어야 하는 선택지입니다.

# 23

회사에서 Amazon S3 Standard 스토리지를 사용하여 백업 파일을 저장하고 있습니다. 1개월 동안 파일에 자주 액세스합니다. 단, 1 개월 이후에는 파일에 접근하지 않습니다. 회사는 파일을 무기한 보관해야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?

**B. S3 수명 주기 구성을 생성하여 1개월 후에 S3 Standard에서 S3 Glacier Deep Archive로 객체를 전환합니다.**

문제의 핵심 요구사항은 **"가장 비용 효율적인"** 방법으로 데이터를 **"무기한 보관"**하는 것입니다.

- **초기 1개월 (자주 액세스):** **S3 Standard**는 데이터에 자주 액세스하는 첫 1개월 동안 가장 적합합니다. 검색 비용이 없고 빠른 액세스를 제공하기 때문입니다.
- **1개월 이후 (액세스 없음):** 1개월 후에는 파일에 전혀 액세스하지 않으므로, 데이터를 가장 저렴한 스토리지에 보관하여 비용을 최소화해야 합니다.
- **S3 Glacier Deep Archive:** 이 스토리지 클래스는 AWS에서 제공하는 가장 저렴한 스토리지 옵션입니다. 데이터에 거의 액세스하지 않고 장기간(수년 이상) 보관하는 아카이빙 목적에 최적화되어 있습니다. 데이터 검색에 몇 시간이 걸리지만, 문제의 시나리오처럼 액세스가 전혀 없는 경우에는 완벽한 선택입니다.

**A, C, D가 적절하지 않은 이유**

**A. 객체를 자동으로 마이그레이션하도록 S3 Intelligent-Tiering을 구성합니다.**

S3 Intelligent-Tiering은 **액세스 패턴을 예측할 수 없거나 자주 변경될 때** 유용한 서비스입니다. 이 시나리오는 "1개월 후 액세스 없음"이라는 **매우 명확하고 예측 가능한 패턴**을 가지고 있습니다. 따라서 Intelligent-Tiering의 자동 계층화 기능은 불필요하며, 객체 모니터링에 대한 추가 비용이 발생하여 Glacier Deep Archive로 직접 전환하는 것보다 비쌉니다.

**C. S3 수명 주기 구성을 생성하여 1 개월 후에 객체를 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.**

S3 Standard-IA는 S3 Standard보다 저렴하지만, S3 Glacier Deep Archive보다는 훨씬 비쌉니다. Standard-IA는 **자주는 아니지만 필요할 때 빠르게(밀리초 단위) 데이터를 검색해야 하는 경우**에 사용됩니다. 문제에서는 1개월 후 데이터에 전혀 접근하지 않으므로, Standard-IA의 빠른 검색 기능에 대한 추가 비용을 지불할 필요가 없습니다. **가장 비용 효율적인** 선택이 아닙니다.

**D. S3 수명 주기 구성을 생성하여 1 개월 후에 객체를 S3 Standard 에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다.**

S3 One Zone-IA는 이름처럼 데이터를 **단 하나의 가용 영역(AZ)에만 저장**하여 비용을 낮춘 스토리지 클래스입니다. 만약 해당 가용 영역에 장애(정전, 재해 등)가 발생하면 데이터가 영구적으로 손실될 수 있습니다. "무기한 보관해야 하는 백업 파일"은 중요한 데이터이므로, 이러한 데이터 손실 위험은 수용할 수 없습니다. 내구성이 중요한 백업 데이터에는 부적합합니다.

# 24

회사는 가장 최근 청구서에서 Amazon EC2 비용 증가를 관찰했습니다. 청구 팀은 몇 개의 EC2 인스턴스에 대한 인스턴스 유형의 원치 않는 수직적 확장을 발견했습니다. 솔루션 설계자는 지난 2 개월간의 EC2 비용을 비교하는 그래프를 생성하고 심층 분석을 수행하여 수직적 확장의 근본 원인을 식별해야 합니다.
솔루션 설계자는 운영 오버헤드가 가장 적은 정보를 어떻게 생성해야 합니까?

- 수직확장, 수평확장
    
    
    | 구분 | **수직 확장 (Scale-Up)** | **수평 확장 (Scale-Out)** |
    | --- | --- | --- |
    | **개념** | 서버 1대의 성능(스펙) 강화 | 처리할 서버의 대수 증가 |
    | **비유** | 자동차 엔진 업그레이드 | 계산대 추가 |
    | **장점** | 단순함, 적용 용이 | 고가용성, 유연성, 비용 효율성 |
    | **단점** | 확장 한계, 단일 장애점(SPOF) | 복잡성, 분산 처리 설계 필요 |
    | **AWS 예시** | EC2 인스턴스 타입 변경
    `t2.micro` → `m5.large` | 오토 스케일링 그룹 + 로드 밸런서 |

**B. Cost Explorer 의 세분화된 필터링 기능을 사용하여 인스턴스 유형을 기반으로 EC2 비용에 대한 심층 분석을 수행합니다.**

문제의 핵심 요구사항은 두 가지입니다.

1. 지난 2개월간의 EC2 비용을 **비교하는 그래프 생성**
2. 원치 않는 수직적 확장(인스턴스 유형 변경)의 **근본 원인 식별을 위한 심층 분석**

이 두 가지를 **가장 적은 운영 오버헤드**로 해결해야 합니다.

**Cost Explorer**는 바로 이러한 목적을 위해 만들어진 AWS의 기본 도구입니다.

- **그래프 생성:** 클릭 몇 번으로 시간 범위(예: 지난 2개월)를 설정하고 서비스(EC2)별 비용을 시각적인 그래프로 바로 확인할 수 있습니다.
- **심층 분석:** '그룹화 기준(Group by)' 및 '필터(Filter)' 기능이 매우 강력합니다. 이 문제의 핵심인 '인스턴스 유형(Instance Type)'을 기준으로 비용을 그룹화하고 필터링할 수 있습니다. 이를 통해 어떤 인스턴스 유형의 비용이 갑자기 증가했는지 쉽게 파악하여 수직적 확장의 근본 원인을 찾을 수 있습니다.
- **최소 운영 오버헤드:** Cost Explorer는 AWS 관리 콘솔에서 바로 사용할 수 있는 완전 관리형 서비스입니다. 별도의 인프라 구축이나 데이터 파이프라인 설정 없이 즉시 분석을 시작할 수 있어 운영 오버헤드가 가장 적습니다.

**A, C, D가 적절하지 않은 이유**

**A. AWS 예산을 사용하여 예산 보고서를 생성하고 인스턴스 유형에 따라 EC2 비용을 비교합니다.**

**AWS Budgets**

- **주요 목적:** 예산 설정 및 알림입니다. 설정한 예산을 초과할 것으로 예상되거나 실제로 초과했을 때 알림을 받는 것이 주된 기능입니다.

비용 추세를 볼 수는 있지만, Cost Explorer처럼 과거 데이터를 **'인스턴스 유형'과 같은 세부적인 기준으로 필터링하고 그룹화하여 심층 분석하는 데는 적합하지 않습니다.** 예산 초과를 감지하는 데는 유용하지만, 그 원인을 파고드는 분석 도구로는 부족합니다.

**C. AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2 개월 동안의 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.**

- 현재까지의 청구 요금, 서비스별 지출 등 **전체적인 비용 현황을 요약해서 보여주는 개요 페이지**입니다.
- 대시보드는 비용에 대한 '높은 수준의 개요(High-level overview)'를 제공합니다. 'EC2 비용이 증가했다'는 사실은 알 수 있지만, '어떤 인스턴스 유형 때문에' 증가했는지와 같은 **세부적인 분석(Deep-dive analysis) 기능은 제공하지 않습니다.** 심층 분석을 하려면 결국 Cost Explorer와 같은 다른 도구로 이동해야 합니다.

**D. AWS 비용 및 사용 보고서를 사용하여 보고서를 생성하고 Amazon S3 버킷으로 보냅니다. Amazon S3 와 함께 Amazon QuickSight 를 소스로 사용하여 인스턴스 유형을 기반으로 대화형 그래프를 생성합니다.**

AWS 비용 및 사용 보고서(CUR) + S3 + QuickSight

- 가장 세분화된 원시(raw) 비용 및 사용량 데이터를 S3 버킷에 저장하고, QuickSight와 같은 BI(비즈니스 인텔리전스) 도구로 시각화 및 분석하는 방식입니다.

이 방법은 가장 강력하고 유연한 분석이 가능하지만, 문제에서 요구한 **'가장 적은 운영 오버헤드'** 조건에 위배됩니다.

- CUR 보고서 설정을 해야 합니다.
- 데이터를 저장할 S3 버킷을 관리해야 합니다.
- QuickSight에서 S3 데이터를 소스로 데이터셋을 생성해야 합니다.
- 분석하려는 내용에 맞게 직접 그래프와 대시보드를 구축해야 합니다.
이 모든 과정은 Cost Explorer를 사용하는 것에 비해 훨씬 많은 설정과 관리가 필요하므로 **운영 오버헤드가 가장 높습니다.**

# 25

회사에서 응용 프로그램을 설계하고 있습니다. 애플리케이션은 AWS Lambda 함수를 사용하여 Amazon API Gateway 를 통해 정보를 수신하고 Amazon Aurora PostgreSQL 데이터베이스에 정보를 저장합니다.
개념 증명 단계에서 회사는 데이터베이스에 로드해야 하는 대용량 데이터를 처리하기 위해 Lambda 할당량을 크게 늘려야 합니다. 
솔루션 설계자는 확장성을 개선하고 구성 노력을최소화하기 위해 새로운 설계를 권장해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**D. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. 
정보를 데이터베이스에 로드하도록 다른 기능을 구성하십시오. 
Amazon Simple Queue Service(Amazon SQS) 대기열을 사용하여 Lambda 함수를 통합합니다.**

기존 설계의 문제점은 API Gateway를 통해 들어오는 대량의 데이터를 Lambda 함수 하나가 직접 처리하여 Aurora DB에 저장하려고 시도했다는 점입니다. 이로 인해 Lambda의 동시성 제한이나 처리 시간 초과 등의 할당량(Quota) 문제에 부딪히게 된 것입니다.

이 솔루션은 **'비동기식 디커플링(Asynchronous Decoupling)'** 아키텍처를 구현합니다.

- **확장성 개선**: 첫 번째 Lambda 함수(수신용)는 API Gateway로부터 요청을 받아 **아주 빠른 속도로 Amazon SQS 대기열에 메시지로 저장**하고 즉시 종료됩니다. 이 작업은 매우 단순하고 빠르기 때문에 많은 요청을 동시에 처리할 수 있습니다. 두 번째 Lambda 함수(처리용)는 SQS 대기열에 쌓인 메시지를 **자신의 처리 능력에 맞게 순차적으로 가져와(Poll)** Aurora DB에 저장합니다. 이 구조는 갑작스러운 데이터 폭증(Spike)이 발생하더라도 SQS 대기열이 **완충(Buffer) 역할**을 해주므로 시스템 전체가 안정적으로 동작하게 합니다. DB가 감당할 수 있는 속도로 데이터를 처리하도록 조절할 수 있어 DB 부하 관리에도 유리합니다.
- **구성 노력 최소화**: SQS는 서버리스 서비스이므로 별도의 서버 관리나 복잡한 클러스터 설정이 필요 없습니다. Lambda 함수에서 SQS를 트리거로 설정하는 것은 매우 간단하며, 이는 서버리스 아키텍처의 장점을 극대화하는 방식입니다. Lambda 할당량을 무리하게 늘릴 필요 없이, SQS의 기본 기능과 Lambda의 이벤트 소스 매핑 설정만으로도 효과적인 확장이 가능합니다.

**A, B, C가 적절하지 않은 이유**

**A. Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 리팩터링합니다. 네이티브 JDBC(Java Database Connectivity) 드라이버를 사용하여 데이터베이스를 연결합니다.**

- **구성 및 관리 노력 증가**: EC2 인스턴스를 사용하면 운영체제, 톰캣(Tomcat) 서버, 자바(Java) 런타임, 애플리케이션 배포, 보안 패치 등 **모든 것을 직접 관리**해야 합니다. 이는 '구성 노력 최소화'라는 요구사항에 정면으로 위배됩니다. 또한, 트래픽에 따라 EC2 인스턴스를 자동으로 확장/축소(Auto Scaling)하려면 별도의 구성을 해야 하는 부담이 따릅니다.
- **서버리스의 이점 상실**: 확장성과 관리 편의성이라는 Lambda의 핵심 이점을 포기하고, 전통적인 서버 기반 아키텍처로 회귀하는 방식입니다.

**B. 플랫폼을 Aurora 에서 Amazon DynamoDProvision a DynamoDB Accelerator(DAX) 클러스터로 변경합니다. DAX 클라이언트 SDK 를 사용하여 DAX 클러스터에서 기존 DynamoDB API 호출을 가리킵니다.**

DynamoDB로 플랫폼 변경

- **과도한 변경**: 기존 데이터베이스는 관계형 데이터베이스(RDB)인 Aurora PostgreSQL입니다. 이를 NoSQL인 DynamoDB로 변경하는 것은 단순히 DB만 바꾸는 것이 아니라, 데이터 모델링, 스키마 설계, 애플리케이션의 데이터 접근 로직(쿼리)까지 **모두 재설계**해야 하는 매우 큰 작업입니다.
- **부적절한 해결책**: 문제의 핵심은 데이터베이스 자체가 아니라, 데이터베이스로 데이터를 **전달하는 방식**에 있습니다. DB를 변경하는 것은 근본적인 해결책이 아닙니다. DAX(DynamoDB Accelerator)는 DynamoDB의 읽기 성능을 가속화하는 캐싱 서비스이지, 대용량 쓰기 요청을 완충하는 역할과는 거리가 있습니다.

**C. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. 정보를 데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Lambda 함수를 통합합니다.**

SNS를 사용하여 Lambda 함수 통합

- **부적절한 사용 사례**: Amazon SNS(Simple Notification Service)는 **게시/구독(Pub/Sub) 모델**에 사용되는 메시징 서비스입니다. 하나의 메시지가 발생했을 때 이를 **여러 구독자(Subscriber)에게 동시에 전달**하는 데 특화되어 있습니다. 예를 들어, 주문이 발생하면 '결제 처리 시스템', '재고 관리 시스템', '알림 시스템' 등 여러 곳에 동시에 알려줘야 할 때 적합합니다.
- **큐(Queue) 기능의 부재**: 이 시나리오에서는 들어온 요청을 순서대로 쌓아두고 처리용 Lambda 함수가 하나씩 가져가 처리하는 **큐(Queue) 방식**이 필요합니다. SNS는 메시지를 저장해두는 대기열 기능이 없으므로, 처리하지 못한 요청은 그대로 유실될 수 있어 대용량 데이터의 안정적인 처리에 부적합합니다. 반면, SQS는 메시지를 안전하게 보관하는 대기열을 제공하여 이러한 문제를 해결합니다.

# 26

회사는 AWS 클라우드 배포를 검토하여 Amazon S3 버킷에 무단 구성 변경이 없는지확인해야 합니다.
솔루션 설계자는 이 목표를 달성하기 위해 무엇을 해야 합니까?

**A. AWS Config**

**AWS Config**는 **AWS 리소스의 구성을 평가, 감사 및 검토**할 수 있게 해주는 서비스입니다. 이 문제의 핵심 요구사항인 'S3 버킷의 무단 구성 변경이 없는지 확인'하는 목적에 가장 정확하게 부합합니다.

- **구성 변경 추적:** 어떤 리소스의 구성이 언제, 어떻게 변경되었는지에 대한 상세한 **이력**을 기록합니다.
- **규정 준수 확인:** 미리 정의된 규칙(AWS 관리형 규칙 또는 사용자 지정 규칙)에 따라 리소스 구성이 회사 정책을 준수하는지 **지속적으로 평가**합니다. 예를 들어, '모든 S3 버킷은 퍼블릭 액세스가 비활성화되어야 한다'는 규칙을 설정하고, 이 규칙을 위반하는 버킷이 생기면 즉시 알림을 받을 수 있습니다.
- **감사 및 보고:** 특정 시점의 리소스 구성 정보를 확인하고 규정 준수 감사에 필요한 보고서를 생성할 수 있습니다.

**B, C, D가 적절하지 않은 이유**

**B. AWS Trusted Advisor**

**AWS Trusted Advisor**는 AWS **모범 사례**에 따라 계정을 분석하고 비용 최적화, 성능, 보안, 내결함성, 서비스 한도에 대한 **권장 사항을 제공**하는 온라인 도구입니다.

- Trusted Advisor는 **실시간으로 모든 구성 변경을 추적하지 않습니다.** 정기적으로 계정을 스캔하여 모범 사례에 어긋나는 부분을 알려주는 **'조언자'** 역할에 가깝습니다.
- 문제에서 요구하는 '무단 구성 변경'을 즉시 탐지하고 상세한 변경 이력을 제공하는 감시 및 감사 도구라기보다는, 현재 상태에 대한 **개선점을 제안**하는 데 중점을 둡니다.

**C. Amazon Inspector**

**Amazon Inspector**는 자동화된 **보안 평가 서비스**로, AWS에 배포된 애플리케이션의 **취약점 및 보안 문제**를 검사합니다.

- Inspector의 주된 관심사는 **EC2 인스턴스, 컨테이너 이미지**와 같은 컴퓨팅 환경 내부입니다. 즉, 운영 체제(OS)의 패치가 누락되었는지, 알려진 소프트웨어 취약점이 있는지, 의도하지 않은 네트워크에 노출되었는지 등을 검사합니다.
- S3 버킷의 정책, ACL, 암호화 설정과 같은 **리소스 자체의 구성을 평가하는 서비스가 아닙니다.**

**D. S3 서버 액세스 로깅 + EventBridge**

- **S3 서버 액세스 로깅:** 버킷에 대한 **모든 요청(Request)을 기록**합니다. 예를 들어 누가 어떤 파일을 다운로드(GET)했는지, 업로드(PUT)했는지 등의 **객체 수준 작업**에 대한 로그를 제공합니다.
- **Amazon EventBridge:** AWS 서비스, 사용자 지정 애플리케이션 등에서 발생하는 **이벤트(Event)에 실시간으로 대응**하는 서버리스 이벤트 버스입니다.
- S3 서버 액세스 로깅은 버킷의 '구성 변경'보다는 버킷 내 '객체에 대한 접근'을 기록하는 데 중점을 둡니다. 구성 변경 API 호출(예: `PutBucketPolicy`)은 **AWS CloudTrail**에 기록됩니다.
- CloudTrail과 EventBridge를 조합하여 구성 변경 API 호출이 발생했을 때 알림을 보내는 시스템을 직접 구축할 수는 있습니다. 하지만 이는 단순히 '변경이 발생했다'는 사실에 반응하는 것이지, 그 변경이 '적절한 구성인지'를 **규칙 기반으로 지속적으로 평가하고 감사 이력을 관리**하는 AWS Config의 포괄적인 기능에는 미치지 못합니다. AWS Config는 이 목적을 위해 이미 만들어진 완제품 서비스입니다.

# 27

회사에서 새 애플리케이션을 시작하고 Amazon CloudWatch 대시보드에 애플리케이션 지표를 표시합니다. 회사의 제품 관리자는 이 대시보드에 주기적으로 액세스해야 합니다. 제품 관리자에게 AWS 계정이 없습니다. 솔루션 설계자는 최소 권한 원칙에 따라 제품 관리자에 대한 액세스를 제공해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**A. CloudWatch 콘솔에서 대시보드를 공유합니다. 제품 관리자의 이메일 주소를 입력하고 공유 단계를 완료합니다. 대시보드에 대한 공유 가능한 링크를 제품 관리자에게 제공하십시오.**

이 솔루션이 정답인 이유는 문제의 핵심 요구사항 두 가지를 가장 완벽하게 충족하기 때문입니다.

- **AWS 계정이 없는 사용자에게 공유:** CloudWatch의 **대시보드 공유 기능**은 이메일 주소만으로 외부 사용자와 특정 대시보드를 공유하기 위해 만들어진 기능입니다. 공유받는 사람은 AWS 계정에 로그인할 필요 없이 제공된 링크를 통해 대시보드만 조회할 수 있습니다.
- **최소 권한 원칙 (Principle of Least Privilege):** 이 방법은 **가장 강력한 수준의 최소 권한**을 제공합니다. 제품 관리자는 공유 설정된 **특정 대시보드 외에는** 다른 어떤 AWS 리소스(다른 대시보드, 경보, 로그 등)에도 접근할 수 없습니다. 딱 필요한 정보만 노출하는 가장 안전하고 이상적인 방법입니다.

**B, C, D가 적절하지 않은 이유**

**B. 특히 제품 관리자를 위한 IAM 사용자를 생성합니다. CloudWatchReadOnlyAccess AWS 관리형 정책을 사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오.올바른 대시보드의 브라우저 URL을 제품 관리자와 공유하십시오.**

IAM 사용자를 생성하고 CloudWatchReadOnlyAccess 정책을 연결

- **최소 권한 원칙 위반:** `CloudWatchReadOnlyAccess` 정책은 이름 그대로 CloudWatch 서비스 전체에 대한 읽기 권한을 부여합니다. 즉, 제품 관리자가 **모든 대시보드, 모든 지표, 모든 경보, 모든 로그 그룹**을 볼 수 있게 됩니다. 이는 요구사항인 '특정 애플리케이션 대시보드'만 보여주는 것이 아니라 과도한 권한을 부여하는 것이므로 최소 권한 원칙에 어긋납니다.
- **불필요한 계정 생성:** 문제에서 제품 관리자는 'AWS 계정이 없다'고 명시했습니다. 이들을 위해 굳이 IAM 사용자를 생성하고 자격 증명을 관리하는 것은 불필요한 관리 부담을 초래합니다.

**C. 회사 직원을 위한 IAM 사용자를 생성합니다. ViewOnlyAccess AWS 관리형 정책을 IAM 사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. 제품 관리자에게 CloudWatch 콘솔로 이동하여 대시보드 섹션에서 이름으로 대시보드를 찾으라고 요청합니다.**

IAM 사용자를 생성하고 ViewOnlyAccess 정책을 연결

- **심각한 최소 권한 원칙 위반:** `ViewOnlyAccess`(또는 `ReadOnlyAccess`) 정책은 CloudWatch뿐만 아니라 계정 내의 **거의 모든 AWS 서비스(EC2, S3, RDS 등)에 대한 읽기 권한**을 부여하는 매우 광범위한 정책입니다. 이는 단일 대시보드 접근이라는 요구사항에 비해 엄청나게 큰 권한을 주는 것으로, **보안상 매우 위험하며 최소 권한 원칙을 크게 위반**합니다.
- **불필요한 계정 생성:** B와 마찬가지로 불필요한 IAM 사용자 생성 및 관리 문제가 있습니다.

**D. 퍼블릭 서브넷에 배스천 서버를 배포합니다. 제품 관리자가 대시보드에 액세스해야 하는 경우 서버를 시작하고 RDP 자격 증명을 공유합니다. 배스천 서버에서 대시보드를 볼 수 있는 적절한 권한이 있는 캐시된 AWS 자격 증명으로 대시보드 URL 을 열도록 브라우저가 구성되어 있는지 확인합니다.**

배스천 서버(Bastion Server)를 배포

- **과도한 복잡성 및 비용:** 단순히 대시보드 하나를 보기 위해 EC2 인스턴스(배스천 서버)를 구축하고, 네트워크(퍼블릭 서브넷)를 구성하고, 원격 접속(RDP)을 관리하는 것은 **지나치게 복잡하고 비용이 많이 드는(over-engineered)** 해결책입니다.
- **운영 및 보안 부담:** 배스천 서버를 직접 운영하고 패치해야 하며, RDP 포트를 외부에 노출하는 것은 보안상 위험합니다. 또한 서버에 AWS 자격 증명을 캐싱하여 관리하는 방식은 좋은 보안 실천 방법이 아닙니다. A의 간단한 방법에 비해 모든 면에서 비효율적입니다.

# 28

회사에서 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 응용 프로그램은 다른 계정에 배포됩니다. 회사는 AWS Organizations 를 사용하여 중앙에서 계정을 관리합니다.
회사의 보안 팀은 회사의 모든 계정에 SSO(Single Sign-On) 솔루션이 필요합니다. 회사는 사내 자체 관리 Microsoft Active Directory 에서 사용자 및 그룹을 계속 관리해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

**B. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. Microsoft Active Directory 용 AWS Directory Service를 사용하여 회사의 자체 관리형 Microsoft Active Directory를 AWS SSO와 연결하는 양방향 포리스트 트러스트를 생성합니다.**

이 솔루션이 정답인 이유는 문제의 모든 요구사항을 가장 완벽하고 효율적으로 충족시키기 때문입니다.

- **중앙 관리형 SSO 솔루션 요구사항 충족**:
    - **AWS Single Sign-On (SSO)** 은 AWS Organizations와 완벽하게 통합되어 여러 AWS 계정에 대한 사용자 액세스를 중앙에서 관리하고 제어할 수 있는 **핵심 서비스**입니다. 사용자는 한 번의 로그인으로 할당된 모든 AWS 계정과 애플리케이션에 접근할 수 있습니다.
- **온프레미스 Microsoft AD 사용자/그룹 관리 요구사항 충족**:
    - 회사는 기존의 온프레미스 AD를 계속 사용하길 원합니다. 이를 AWS 환경과 연결하는 가장 표준적이고 강력한 방법은 **AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD)** 를 사용하는 것입니다.
    - **양방향 트러스트(Two-way trust)** 를 구성하면 온프레미스 AD와 AWS의 Managed AD가 서로의 리소스를 신뢰하고 인증 정보를 교환할 수 있습니다. 이를 통해 AWS SSO는 온프레미스 AD에 있는 사용자 및 그룹 정보를 원활하게 조회하고 인증을 처리할 수 있습니다.

이 두 가지를 조합하면, 관리자는 온프레미스 AD에서 사용자와 그룹을 관리하고, AWS SSO에서 이 그룹에 AWS 계정의 특정 권한(Permission Set)을 매핑하여 접근 제어를 손쉽게 구현할 수 있습니다.

**A, C, D가 적절하지 않은 이유**

**A. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. 단방향 포리스트 트러스트 또는 단방향 도메인 트러스트를 생성하여 Microsoft Active Directory 용 AWS Directory Service 를 사용하여 회사의 자체 관리형 Microsoft Active Directory 를 AWS SSO와 연결합니다.**

- 단방향 트러스트(One-way trust)를 생성
AWS SSO가 온프레미스 AD의 사용자와 그룹을 조회하고 인증을 원활하게 처리하려면, AWS Managed AD와 온프레미스 AD 간에 상호 인증이 가능한 **양방향 트러스트**가 필요합니다. 단방향 트러스트는 한쪽 디렉터리만 다른 쪽을 신뢰하므로, AWS SSO가 사용자 정보를 동기화하고 인증하는 과정에서 제약이 발생할 수 있습니다. 따라서 완전한 기능을 위해서는 양방향 트러스트가 권장되는 구성입니다.

**C. AWS 디렉터리 서비스를 사용합니다. 회사의 자체 관리 Microsoft Active Directory 와 양방향 신뢰 관계를 만드십시오.**

- AWS Directory Service만 사용하고 AWS SSO를 사용하지 않음

**D. 온프레미스에 ID 공급자(IdP)를 배포합니다. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다.**

- 온프레미스에 ID 공급자(IdP)를 배포
온프레미스에 ADFS(Active Directory Federation Services)와 같은 별도의 ID 공급자(IdP)를 배포하여 AWS SSO와 연동하는 것(SAML 2.0 기반 연동)도 **기술적으로는 가능한 아키텍처**입니다.

하지만

- **관리 복잡성 증가**: 회사가 직접 IdP 서버를 온프레미스에 구축하고 유지/관리해야 하므로 추가적인 관리 부담이 발생합니다.
- **더 복잡한 구성**: AWS Directory Service를 사용하는 것보다 구성이 더 복잡할 수 있습니다.

# 29

회사는 UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스를 제공합니다. 이 서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 회사는 여러 AWS 리전에 배포하고 있습니다. 회사는 지연 시간이 가장 짧은 리전으로 사용자를 라우팅해야 합니다. 이 회사는 또한 지역 간 자동 장애 조치가 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

**A. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 리전에서 NLB 를 AWS Global Accelerator 엔드포인트로 사용합니다.**

**NLB + AWS Global Accelerator (정답)**

이 솔루션이 모든 요구사항을 완벽하게 충족합니다.

- **NLB (Network Load Balancer)**: NLB는 OSI 4계층에서 작동하며 **TCP 및 UDP 트래픽을 처리**할 수 있습니다. 따라서 VoIP의 UDP 연결에 가장 적합한 로드 밸런서입니다.
- **AWS Global Accelerator**: Global Accelerator는 사용자를 성능 기반(지연 시간, 지터 등)으로 가장 가까운 최적의 리전 엔드포인트(이 경우 NLB)로 라우팅합니다. 또한 엔드포인트의 상태를 지속적으로 확인하여 장애 발생 시 **자동으로 트래픽을 정상 리전으로 신속하게 장애 조치**합니다. AWS의 광대한 글로벌 네트워크 엣지를 사용하므로 전반적인 연결 성능과 안정성이 향상됩니다.

**결론적으로 A는 UDP 지원, 최저 지연 시간 라우팅, 자동 장애 조치라는 모든 핵심 요구사항을 가장 효율적으로 만족시키는 조합입니다.**

**B, C, D가 적절하지 않은 이유**

**B. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 리전에서 ALB 를 AWS Global Accelerator 엔드포인트로 사용합니다.**

**C. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 AutoScaling 그룹과 연결합니다. 각 NLB 의 별칭을 가리키는 Amazon Route 53 지연 시간 레코드를 생성합니다. 지연 시간 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를생성합니다.**

**D. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 ALB의 별칭을 가리키는 Amazon Route 53 가중치 레코드를 생성합니다. 가중 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 배포합니다.**

- **ALB (Application Load Balancer)**: ALB는 OSI 7계층(HTTP/HTTPS)에서 작동합니다. **UDP 프로토콜을 지원하지 않으므로** VoIP 서비스에 사용할 수 없습니다
- **Route 53 가중치 레코드**: '가중치(Weighted)' 레코드는 설정된 가중치(비율)에 따라 트래픽을 분산합니다. 예를 들어 A 리전에 80%, B 리전에 20%를 보내는 식입니다. 이는 **'최저 지연 시간' 기반 라우팅이 아닙니다.**
- **Amazon CloudFront**: CloudFront는 주로 정적/동적 **웹 콘텐츠(HTTP/S)를 캐싱하고 전송하는 CDN** 서비스입니다. VoIP와 같은 실시간 양방향 UDP 트래픽을 처리하도록 설계되지 않았습니다. CloudFront를 통과하는 것은 부적절하며 성능 저하를 유발할 수 있습니다.

# 30

개발 팀은 성능 개선 도우미가 활성화된 MySQL DB 인스턴스용 범용 Amazon RDS 에서 매월 리소스 집약적 테스트를 실행합니다. 테스트는 한 달에 한 번 48 시간 동안 지속되며 데이터베이스를 사용하는 유일한 프로세스입니다. 팀은 DB 인스턴스의 컴퓨팅 및 메모리 속성을 줄이지 않고 테스트 실행 비용을 줄이려고 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

**개발팀:** "우리 앱/웹사이트가 대박 났을 때를 대비해서, 데이터베이스가 잘 버티는지 한 달에 한 번씩 극한의 테스트를 해보자!"
결론적으로, 이 문제는 **"한 달 중 48시간만 고성능으로 사용하고 나머지 28일은 사용하지 않을 DB를 어떻게 하면 가장 저렴하게 유지할 수 있는가?"**를 묻는 것입니다.

**C. 테스트가 완료되면 스냅샷을 만듭니다. DB 인스턴스를 종료하고 필요한 경우 스냅샷을 복원합니다.**

- **DB 인스턴스 비용 제거**: RDS 비용의 가장 큰 부분은 인스턴스 실행 시간(시간당 요금)입니다. DB 인스턴스를 종료(Terminate)하면 이 비용이 완전히 사라집니다.
- **저렴한 스토리지 비용**: 인스턴스가 종료된 동안에는 **스냅샷 스토리지 비용**만 발생합니다. 스냅샷 스토리지는 RDS 인스턴스에 연결된 활성 EBS 볼륨(프로비저닝된 스토리지)보다 훨씬 저렴합니다.
- **긴 유휴 기간에 최적화**: 시나리오는 "한 달에 한 번 48시간 동안" 테스트를 실행합니다. 즉, 약 28일 동안은 데이터베이스가 필요 없습니다. 이렇게 긴 유휴 기간에는 인스턴스를 완전히 제거하고 필요할 때만 복원하는 것이 압도적으로 비용을 절감할 수 있습니다.

**프로세스:** 테스트 완료 → 수동 스냅샷 생성 → DB 인스턴스 종료 → (약 28일 후) → 다음 테스트 직전 스냅샷에서 DB 인스턴스 복원

**A, B, D가 적절하지 않은 이유**

**A. 테스트가 완료되면 DB 인스턴스를 중지합니다. 필요한 경우 DB 인스턴스를 다시 시작합니다.**

- RDS DB 인스턴스는 최대 **7일까지만 중지(Stop)**할 수 있습니다. 7일이 지나면 AWS가 자동으로 인스턴스를 다시 시작합니다. 문제의 시나리오에서는 거의 한 달 동안 인스턴스를 사용하지 않아야 하므로, 7일 제한 때문에 이 방법은 적합하지 않습니다. 또한, 중지 기간에도 프로비저닝된 스토리지 비용은 계속 청구됩니다.

**B. DB 인스턴스와 함께 Auto Scaling 정책을 사용하여 테스트가 완료되면 자동으로 확장합니다.**

- RDS Auto Scaling은 주로 **읽기 전용 복제본(Read Replica)의 수를 트래픽에 따라 자동으로 조절**하는 기능입니다. 이 문제처럼 단일 DB 인스턴스의 크기(컴퓨팅 및 메모리)를 조절하여 비용을 절감하는 것과는 직접적인 관련이 없습니다. Auto Scaling은 유휴 상태일 때 인스턴스를 종료하거나 축소하는 기능이 아닙니다.

**D. 테스트가 완료되면 DB 인스턴스를 저용량 인스턴스로 수정합니다. 필요한 경우 DB 인스턴스를 다시 수정합니다.**

- 이 방법은 비용을 절감할 수는 있지만 **가장 비용 효율적이지는 않습니다.** 저용량 인스턴스로 변경하더라도 인스턴스는 계속 실행 중이므로 **인스턴스 시간당 요금과 프로비저닝된 스토리지 비용이 계속 발생**합니다. 스냅샷 후 종료하는 C 방법은 인스턴스 비용을 0으로 만들 수 있으므로, D보다 비용 절감 효과가 훨씬 큽니다.