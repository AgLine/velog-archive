# SAA-C03 덤프 91~120

게시일: Wed, 02 Jul 2025 13:33:37 GMT
링크: https://velog.io/@agline/SAA-C03-%EB%8D%A4%ED%94%84-91120

---

<h1 id="91">91</h1>
<p>회사에 VPC 의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 애플리케이션 중 하나는 Amazon S3 API 를 호출하여 객체를 저장하고 읽어야 합니다. 회사의 보안 규정에 따라 응용 프로그램의 트래픽은 인터넷을 통해 이동할 수 없습니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>A. S3 게이트웨이 엔드포인트를 구성합니다.</strong> </p>
<ul>
<li>VPC 게이트웨이 엔드포인트는 VPC와 Amazon S3 간에 <strong>프라이빗 연결</strong>을 제공하는 기능입니다. 이를 사용하면 EC2 인스턴스에서 S3로 보내는 트래픽이 인터넷 게이트웨이, NAT 게이트웨이, VPN 연결 또는 AWS Direct Connect 연결을 거치지 않고 AWS 네트워크 내에서 안전하게 통신할 수 있습니다.</li>
<li><strong>보안 요구사항 충족:</strong> 회사의 보안 규정인 &quot;애플리케이션의 트래픽은 인터넷을 통해 이동할 수 없습니다&quot;라는 요구사항을 완벽하게 만족시킵니다.</li>
</ul>
<h1 id="92">92</h1>
<p>회사에서 Amazon S3 버킷에 민감한 사용자 정보를 저장하고 있습니다. 회사는 VPC 내부의 Amazon EC2 인스턴스에서 실행되는 애플리케이션 계층에서 이 버킷에 대한 보안 액세스를 제공하려고 합니다. 솔루션 설계자는 이를 달성하기 위해 어떤 단계 조합을 취해야 합니까? (2 개를 선택하세요.) </p>
<p><strong>A. VPC 내에서 Amazon S3용 VPC 게이트웨이 엔드포인트를 구성합니다.</strong> </p>
<ul>
<li><strong>보안 (트래픽 경로):</strong> VPC 게이트웨이 엔드포인트(VPC Gateway Endpoint)는 VPC와 S3 간의 트래픽이 <strong>인터넷을 거치지 않고 AWS의 프라이빗 네트워크 내에서만</strong> 이루어지도록 합니다. 인터넷 게이트웨이(IGW)나 NAT 게이트웨이가 필요 없으므로, 민감한 데이터가 공용 인터넷에 노출될 위험을 원천적으로 차단합니다. 이는 보안을 극대화하는 가장 중요한 단계 중 하나입니다.</li>
</ul>
<p><strong>C. VPC 에서 실행되는 애플리케이션 계층으로만 액세스를 제한하는 버킷 정책을 생성합니다.</strong> </p>
<ul>
<li><strong>최소 권한 원칙:</strong> 이 방법을 사용하면, 설령 어떤 이유로 IAM 자격 증명이 외부에 유출되더라도 해당 자격 증명을 이용한 요청이 지정된 VPC 엔드포인트를 통해 오지 않으면 S3 버킷이 접근을 거부합니다. 이는 &quot;최소 권한의 원칙&quot;을 구현하는 강력한 보안 계층을 추가하는 것입니다.</li>
</ul>
<p>A <strong>(VPC 엔드포인트)는 안전한 통신 경로(터널)</strong>를 만들고, C (버킷 정책)는 그 <strong>터널을 통과한 요청만 허용하는 문</strong>을 만드는 것과 같습니다. </p>
<p><strong>B, D, E가 적절하지않은이유</strong></p>
<p><strong>B. S3 버킷의 객체를 퍼블릭으로 만들기 위한 버킷 정책을 생성합니다.</strong> </p>
<ul>
<li>문제에서 다루는 데이터는 &quot;민감한 사용자 정보&quot;입니다. 버킷을 퍼블릭으로 만드는 것은 이 정보를 인터넷상의 모든 사람에게 공개하는 것과 같으므로, 보안 요구사항에 정면으로 위배됩니다.</li>
</ul>
<p><strong>D. S3 액세스 정책으로 IAM 사용자를 생성하고 IAM 자격 증명을 EC2 인스턴스에 복사합니다.</strong> </p>
<ul>
<li>이것은 AWS에서 권장하지 않는 <strong>보안 안티패턴(Anti-Pattern)</strong>입니다.</li>
</ul>
<p><strong>E. NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 사용하여 S3 버킷에 액세스하도록 합니다.</strong></p>
<ul>
<li><strong>보안 수준 저하:</strong> 이 방식을 사용하면 EC2 인스턴스에서 S3로 가는 트래픽이 <strong>공용 인터넷을 경유</strong>하게 됩니다. 물론 HTTPS로 암호화되기는 하지만, VPC 엔드포인트를 사용하여 AWS 내부망으로만 통신하는 것보다는 보안 수준이 낮습니다.</li>
</ul>
<h1 id="93">93</h1>
<p>회사는 MySQL 데이터베이스로 구동되는 온프레미스 애플리케이션을 실행합니다. 이 회사는 애플리케이션의 탄력성과 가용성을 높이기 위해 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 현재 아키텍처는 정상 작동 시간 동안 데이터베이스에서 많은 읽기 활동을 보여줍니다. 회사의 개발 팀은 4 시간마다 프로덕션 데이터베이스의 전체 내보내기를 가져와 준비 환경의 데이터베이스를 채웁니다. 이 기간 동안 사용자는 허용할 수 없는 애플리케이션 대기 시간을 경험합니다. 개발 팀은 절차가 완료될 때까지 스테이징 환경을 사용할 수 없습니다. 솔루션 설계자는 애플리케이션 지연 문제를 완화하는 대체 아키텍처를 권장해야 합니다. 또한 대체 아키텍처는 개발 팀이 지연 없이 스테이징 환경을 계속 사용할 수 있는 능력을 제공해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p>스테이징이란?
소프트웨어나 애플리케이션을 개발해서 사용자들에게 최종적으로 배포하는 환경을 <strong>프로덕션(Production) 또는 운영 환경</strong>이라고 합니다. 스테이징 환경은 이 프로덕션 환경과 거의 동일하게 복제해 놓은 <strong>'모의 운영 환경'</strong>입니다.</p>
<p><strong>B. 프로덕션용 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL 을 사용합니다. 데이터베이스 복제를 사용하여 요청 시 스테이징 데이터베이스를 생성합니다.</strong> </p>
<ul>
<li><strong>애플리케이션 지연 문제 해결 (프로덕션 환경)</strong><ul>
<li><strong>Amazon Aurora:</strong> Aurora는 고성능 클라우드 네이티브 데이터베이스입니다. MySQL보다 몇 배 더 높은 처리량을 제공하므로, 기본적으로 많은 읽기 활동을 더 잘 처리할 수 있습니다.</li>
<li><strong>다중 AZ (Multi-AZ) 및 Aurora 복제본 (Read Replicas):</strong> 프로덕션 데이터베이스를 다중 AZ로 구성하면 장애 발생 시 자동으로 다른 가용 영역(AZ)으로 장애 조치(failover)되어 높은 가용성과 탄력성을 확보할 수 있습니다. 또한, 읽기 전용 복제본(Aurora Replica)을 여러 개 두어 많은 읽기 트래픽을 분산 처리함으로써 기본(마스터) 데이터베이스의 부하를 줄여 애플리케이션 지연을 최소화할 수 있습니다.</li>
</ul>
</li>
<li><strong>스테이징 환경 문제 해결 (빠르고 영향 없는 생성)</strong><ul>
<li><strong>데이터베이스 복제 (Database Cloning):</strong> 이것이 <strong>핵심적인 해결책</strong>입니다. Amazon Aurora의 '복제(Clone)' 기능은 기존 데이터베이스 클러스터를 기반으로 거의 즉시(몇 분 내에) 새로운 데이터베이스 클러스터를 생성할 수 있습니다.</li>
<li><strong>Copy-on-Write 프로토콜:</strong> Aurora 복제는 Copy-on-Write 프로토콜을 사용합니다. 이는 복제 시점에 실제 데이터 블록을 모두 복사하는 것이 아니라, 원본이나 복제본에서 데이터 변경이 발생할 때만 해당 데이터 블록을 복사하는 방식입니다.</li>
<li><strong>결과:</strong><ul>
<li><strong>성능 영향 없음:</strong> 복제 작업이 프로덕션 데이터베이스에 거의 또는 전혀 부하를 주지 않습니다. 따라서 4시간마다 발생하던 애플리케이션 지연 문제가 완전히 해결됩니다.</li>
<li><strong>신속한 생성:</strong> 개발팀은 몇 시간이 아닌 단 몇 분 만에 프로덕션 데이터의 최신 복사본을 가진 스테이징 환경을 사용할 수 있어 대기 시간이 사라집니다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지 않은 이유</strong></p>
<p><strong>A. 프로덕션용 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL 을 사용합니다. mysqldump 유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테이징 데이터베이스를 채웁니다.</strong> </p>
<ul>
<li>이 옵션은 프로덕션 환경에 Aurora를 도입하여 개선했지만, 스테이징 환경을 만드는 방식에서 기존의 문제를 그대로 가지고 있습니다. <code>mysqldump</code>는 데이터베이스의 전체 데이터를 논리적으로 내보내는(export) 유틸리티입니다. 이 작업은 프로덕션 데이터베이스에 상당한 읽기 부하를 발생시켜, 결국 사용자들이 겪는 <strong>애플리케이션 지연 문제를 해결하지 못합니다.</strong></li>
</ul>
<p><strong>C. 다중 AZ 배포 및 프로덕션용 읽기 전용 복제본과 함께 MySQL 용 Amazon RDS 를 사용합니다. 스테이징 데이터베이스에 대해 대기 인스턴스를 사용합니다.</strong> </p>
<ul>
<li><strong>대기 인스턴스의 목적:</strong> RDS의 다중 AZ 배포에서 대기 인스턴스는 <strong>장애 조치(failover)만을 위한 예비용</strong>입니다. 평상시에는 활성화되어 있지 않으며, 사용자가 직접 연결하여 데이터를 읽거나 쓸 수 없습니다. 주(Primary) 인스턴스에 장애가 발생했을 때만 자동으로 승격되어 서비스 연속성을 보장하는 역할을 합니다.</li>
</ul>
<p><strong>D. 다중 AZ 배포 및 프로덕션용 읽기 전용 복제본과 함께 MySQL 용 Amazon RDS 를 사용합니다. mysqldump 유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테이징데이터베이스를 채웁니다.</strong></p>
<ul>
<li>프로덕션 환경으로 RDS for MySQL을 사용하는 것은 합리적이지만, 스테이징 환경을 <code>mysqldump</code>로 생성하는 것은 <strong>프로덕션 데이터베이스에 부하를 주어 지연을 유발하는 근본적인 문제를 해결하지 못합니다.</strong></li>
</ul>
<h1 id="94">94</h1>
<p>한 회사에서 사용자가 Amazon S3 에 작은 파일을 업로드하는 애플리케이션을 설계하고 있습니다. 사용자가 파일을 업로드한 후 데이터를 변환하고 나중에 분석할 수 있도록 데이터를 JSON 형식으로 저장하려면 파일에 일회성 단순 처리가 필요합니다. 각 파일은 업로드 후 최대한 빨리 처리해야 합니다. 수요는 다양할 것입니다. 어떤 날에는 사용자가 많은 수의 파일을 업로드합니다. 다른 날에는 사용자가 몇 개의 파일을 업로드하거나 파일을 업로드하지 않습니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>C. 이벤트 알림을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 Amazon S3 를 구성합니다. AWS Lambda 함수를 사용하여 대기열에서 읽고 데이터를 처리합니다. 결과 JSON 파일을 Amazon DynamoDB에 저장합니다.</strong> </p>
<ul>
<li>Amazon S3 → Amazon SQS (이벤트 소스 및 디커플링)</li>
<li><strong>최소한의 운영 오버헤드:</strong> Lambda는 서버리스 컴퓨팅 서비스</li>
</ul>
<p><strong>A. Amazon S3 에서 텍스트 파일을 읽도록 Amazon EMR 을 구성합니다. 처리 스크립트를 실행하여 데이터를 변환합니다. 결과 JSON 파일을 Amazon Aurora DB 클러스터에 저장합니다.</strong> </p>
<ul>
<li><strong>Amazon EMR:</strong> EMR은 대규모 데이터 세트(빅데이터)를 처리하기 위한 하둡(Hadoop)이나 스파크(Spark) 클러스터 서비스입니다.</li>
</ul>
<p><strong>B. Amazon SQS(Amazon Simple Queue Service) 대기열에 이벤트 알림을 보내도록 Amazon S3 를 구성합니다. Amazon EC2 인스턴스를 사용하여 대기열에서 읽고 데이터를 처리합니다. 결과 JSON 파일을 Amazon DynamoDB에 저장합니다.</strong> </p>
<ul>
<li>Amazon EC2 인스턴스 사용 → 운영 오버헤드</li>
</ul>
<p><strong>D. 새 파일이 업로드될 때 Amazon Kinesis Data Streams 에 이벤트를 보내도록 Amazon EventBridge (Amazon CloudWatch Events)를 구성합니다. AWS Lambda 함수를 사용하여 스트림에서 이벤트를 소비하고 데이터를 처리합니다. 결과 JSON 파일을 Amazon Aurora DB 클러스터에 저장합니다.</strong></p>
<ul>
<li>Kinesis는 대량의 데이터를 실시간으로 스트리밍하고 처리하기 위한 서비스입니다.</li>
</ul>
<h1 id="95">95</h1>
<p>응용 프로그램을 사용하면 회사 본사의 사용자가 제품 데이터에 액세스할 수 있습니다. 제품 데이터는 Amazon RDS MySQL DB 인스턴스에 저장됩니다. 운영 팀은 애플리케이션 성능 저하를 격리하고 쓰기 트래픽에서 읽기 트래픽을 분리하려고 합니다. 솔루션 설계자는 애플리케이션의 성능을 신속하게 최적화해야 합니다. 솔루션 설계자는 무엇을 권장해야 합니까? </p>
<p><strong>D. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 원본 데이터베이스와 동일한 컴퓨팅 및 스토리지 리소스로 읽기 전용 복제본을 구성합니다.</strong></p>
<ul>
<li><strong>적절한 리소스 할당:</strong> 원본 데이터베이스에 부하를 주던 읽기 트래픽을 감당하려면, 읽기 전용 복제본도 그에 상응하는 성능을 갖추어야 합니다. 따라서 원본과 <strong>동일한 컴퓨팅 및 스토리지 리소스</strong>로 구성하는 것이 가장 안전하고 확실한 방법입니다. 만약 복제본의 사양이 너무 낮으면, 복제본 자체가 새로운 병목 지점이 될 수 있습니다.</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>C. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 컴퓨팅 및 스토리지 리소스의 절반을 원본 데이터베이스로 사용하여 읽기 전용 복제본을 구성합니다.</strong> </p>
<ul>
<li><strong>새로운 병목 발생 가능성:</strong> 현재 원본 데이터베이스가 읽기 트래픽 때문에 성능 저하를 겪고 있다는 것은, 그만큼 읽기 부하가 크다는 의미입니다. 이런 상황에서 원본보다 사양이 훨씬 낮은 복제본을 만들면, 이제는 그 복제본이 부하를 감당하지 못하고 새로운 성능 병목 지점이 될 가능성이 매우 높습니다.</li>
</ul>
<p><strong>A. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 기본 가용 영역에서 읽기 요청을 제공합니다.</strong> </p>
<p><strong>B. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 보조 가용 영역에서 읽기 요청을 제공합니다.</strong> </p>
<ul>
<li><strong>다중 AZ의 핵심 목적:</strong> 다중 AZ는 <strong>고가용성(High Availability) 및 장애 복구(Failover)</strong>를 위한 기능입니다.</li>
</ul>
<h1 id="96">96</h1>
<p>Amazon EC2 관리자는 여러 사용자가 포함된 IAM 그룹과 연결된 다음 정책을 생성했습니다.</p>
<p><img alt="" src="https://velog.velcdn.com/images/agline/post/3b3f1168-53b7-4326-bbb6-61d33a00104f/image.png" /></p>
<p>이 정책의 효과는 무엇입니까? </p>
<p><strong>C. 사용자는 사용자의 소스 IP 가 10.100.100.254 일 때 us-east-1 리전에서 EC2 인스턴스를 종료할 수 있습니다.</strong> </p>
<ul>
<li><strong>첫 번째 Statement (Allow):</strong><ul>
<li><code>Effect</code>: &quot;Allow&quot; (허용)</li>
<li><code>Action</code>: &quot;ec2:TerminateInstances&quot; (EC2 인스턴스 종료 작업)</li>
<li><code>Resource</code>: &quot;*&quot; (모든 리소스)</li>
<li><code>Condition</code>: <code>aws:SourceIp</code>가 <code>10.100.100.0/24</code> 대역일 경우.</li>
<li><strong>의미:</strong> 사용자의 IP 주소가 <code>10.100.100.0</code> ~ <code>10.100.100.255</code> 범위 안에 있을 때만 EC2 인스턴스 종료를 <strong>허용</strong>합니다.</li>
</ul>
</li>
<li><strong>두 번째 Statement (Deny):</strong><ul>
<li><code>Effect</code>: &quot;Deny&quot; (거부)</li>
<li><code>Action</code>: &quot;ec2:*&quot; (모든 EC2 작업)</li>
<li><code>Resource</code>: &quot;*&quot; (모든 리소스)</li>
<li><code>Condition</code>: <code>ec2:Region</code>이 <code>us-east-1</code>이 아닐 경우 (<code>StringNotEquals</code>)</li>
<li><strong>의미:</strong> 작업이 실행되는 리전이 <code>us-east-1</code>이 <strong>아니면</strong> 모든 EC2 작업을 <strong>거부</strong>합니다. 반대로 말하면, <code>us-east-1</code> 리전에서는 이 <code>Deny</code> 정책이 적용되지 않습니다.</li>
</ul>
</li>
</ul>
<p><strong>A. 사용자는 us-east-1 을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다.</strong> </p>
<ul>
<li>두 번째 <code>Deny</code> 문 때문입니다. 이 문은 리전이 <code>us-east-1</code>이 아닐 경우(<code>StringNotEquals</code>) 모든 EC2 작업(<code>ec2:*</code>)을 명시적으로 거부합니다. 따라서 사용자는 <code>us-east-1</code>을 제외한 다른 모든 리전에서는 어떤 EC2 작업도 수행할 수 없습니다.</li>
</ul>
<p><strong>B. 사용자는 us-east-1 리전에서 IP 주소가 10.100.100.1 인 EC2 인스턴스를 종료할 수 있습니다.</strong> </p>
<ul>
<li>정책의 IP 조건(<code>aws:SourceIp</code>)은 <strong>사용자(요청을 보내는 사람)의 IP 주소</strong>를 확인하는 것이지, 대상 <strong>EC2 인스턴스의 IP 주소</strong>를 확인하는 것이 아닙니다.</li>
</ul>
<p><strong>D. 사용자의 소스 IP 가 10.100.100.254 인 경우 사용자는 us-east-1 리전에서 EC2 인스턴스를 종료할 수 없습니다.</strong></p>
<ul>
<li>종료할수있음</li>
</ul>
<h1 id="97">97</h1>
<p>회사에는 Microsoft Windows 공유 파일 저장소가 필요한 온프레미스에서 실행되는 대규모 Microsoft SharePoint 배포가 있습니다. 회사는 이 워크로드를 AWS 클라우드로 마이그레이션하기를 원하며 다양한 스토리지 옵션을 고려하고 있습니다. 저장소 솔루션은 액세스 제어를 위해 고가용성 및 Active Directory와 통합되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>D. AWS 에서 Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하고 인증을 위해 Active Directory 도메인을 설정합니다.</strong></p>
<ul>
<li>FSx for Windows File Server는 Windows 기반 워크로드를 클라우드로 이전할 때 필요한 모든 핵심 요구사항(네이티브 Windows 호환성, 고가용성, AD 통합)을 가장 간단하고 효율적인 완전 관리형 서비스로 제공하기 때문에 정답</li>
</ul>
<p><strong>A, B, C가 적절하지 않은 이유</strong></p>
<p><strong>A. Amazon EFS 스토리지를 구성하고 인증을 위해 Active Directory 도메인을 설정합니다.</strong> </p>
<ul>
<li>Amazon EFS(Elastic File System)는 주로 Linux 워크로드를 위한 서비스이며 <strong>NFS(Network File System) 프로토콜</strong>을 사용합니다.</li>
<li>Microsoft SharePoint 및 Windows 환경은 기본적으로 SMB 프로토콜을 사용합니다.</li>
</ul>
<p><strong>B. 두 가용 영역의 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 생성합니다.</strong> </p>
<ul>
<li>AWS Storage Gateway의 파일 게이트웨이(File Gateway)는 SMB 공유를 제공하고 백엔드로 Amazon S3를 사용하므로 데이터는 내구성이 높습니다.</li>
<li>하지만 게이트웨이 자체(EC2 인스턴스 또는 VM)가 <strong>단일 장애 지점(Single Point of Failure)</strong>이 될 수 있습니다.</li>
</ul>
<p><strong>C. Amazon S3 버킷을 생성하고 볼륨으로 탑재하도록 Microsoft Windows Server 를 구성합니다.</strong> </p>
<ul>
<li>mazon S3는 <strong>객체 스토리지(Object Storage)</strong>이지, <strong>파일 스토리지(File Storage)</strong>가 아닙니다. 따라서 S3 버킷을 Windows에서 직접 파일 시스템 볼륨처럼 탑재할 수 없습니다.</li>
</ul>
<h1 id="98">98</h1>
<p>이미지 처리 회사에는 사용자가 이미지를 업로드하는 데 사용하는 웹 응용 프로그램이 있습니다. 애플리케이션은 이미지를 Amazon S3 버킷에 업로드합니다. 회사는 객체 생성 이벤트를 Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 게시하도록 S3 이벤트 알림을 설정했습니다. SQS 대기열은 이미지를 처리하고 결과를 이메일을 통해 사용자에게 보내는 AWS Lambda 함수의 이벤트 소스 역할을 합니다. 사용자는 업로드된 모든 이미지에 대해 여러 이메일 메시지를 수신하고 있다고 보고합니다. 솔루션 설계자는 SQS 메시지가 Lambda 함수를 두 번 이상 호출하여 여러 이메일 메시지를 생성한다고 판단합니다. 솔루션 설계자는 이 문제를 최소한의 운영 오버헤드로 해결하기 위해 무엇을 해야 합니까? </p>
<p><strong>C. SQS 대기열의 가시성 제한 시간을 함수 제한 시간과 일괄 처리 창 제한 시간의 합계보다 큰 값으로 늘립니다.</strong> </p>
<ul>
<li><strong>SQS의 '가시성 제한 시간(Visibility Timeout)'</strong> 과 <strong>Lambda 함수의 '처리 시간'</strong> 사이의 관계를 이해하는 것입니다.</li>
<li>현재:  가시성제한시간&lt;함수처리시간  → 가기성제한시간&gt;함수처리시간</li>
</ul>
<p><strong>A, B, D가 적절하지 않은 이유</strong></p>
<p><strong>A. ReceiveMessage 대기 시간을 30초로 늘려 SQS 대기열에서 긴 폴링을 설정합니다.</strong> </p>
<ul>
<li>이 기능은 <strong>메시지를 수신하는 단계의 효율성</strong>에 관한 것이지, <strong>이미 수신한 메시지가 중복으로 처리되는 문제</strong>를 해결하지는 못합니다. 문제의 원인과는 전혀 관련이 없습니다.</li>
</ul>
<p><strong>B. SQS 표준 대기열을 SQS FIFO 대기열로 변경합니다. 메시지 중복 제거 ID 를 사용하여 중복 메시지를 버리십시오.</strong> </p>
<ul>
<li><strong>SQS FIFO(First-In, First-Out) 대기열</strong>은 메시지 순서를 보장하고, <strong>정확히 한 번(Exactly-Once) 처리</strong>를 지원합니다. 메시지 중복 제거 ID는 대기열에 동일한 메시지가 중복으로 들어오는 것을 방지하는 기능입니다.</li>
<li>하지만 문제의 상황은 '중복 메시지가 대기열에 들어오는 것'이 아니라 '하나의 메시지가 여러 번 처리되는 것'입니다.</li>
</ul>
<p><strong>D. 처리 전에 메시지를 읽은 직후 SQS 대기열에서 각 메시지를 삭제하도록 Lambda 함수를 수정합니다.</strong></p>
<ul>
<li>이는 매우 위험한 <strong>안티패턴(Anti-Pattern)</strong>입니다.</li>
<li>메시지를 처리하기도 전에 삭제해버리면, 만약 Lambda 함수가 이미지 처리 도중 오류로 인해 실패하거나 타임아웃이 발생했을 때 어떤 일이 생길까요?</li>
<li>메시지는 이미 삭제되었기 때문에 재처리할 기회가 영원히 사라집니다. 즉, <strong>사용자가 업로드한 이미지가 처리되지 않고 유실</strong>되는 심각한 문제가 발생합니다.</li>
<li>항상 <strong>처리가 성공적으로 완료된 후에 메시지를 삭제</strong>하는 것이 올바른 패턴입니다. (Lambda-SQS 통합에서는 이 삭제가 자동으로 이루어집니다.)</li>
</ul>
<h1 id="99">99</h1>
<p>회사는 온프레미스 데이터 센터에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 구현하고 있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>D. Lustre 파일 시스템용 Amazon FSx 를 생성합니다. 파일 시스템을 원본 서버에 연결합니다. 응용 프로그램 서버를 파일 시스템에 연결합니다.</strong></p>
<ul>
<li><strong>공유 스토리지</strong>: 여러 클라이언트가 동시에 액세스할 수 있는 고성능 공유 파일 시스템을 제공합니다.</li>
<li><strong>Lustre 클라이언트 지원</strong>: Lustre는 고성능 컴퓨팅(HPC) 워크로드에 널리 사용되는 오픈 소스 병렬 파일 시스템입니다. Amazon FSx for Lustre는 Lustre와 완벽하게 호환되므로 기존 Lustre 클라이언트를 사용하여 파일 시스템에 액세스할 수 있습니다.</li>
<li><strong>완전 관리형</strong>: AWS가 파일 서버의 프로비저닝, 패치, 유지 관리 등 모든 관리 작업을 처리합니다. 사용자는 스토리지 용량, 처리량 등만 설정하면 되므로 인프라 관리에 대한 부담이 없습니다.</li>
</ul>
<p><strong>A, B, C가 적절하지 않은 이유:</strong></p>
<p><strong>A. AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다.</strong> </p>
<ul>
<li><strong>AWS Storage Gateway 파일 게이트웨이 NFS(Network File System) 및 SMB(Server Message Block) 프로토콜</strong>을 지원합니다. Lustre 프로토콜을 지원하지 않기 때문에 핵심 요구사항을 충족하지 못합니다.</li>
</ul>
<p><strong>B. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다.</strong> </p>
<ul>
<li>완전 관리형이 아님</li>
<li><strong>Lustre 미지원</strong>: Windows 파일 공유는 SMB 프로토콜을 사용합니다. Lustre 파일 시스템을 제공하지 않습니다.</li>
</ul>
<p><strong>C. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하고 Lustre 를 지원하도록 구성합니다. 파일 시스템을 원본 서버에 연결합니다. 응용 프로그램 서버를 파일 시스템에 연결합니다.</strong> </p>
<ul>
<li>Amazon EFS는 훌륭한 <strong>완전 관리형 공유 스토리지</strong> 솔루션이지만, <strong>NFSv4 프로토콜</strong>을 사용합니다. Lustre 클라이언트와 호환되지 않습니다.</li>
</ul>
<h1 id="100">100</h1>
<p>회사의 컨테이너화된 애플리케이션은 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 다른 비즈니스 애플리케이션과 통신하기 전에 보안 인증서를 다운로드해야 합니다. 회사는 거의 실시간으로 인증서를 암호화하고 해독할 수 있는 매우 안전한 솔루션을 원합니다. 또한 솔루션은 데이터가 암호화된 후 고가용성 스토리지에 데이터를 저장해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>C. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. EC2 역할이 암호화 작업에 KMS 키를 사용하도록 허용합니다. 암호화된 데이터를 Amazon S3 에 저장합니다.</strong> </p>
<ul>
<li><strong>매우 안전하고 거의 실시간인 암호화/복호화 (AWS KMS):</strong><ul>
<li>애플리케이션은 SDK를 통해 KMS API를 호출하여 거의 실시간으로 데이터를 암호화하고 복호화할 수 있습니다. 이는 &quot;거의 실시간으로 인증서를 암호화하고 해독&quot;해야 한다는 요구사항을 완벽히 만족시킵니다.</li>
<li><strong>고객 관리형 키(Customer-Managed Key)</strong>를 사용하면 키에 대한 정책, 순환 등을 직접 제어할 수 있어 보안 수준을 더욱 높일 수 있습니다.</li>
</ul>
</li>
<li><strong>최소한의 운영 오버헤드 (IAM 역할 및 관리형 서비스):</strong><ul>
<li><strong>EC2 역할(IAM Role)</strong>을 사용하는 것은 보안 모범 사례입니다. EC2 인스턴스에 직접 액세스 키를 저장할 필요 없이, 필요한 권한(이 경우 KMS 키 사용 권한)을 안전하게 부여할 수 있습니다. 키를 코드에 하드코딩하거나 인스턴스에 저장하는 방식보다 훨씬 안전하며, 키 관리 및 교체에 대한 운영 부담이 없습니다.</li>
<li>KMS와 S3 모두 AWS의 <strong>완전 관리형 서비스</strong>이므로, 인프라 관리, 패치, 확장 등에 대한 운영 오버헤드가 거의 없습니다.</li>
</ul>
</li>
<li><strong>고가용성 스토리지 (Amazon S3):</strong><ul>
<li><strong>Amazon S3</strong>는 99.999999999%(11-nines)의 내구성을 갖도록 설계된 객체 스토리지 서비스입니다.</li>
</ul>
</li>
</ul>
<p><strong>KMS + IAM 역할 + S3</strong> 조합은 AWS에서 제공하는 관리형 서비스를 활용하여 보안, 고가용성, 낮은 운영 부담이라는 세 마리 토끼를 모두 잡는 가장 이상적인 아키텍처입니다.</p>
<p><strong>A, B, D가 적절하지 않은 이유</strong></p>
<p><strong>A. 암호화된 인증서에 대한 AWS Secrets Manager 암호를 생성합니다. 필요에 따라 인증서를 수동으로 업데이트합니다. 세분화된 IAM 액세스를 사용하여 데이터에 대한 액세스를 제어합니다.</strong> </p>
<ul>
<li>&quot;필요에 따라 인증서를 <strong>수동으로 업데이트</strong>합니다&quot;라는 부분이 결정적인 단점입니다. 이 방식은 &quot;최소한의 운영 오버헤드&quot;라는 핵심 요구사항에 정면으로 위배됩니다.</li>
</ul>
<p><strong>B. Python 암호화 라이브러리를 사용하여 암호화 작업을 수신하고 수행하는 AWS Lambda 함수를 생성합니다. 함수를 Amazon S3 버킷에 저장합니다.</strong> </p>
<ul>
<li>직접 암호화 로직을 개발하고 관리하는 것은 <strong>매우 높은 운영 오버헤드와 보안 위험</strong>을 동반합니다.</li>
</ul>
<p><strong>D. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. EC2 역할이 암호화 작업에 KMS 키를 사용하도록 허용합니다. 암호화된 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다.</strong></p>
<ul>
<li>스토리지 선택이 잘못되었습니다. <strong>Amazon EBS</strong>는 EC2 인스턴스에 연결되는 블록 스토리지로, <strong>특정 가용 영역(AZ)에 종속</strong>됩니다.<ul>
<li><strong>고가용성 부족:</strong> EBS 볼륨은 생성된 AZ 내의 EC2 인스턴스에만 연결할 수 있습니다. 만약 해당 AZ에 장애가 발생하거나, 다른 AZ에 있는 EC2 인스턴스에서 인증서에 접근해야 할 경우, EBS 볼륨의 데이터에 접근할 수 없습니다. 이는 &quot;고가용성 스토리지&quot; 요구사항을 충족시키지 못합니다.</li>
<li><strong>공유의 어려움:</strong> 여러 EC2 인스턴스에서 하나의 EBS 볼륨을 동시에 공유하는 것은 복잡하며(EBS Multi-Attach는 특정 인스턴스 유형과 파일 시스템에서만 제한적으로 지원), S3를 사용하는 것보다 훨씬 어렵습니다. 반면 S3는 리전 내 모든 AZ의 인스턴스에서 쉽게 접근할 수 있는 공유 스토리지입니다.</li>
</ul>
</li>
</ul>
<h1 id="101">101</h1>
<p>솔루션 설계자는 퍼블릭 및 프라이빗 서브넷이 있는 VPC 를 설계하고 있습니다. VPC 와 서브넷은 IPv4 CIDR 블록을 사용합니다. 고가용성을 위해 세 개의 가용 영역(AZ) 각각에 하나의 퍼블릭 서브넷과 하나의 프라이빗 서브넷이 있습니다. 인터넷 게이트웨이는 퍼블릭 서브넷에 대한 인터넷 액세스를 제공하는 데 사용됩니다. 프라이빗 서브넷은 Amazon EC2 인스턴스가 소프트웨어 업데이트를 다운로드할 수 있도록 인터넷에 액세스할 수 있어야 합니다. 솔루션 설계자는 프라이빗 서브넷에 대한 인터넷 액세스를 활성화하기 위해 무엇을 해야 합니까? </p>
<p><strong>A. 각 AZ 의 각 퍼블릭 서브넷에 대해 하나씩 3 개의 NAT 게이트웨이를 생성합니다. 비 VPC 트래픽을 해당AZ  의 NAT 게이트웨이로 전달하는 각 AZ 에 대한 프라이빗 라우팅 테이블을 생성합니다.</strong> </p>
<ul>
<li><strong>NAT 게이트웨이의 역할</strong>: NAT(Network Address Translation) 게이트웨이는 프라이빗 서브넷에 있는 인스턴스가 인터넷과 통신할 수 있도록 IP 주소를 변환해주는 AWS 관리형 서비스입니다. 프라이빗 IP를 가진 인스턴스가 외부로 통신을 시작(outbound)할 수는 있지만, 외부에서 먼저 연결을 시작(inbound)할 수는 없게 만들어 보안 요구사항을 완벽하게 충족합니다.</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. 각 AZ 의 프라이빗 서브넷마다 하나씩 3 개의 NAT 인스턴스를 생성합니다. 비 VPC 트래픽을 해당 AZ 의 NAT 인스턴스로 전달하는 각 AZ 에 대한 프라이빗 라우팅 테이블을 생성합니다.</strong> </p>
<ul>
<li>AWS에서는 NAT 인스턴스보다 <strong>NAT 게이트웨이 사용을 강력히 권장</strong>합니다.</li>
</ul>
<p><strong>C. 프라이빗 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성합니다. VPC 가 아닌 트래픽을 프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.</strong> </p>
<ul>
<li>인터넷 게이트웨이(IGW)는 VPC와 인터넷 간의 <strong>양방향 통신</strong>을 허용하는 관문입니다. 라우팅 테이블에 IGW로 향하는 경로(<code>0.0.0.0/0 -&gt; igw-xxxx</code>)가 있는 서브넷은 '퍼블릭 서브넷'이 됩니다.</li>
<li>하나의 VPC에는 <strong>오직 하나의 인터넷 게이트웨이</strong>만 연결할 수 있습니다.</li>
</ul>
<p><strong>D. 퍼블릭 서브넷 중 하나에 송신 전용 인터넷 게이트웨이를 생성합니다. VPC 가 아닌 트래픽을 외부 전용 인터넷 게이트웨이로 전달하는 프라이빗 서브넷에 대한 라우팅 테이블을 업데이트합니다.</strong></p>
<ul>
<li>송신 전용 인터넷 게이트웨이(Egress-Only Internet Gateway)는 <strong>IPv6</strong> 트래픽을 위해 설계된 서비스입니다.</li>
<li>문제에서는 명확하게 <strong>IPv4 CIDR 블록</strong>을 사용한다고 명시했습니다.</li>
</ul>
<h1 id="102">102</h1>
<p>회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 데이터 센터는 NFS 기반 파일 시스템에 데이터를 저장하는 SFTP 서버를 호스팅합니다. 서버에는 전송해야 하는 200GB 의 데이터가 있습니다. 서버는 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용하는 Amazon EC2 인스턴스에서 호스팅되어야 합니다. 솔루션 설계자는 이 작업을 자동화하기 위해 어떤 단계 조합을 취해야 합니까? (2 개를 선택하세요.) </p>
<p><strong>A. EFS 파일 시스템과 동일한 가용 영역에서 EC2 인스턴스를 시작합니다.</strong> </p>
<ul>
<li>Amazon EFS 파일 시스템에 EC2 인스턴스가 접근하려면 '탑재 대상(Mount Target)'이 필요합니다. 이 탑재 대상은 특정 가용 영역(Availability Zone, AZ) 내에 생성됩니다.</li>
<li>EC2 인스턴스가 EFS 탑재 대상과 <strong>동일한 가용 영역</strong>에 있으면, 데이터 전송 지연 시간이 매우 짧고(낮은 레이턴시) 추가적인 데이터 전송 비용이 발생하지 않습니다.</li>
<li>만약 다른 가용 영역에 있는 EC2 인스턴스에서 EFS에 접근하면, 가용 영역 간 데이터 전송 비용이 발생하고 네트워크 지연 시간도 길어집니다. 따라서 SFTP 서버와 같이 파일 시스템 접근이 잦은 애플리케이션의 성능을 위해서는 동일 가용 영역에 배포하는 것이 필수적인 모범 사례입니다.</li>
</ul>
<p><strong>B. 온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다.</strong> </p>
<ul>
<li>AWS DataSync는 온프레미스 스토리지와 AWS 스토리지 서비스 간의 데이터 전송을 자동화하고 가속화하도록 특별히 설계된 서비스입니다. 200GB라는 대용량 데이터를 안정적으로 옮기는 데 가장 적합한 도구입니다.</li>
<li>DataSync를 사용하려면 가장 먼저 온프레미스 데이터 센터(VMware, Hyper-V 등)에 <strong>DataSync 에이전트(가상 머신)</strong>를 설치해야 합니다.</li>
</ul>
<p><strong>C, D, E가 적절하지않은이유</strong></p>
<p><strong>C. 데이터에 대한 EC2 인스턴스에 보조 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다.</strong> </p>
<ul>
<li>Amazon EBS는 단일 EC2 인스턴스에만 연결하여 사용하는 블록 스토리지입니다.</li>
</ul>
<p><strong>D. 수동으로 운영 체제 복사 명령을 사용하여 데이터를 EC2 인스턴스로 푸시합니다.</strong></p>
<ul>
<li>문제는 &quot;자동화&quot;된 솔루션을 요구하고 있습니다.</li>
</ul>
<p><strong>E. AWS DataSync 를 사용하여 온프레미스 SFTP 서버에 적합한 위치 구성을 생성합니다.</strong></p>
<ul>
<li>AWS DataSync는 <strong>파일 시스템 레벨</strong>에서 작동합니다. 즉, 데이터 소스로 NFS나 SMB 같은 파일 공유 프로토콜을 직접 지원합니다.</li>
</ul>
<h1 id="103">103</h1>
<p>회사에 매일 같은 시간에 실행되는 AWS Glue 추출, 변환 및 로드(ETL) 작업이 있습니다. 작업은 Amazon S3 버킷에 있는 XML 데이터를 처리합니다. 매일 새로운 데이터가 S3 버킷에 추가됩니다. 솔루션 설계자는 AWS Glue 가 각 실행 중에 모든 데이터를 처리하고 있음을 알아차렸습니다. 솔루션 아키텍트는 AWS Glue가 오래된 데이터를 재처리하지 못하도록 하려면 어떻게 해야 합니까? </p>
<p><strong>A. 작업 북마크를 사용하도록 작업을 편집합니다.</strong> </p>
<ul>
<li><strong>AWS Glue 작업 북마크(Job Bookmark)</strong>는 AWS Glue가 ETL 작업을 실행할 때 <strong>어디까지 데이터를 처리했는지 상태 정보를 지속적으로 저장하고 추적하는 기능</strong>입니다.</li>
<li><strong>동작 원리:</strong><ul>
<li>작업 북마크를 활성화하면, Glue 작업이 성공적으로 완료될 때마다 처리한 파일의 상태 정보(예: S3 객체의 최종 수정 타임스탬프)를 저장합니다.</li>
<li>다음 번에 동일한 작업이 실행되면, Glue는 저장된 북마크 정보를 참조하여 <strong>이전에 처리한 데이터는 건너뛰고 그 이후에 추가되거나 수정된 새로운 데이터만 처리</strong>합니다.</li>
</ul>
</li>
</ul>
<p><strong>B, C, D가 적절하지 않은 이유</strong></p>
<p><strong>B. 데이터가 처리된 후 데이터를 삭제하도록 작업을 편집합니다.</strong> </p>
<ul>
<li>이 방법은 처리된 원본 데이터를 영구적으로 삭제하므로 매우 위험합니다.</li>
</ul>
<p><strong>C. NumberOfWorkers 필드를 1로 설정하여 작업을 편집합니다.</strong> </p>
<ul>
<li><code>NumberOfWorkers</code>는 Glue 작업에 할당할 DPU(Data Processing Unit)의 수를 지정하여 <strong>작업의 병렬 처리 수준과 성능을 제어하는 설정</strong>입니다.</li>
</ul>
<p><strong>D. FindMatches 기계 학습(ML) 변환을 사용합니다.</strong></p>
<ul>
<li>데이터 세트 내에서 <strong>중복되거나 유사한 레코드(Record)를 식별하고 연결하는 데 사용되는 머신러닝 변환 기능</strong>입니다. 예를 들어, &quot;AWS&quot;와 &quot;Amazon Web Services&quot;를 같은 엔티티로 식별하는 등의 작업에 사용됩니다.</li>
</ul>
<h1 id="104">104</h1>
<p>솔루션 설계자는 웹사이트를 위한 고가용성 인프라를 설계해야 합니다. 웹 사이트는 Amazon EC2 인스턴스에서 실행되는 Windows 웹 서버에 의해 구동됩니다. 솔루션 설계자는 수천 개의 IP 주소에서 시작되는 대규모 DDoS 공격을 완화할 수 있는 솔루션을 구현해야 합니다. 다운타임은 웹사이트에 허용되지 않습니다. 솔루션 설계자는 이러한 공격으로부터 웹사이트를 보호하기 위해 어떤 조치를 취해야 합니까? (2개를 선택하세요.) </p>
<p><strong>A. AWS Shield Advanced 를 사용하여 DDoS 공격을 차단하십시오.</strong> </p>
<p><strong>C. 정적 및 동적 콘텐츠 모두에 Amazon CloudFront 를 사용하도록 웹 사이트를 구성합니다.</strong> </p>
<ul>
<li><strong>공격 트래픽 흡수</strong>: CloudFront는 전 세계에 분산된 수백 개의 엣지 로케이션(Edge Location)을 가지고 있습니다. DDoS 공격 트래픽이 발생하면, 이 트래픽은 사용자의 원본 서버(EC2 인스턴스)에 도달하기 전에 분산된 엣지 로케이션으로 흡수 및 분산됩니다. 이 거대한 네트워크 인프라 자체가 대규모 공격을 견뎌낼 수 있는 방패 역할을 합니다.</li>
</ul>
<p><strong>B, D, E가 적절하지않은이유</strong></p>
<p><strong>B. 공격자를 자동으로 차단하도록 Amazon GuardDuty를 구성합니다.</strong> </p>
<ul>
<li>GuardDuty는 위협 '탐지' 서비스입니다. VPC Flow Logs, DNS 로그, CloudTrail 로그 등을 분석하여 의심스러운 활동(예: 악성 IP와의 통신, 비정상적인 API 호출)을 찾아내지만, 스스로 트래픽을 '차단'하지는 않습니다.</li>
</ul>
<p><strong>D. AWS Lambda 함수를 사용하여 VPC 네트워크 ACL 에 공격자 IP 주소를 자동으로 추가합니다.</strong> </p>
<ul>
<li>NACL에는 규칙 수 제한이 있어 수천 개의 IP를 모두 추가하기 어렵습니다.</li>
</ul>
<p><strong>E. 80% CPU 사용률로 설정된 대상 추적 조정 정책과 함께 Auto Scaling 그룹의 EC2 스팟 인스턴스를 사용합니다.</strong></p>
<ul>
<li><strong>스팟 인스턴스</strong>: 스팟 인스턴스는 AWS가 여유 용량을 저렴하게 제공하는 대신, 언제든지 회수할 수 있습니다. &quot;다운타임이 허용되지 않는&quot; 고가용성 웹사이트에는 부적합합니다.</li>
</ul>
<h1 id="105">105</h1>
<p>회사에서 새로운 서버리스 워크로드를 배포할 준비를 하고 있습니다. 솔루션 설계자는 최소 권한 원칙을 사용하여 AWS Lambda 함수를 실행하는 데 사용할 권한을 구성해야 합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙이 함수를 호출합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>D. lambda:InvokeFunction 을 작업으로, Service: <a href="http://events.amazonaws.com/">events.amazonaws.com</a> 을 보안 주체로 사용하여 리소스 기반 정책을 함수에 추가합니다.</strong></p>
<ul>
<li><strong>리소스 기반 정책 (Resource-Based Policy):</strong><ul>
<li>Lambda 함수와 같은 리소스에 직접 연결하여, <strong>어떤 외부 서비스나 계정이 이 리소스에 접근(호출)할 수 있는지</strong>를 정의하는 정책입니다.</li>
<li>EventBridge가 Lambda 함수를 호출하는 시나리오는, 외부 서비스(EventBridge)가 내 리소스(Lambda 함수)에 접근하는 것이므로 리소스 기반 정책을 설정하는 것이 올바른 방법입니다.</li>
</ul>
</li>
<li><strong>보안 주체 (Principal): <code>Service: events.amazonaws.com</code></strong><ul>
<li><code>Principal</code>은 권한을 부여받는 대상을 지정합니다.</li>
<li><code>events.amazonaws.com</code>으로 지정하면 오직 <strong>Amazon EventBridge 서비스</strong>만이 이 Lambda 함수를 호출할 수 있는 권한을 갖게 됩니다. 다른 서비스나 사용자는 호출할 수 없습니다. 이것이 바로 최소 권한의 핵심입니다.</li>
</ul>
</li>
<li><strong>작업 (Action): <code>lambda:InvokeFunction</code></strong><ul>
<li><code>Action</code>은 허용할 구체적인 작업을 명시합니다.</li>
<li><code>lambda:InvokeFunction</code>은 함수를 실행(호출)하는 데 필요한 <strong>정확하고 유일한 권한</strong>입니다. 함수를 삭제하거나 코드를 수정하는 등의 불필요하고 위험한 권한을 부여하지 않습니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, C가 적절하지 않은 이유</strong></p>
<p><strong>B. 작업으로 lambda:InvokeFunction 을 사용하고 보안 주체로 Service: <a href="http://lambda.amazonaws.com/">lambda.amazonaws.com</a> 을 사용하여 함수에 실행 역할을 추가합니다.</strong> </p>
<ul>
<li><strong>실행 역할(Execution Role)은 Lambda 함수가 실행될 때</strong> 다른 AWS 서비스(예: S3, DynamoDB)에 접근하기 위해 필요한 권한입니다. 다른 서비스가 Lambda를 호출하는 권한을 정의하는 데 사용되지 않습니다.</li>
</ul>
<p><strong>A. lambda:InvokeFunction 을 작업으로, *를 보안 주체로 사용하여 함수에 실행 역할을 추가합니다.</strong> </p>
<p><strong>C. 작업으로 lambda:*를 사용하고 보안 주체로 Service: <a href="http://events.amazonaws.com/">events.amazonaws.com</a> 을 사용하여 리소스 기반 정책을 함수에 추가합니다.</strong> </p>
<ul>
<li><code>*</code>(와일드카드)로 설정하면 <strong>누구나</strong> 이 함수를 호출할 수 있게 되어 심각한 보안 허점을 만듭니다. 최소 권한 원칙에 정면으로 위배됩니다.</li>
</ul>
<h1 id="106">106</h1>
<p>회사에서 Amazon S3 에 기밀 데이터를 저장할 준비를 하고 있습니다. 규정 준수를 위해 미사용 데이터를 암호화해야 합니다. 암호화 키 사용은 감사 목적으로 기록되어야 합니다. 키는 매년 순환해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? </p>
<p><strong>D. 자동 교체 기능이 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화</strong></p>
<ul>
<li>키 자동순환 → AWS KMS</li>
</ul>
<p><strong>A. 고객 제공 키를 사용한 서버 측 암호화(SSE-C)</strong> </p>
<p><strong>B. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3)</strong> </p>
<p><strong>C. 수동 교체가 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화</strong> </p>
<h1 id="107">107</h1>
<p>자전거 공유 회사는 피크 운영 시간 동안 자전거의 위치를 추적하기 위해 다층 아키텍처를 개발하고 있습니다. 회사는 기존 분석 플랫폼에서 이러한 데이터 포인트를 사용하려고 합니다. 솔루션 설계자는 이 아키텍처를 지원하기 위해 가장 실행 가능한 다중 계층 옵션을 결정해야 합니다. 데이터 포인트는 REST API에서 액세스할 수 있어야 합니다. 위치 데이터 저장 및 검색에 대한 이러한 요구 사항을 충족하는 작업은 무엇입니까 </p>
<p><strong>B. AWS Lambda 와 함께 Amazon API Gateway를 사용합니다.</strong> </p>
<ul>
<li><strong>1계층 (프레젠테이션 계층): Amazon API Gateway</strong><ul>
<li>API Gateway는 REST API 엔드포인트(<code>https://api.example.com/bikes/123/location</code>)를 생성하고 외부에 노출하는 역할을 합니다. 즉, <strong>&quot;REST API에서 액세스할 수 있어야 한다&quot;</strong>는 요구사항을 직접적으로 해결합니다.</li>
<li>클라이언트(앱, 웹 등)의 요청을 받는 '현관' 역할을 하며, 인증, 권한 부여, 트래픽 제어(Throttling) 등 다양한 부가 기능을 제공합니다.</li>
</ul>
</li>
<li><strong>2계층 (로직 계층): AWS Lambda</strong><ul>
<li>API Gateway가 받은 요청을 처리할 '두뇌' 역할을 합니다.</li>
<li>API Gateway를 통해 특정 요청이 들어오면, 연결된 Lambda 함수가 자동으로 실행됩니다. 이 함수 안에서 비즈니스 로직(예: 요청된 자전거 ID 확인)을 수행하고 데이터 계층에 접근하여 데이터를 가져오거나 저장합니다.</li>
</ul>
</li>
<li><strong>3계층 (데이터 계층): (Lambda가 접근할 데이터베이스)</strong><ul>
<li>문제의 선택지에는 명시되지 않았지만, Lambda 함수는 위치 데이터를 <strong>저장하고 검색</strong>하기 위해 Amazon DynamoDB(실시간 위치 추적에 가장 적합한 NoSQL 데이터베이스)나 Amazon RDS 같은 데이터베이스와 통신하게 됩니다.</li>
</ul>
</li>
</ul>
<p><strong>A, C, D가 적절하지 않은 이유</strong></p>
<p><strong>A. Amazon S3 와 함께 Amazon Athena를 사용하십시오.</strong> </p>
<ul>
<li>이 조합은 <strong>실시간 데이터 검색 API용이 아닌, 분석용</strong>입니다.</li>
</ul>
<p><strong>C. Amazon Redshift 와 함께 Amazon QuickSight 를 사용합니다.</strong> </p>
<ul>
<li>이 조합은 <strong>비즈니스 인텔리전스(BI) 및 데이터 시각화</strong>를 위한 것입니다.</li>
</ul>
<p><strong>D. Amazon Kinesis Data Analytics 와 함께 Amazon API Gateway 를 사용합니다.</strong></p>
<ul>
<li>이 조합은 <strong>데이터 저장 및 검색이 아닌, 실시간 스트림 데이터 분석</strong>을 위한 것입니다.</li>
</ul>
<h1 id="108">108</h1>
<p>한 회사에 Amazon RDS 의 데이터베이스에 목록을 저장하는 자동차 판매 웹사이트가 있습니다. 자동차가 판매되면 웹사이트에서 목록을 제거해야 하고 데이터를 여러 대상 시스템으로 보내야 합니다. 솔루션 아키텍트는 어떤 디자인을 추천해야 할까요? </p>
<p>D. Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.</p>
<ul>
<li>RDS 이벤트 알림을 구독하고 Amazon Simple Notification Service(Amazon SNS) 주제를 여러 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. AWS Lambda 함수를 사용하여 대상을 업데이트합니다</li>
<li>이 아키텍처는 <strong>팬아웃(Fan-out)</strong> 패턴의 가장 이상적인 구현입니다</li>
<li><strong>SNS를 허브로 사용하여 여러 SQS 대기열로 메시지를 팬아웃하는 D</strong>가 가장 분리되고, 확장 가능하며, 안정적인 솔루션입니다.</li>
</ul>
<p>C. Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.</p>
<ul>
<li>RDS 이벤트 알림을 구독하고Amazon Simple Queue Service(Amazon SQS) 주제를 여러  Amazon Simple Notification Service(Amazon SNS) 대기열로 보냅니다. AWS Lambda 함수를 사용하여 대상을 업데이트합니다</li>
<li><strong>잘못된 아키텍처 흐름 :</strong> <code>SQS 대기열 -&gt; SNS 주제로 팬아웃</code> 이라는 흐름은 <strong>아키텍처적으로 성립하지 않습니다.</strong></li>
</ul>
<h1 id="109">109</h1>
<p>회사는 Amazon S3 에 데이터를 저장해야 하며 데이터가 변경되지 않도록 해야 합니다. 회사는 Amazon S3 에 업로드된 새 객체가 회사가 객체를 수정하기로 결정할 때까지 일정하지 않은 시간 동안 변경할 수 없는 상태로 유지되기를 원합니다. 회사 AWS 계정의 특정 사용자만 객체를 삭제할 수 있습니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? </p>
<p><strong>D. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 버전 관리를 활성화합니다. 개체에 법적 보존을 추가합니다. 객체를 삭제해야 하는 사용자의 IAM 정책에 s3:PutObjectLegalHold 권한을 추가합니다.</strong></p>
<ul>
<li><strong>데이터 변경 불가</strong>: <code>S3 객체 잠금(Object Lock)</code> 기능은 객체를 WORM(Write-Once, Read-Many) 모델로 보호하여 정해진 기간 또는 무기한으로 객체가 덮어쓰이거나 삭제되는 것을 방지합니다.</li>
<li><strong>일정하지 않은 시간 동안 변경 불가</strong>: S3 객체 잠금에는 두 가지 모드가 있습니다: <strong>보존 기간(Retention Period)</strong>과 <strong>법적 보존(Legal Hold)</strong>.<ul>
<li><strong>보존 기간</strong>: <em>정해진 만료 날짜</em>까지 객체를 보호합니다.</li>
<li><strong>법적 보존(Legal Hold)</strong>: 명시적으로 제거할 때까지 <em>무기한</em>으로 객체를 보호합니다. 만료 날짜가 없습니다.
문제에서 &quot;일정하지 않은 시간 동안&quot; 보호하고 &quot;회사가 수정하기로 결정할 때까지&quot; 유지되기를 원하므로, 만료 기간이 없는 <strong>법적 보존(Legal Hold)</strong>이 가장 적합합니다.</li>
</ul>
</li>
<li><strong>특정 사용자만 객체 삭제 가능</strong>: <code>s3:PutObjectLegalHold</code> IAM 권한은 사용자에게 법적 보존을 설정하거나 <strong>해제</strong>할 수 있는 권한을 부여합니다. 이 권한을 가진 특정 사용자만이 법적 보존을 해제하고 객체를 삭제할 수 있으므로, 권한 있는 사용자만 삭제할 수 있다는 요구사항을 만족시킵니다.</li>
<li><strong>버전 관리 활성화</strong>: S3 객체 잠금을 사용하려면 반드시 S3 버킷에 버전 관리(Versioning)가 활성화되어 있어야 합니다. 이 선택지는 이 전제 조건까지 정확히 명시하고 있습니다.</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. S3 Glacier 볼트를 생성합니다. WORM(Write-Once, Read-Many) 볼트 잠금 정책을 개체에 적용합니다.</strong> </p>
<ul>
<li>문제의 요구사항은 'Amazon S3'에 데이터를 저장하는 것이지, 장기 아카이브 스토리지인 'S3 Glacier'가 아닙니다.</li>
<li>S3 Glacier 볼트 잠금 정책(Vault Lock)도 WORM 기능을 제공하지만, 일단 잠그면 정책을 변경하거나 제거하기가 매우 어렵거나 불가능합니다. &quot;회사가 수정하기로 결정할 때&quot; 유연하게 잠금을 해제해야 하는 요구사항과는 맞지 않습니다.</li>
</ul>
<p><strong>B. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 버전 관리를 활성화합니다. 보존 기간을 100 년으로 설정합니다. 거버넌스 모드를 새 객체에 대한 S3 버킷의 기본 보존 모드로 사용합니다.</strong> </p>
<ul>
<li>가장 큰 문제점은 <code>보존 기간을 100년으로 설정</code>하는 부분입니다. 문제에서는 &quot;일정하지 않은 시간&quot; 동안 보호해야 한다고 명시했는데, 이 선택지는 '100년'이라는 고정된 기간을 설정합니다.</li>
</ul>
<p><strong>C. S3 버킷을 생성합니다. AWS CloudTrail 을 사용하여 객체를 수정하는 모든 S3 API 이벤트를 추적합니다. 통지 시 회사가 보유한 모든 백업 버전에서 수정된 개체를 복원합니다.</strong> </p>
<ul>
<li>이 솔루션은 데이터 변경을 <strong>방지</strong>하지 못합니다. AWS CloudTrail은 API 호출을 기록하고 모니터링하는 서비스일 뿐, 변경 자체를 막는 기능이 없습니다.</li>
</ul>
<h1 id="110">110</h1>
<p>소셜 미디어 회사는 사용자가 웹사이트에 이미지를 업로드할 수 있도록 합니다. 웹 사이트는 Amazon EC2 인스턴스에서 실행됩니다. 업로드 요청 중에 웹 사이트는 이미지의 크기를 표준 크기로 조정하고 크기가 조정된 이미지를 Amazon S3에 저장합니다. 사용자가 웹 사이트에 대한 느린 업로드 요청을 경험하고 있습니다. 회사는 애플리케이션 내 커플링을 줄이고 웹사이트 성능을 개선해야 합니다. 솔루션 설계자는 이미지 업로드를 위한 운영상 가장 효율적인 프로세스를 설계해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까? (2 개를 선택하세요.) </p>
<p><strong>C. 미리 서명된 URL 을 사용하여 각 사용자의 브라우저에서 Amazon S3 로 이미지를 직접 업로드하도록 애플리케이션 구성</strong> </p>
<ul>
<li>기존 방식에서는 사용자가 업로드하는 대용량 이미지 파일이 EC2 인스턴스를 거쳐야 했습니다.</li>
<li><strong>미리 서명된 URL</strong>을 사용하면, 웹 서버(EC2)는 단지 S3에 업로드할 수 있는 임시 권한(URL)만 생성해줄 뿐입니다. 실제 대용량 이미지 파일은 <strong>사용자의 브라우저에서 S3로 직접 전송됩니다.</strong></li>
</ul>
<p><strong>D. 이미지가 업로드될 때 AWS Lambda 함수를 호출하도록 S3 이벤트 알림을 구성합니다. 기능을 사용하여 이미지 크기를 조정합니다.</strong> </p>
<ul>
<li>이미지 리사이징이라는 부하가 많이 걸리는 작업을 EC2 웹 서버에서 완전히 분리하여 <strong>서버리스(Serverless)</strong> 서비스인 Lambda로 이전합니다.</li>
</ul>
<p><strong>A, B, E가 적절하지않은이유</strong></p>
<p><strong>A. S3 Glacier 에 이미지를 업로드하도록 애플리케이션을 구성합니다.</strong> </p>
<ul>
<li>S3 Glacier는 데이터 보관(Archiving) 및 장기 백업을 위한 저비용 스토리지입니다.</li>
</ul>
<p><strong>B. 원본 이미지를 Amazon S3에 업로드하도록 웹 서버를 구성합니다.</strong> </p>
<ul>
<li>이 방식은 여전히 <strong>사용자 → EC2 웹 서버 → S3</strong>의 경로로 데이터가 전송됩니다.</li>
</ul>
<p><strong>E. 업로드된 이미지의 크기를 조정하기 위해 일정에 따라 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.</strong></p>
<ul>
<li>EventBridge를 사용하여 &quot;일정(Schedule)에 따라&quot; Lambda를 실행하는 것은 <strong>배치(Batch) 처리</strong> 방식입니다. 예를 들어 &quot;5분마다 실행&quot;하도록 설정하면, 사용자는 이미지를 업로드한 후 최장 5분을 기다려야 자신의 이미지가 리사이징되어 표시됩니다.</li>
</ul>
<h1 id="111">111</h1>
<p>한 회사는 최근에 메시지 처리 시스템을 AWS 로 마이그레이션했습니다. 시스템은 Amazon EC2 인스턴스에서 실행되는 ActiveMQ 대기열로 메시지를 수신합니다. 메시지는 Amazon EC2 에서 실행되는 소비자 애플리케이션에 의해 처리됩니다. 소비자 애플리케이션은 메시지를 처리하고 결과를 Amazon EC2 에서 실행되는 MySQL 데이터베이스에 씁니다. 회사는 이 애플리케이션이 낮은 운영 복잡성으로 고가용성을 갖기를 원합니다. 가장 높은 가용성을 제공하는 아키텍처는 무엇입니까? </p>
<p><strong>D. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 두 가용 영역에 걸쳐 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹을 추가합니다. 다중 AZ 가 활성화된 MySQL용 Amazon RDS를 사용합니다.</strong></p>
<ul>
<li><strong>메시지 큐: Amazon MQ (활성/대기 브로커)</strong><ul>
<li><strong>고가용성</strong>: Amazon MQ는 AWS의 관리형 메시지 브로커 서비스입니다. 활성/대기(Active/Standby) 모드로 구성하면, 기본(Active) 브로커가 있는 가용 영역(Availability Zone, AZ)에 장애가 발생할 경우 AWS가 자동으로 다른 AZ에 있는 대기(Standby) 브로커로 장애 조치(Failover)를 수행합니다.</li>
<li><strong>고가용성 :</strong> Auto Scaling 그룹</li>
<li><strong>낮은 운영 복잡성</strong>: 사용자가 직접 EC2에 ActiveMQ를 설치하고, 클러스터를 구성하고, 장애 발생 시 수동으로 복구할 필요가 없습니다. AWS가 모든 관리를 대행해주므로 운영 부담이 크게 줄어듭니다.</li>
</ul>
</li>
<li><strong>데이터베이스: Amazon RDS for MySQL (다중 AZ 활성화)</strong><ul>
<li><strong>고가용성</strong>: RDS 다중 AZ(Multi-AZ) 기능은 다른 가용 영역에 동기식으로 복제된 예비(Standby) 데이터베이스를 유지합니다. 기본(Primary) DB에 장애가 발생하면 RDS가 자동으로 예비 DB로 장애 조치를 수행하여 데이터베이스 서비스의 중단을 최소화합니다.</li>
<li><strong>낮은 운영 복잡성</strong>: 사용자가 직접 데이터베이스 복제, 모니터링, 패치, 백업 및 장애 조치를 관리할 필요 없이 AWS가 모두 처리해줍니다. EC2에 직접 MySQL을 설치하고 운영하는 것에 비해 운영 복잡성이 현저히 낮습니다.</li>
</ul>
</li>
</ul>
<p><strong>A, B, C가 적절하지않은이유</strong></p>
<p><strong>A. 다른 가용 영역에 두 번째 ActiveMQ 서버를 추가합니다. 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.</strong> </p>
<ul>
<li><strong>높은 운영 복잡성</strong>: 이 선택지는 모든 구성 요소를 EC2 인스턴스 위에서 <strong>수동으로 관리</strong>하는 방식입니다.</li>
</ul>
<p><strong>B. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.</strong></p>
<ul>
<li><strong>부분적으로 높은 운영 복잡성</strong>: 메시지 큐는 Amazon MQ를 사용하여 개선했지만, 데이터베이스는 여전히 EC2 위에서 <strong>수동으로 복제하고 관리</strong>해야 합니다. ****</li>
</ul>
<p><strong>C. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다. 다중 AZ 가 활성화된 MySQL 용 Amazon RDS를 사용합니다. -</strong> </p>
<ul>
<li>다른 AZ에 EC2 인스턴스를 하나만 추가하는 것은 Auto Scaling 그룹이 제공하는 <strong>자동 복구(self-healing)</strong> 및 <strong>탄력적 확장(scalability)</strong> 기능을 갖추지 못했습니다. 만약 트래픽이 급증하거나, 추가된 인스턴스마저 장애가 발생하면 서비스가 중단될 수 있습니다. 따라서 <strong>'가장 높은 가용성'</strong>을 제공한다고 보기 어렵습니다.</li>
</ul>
<h1 id="112">112</h1>
<p>회사는 들어오는 요청을 처리하는 온프레미스 서버 집합에서 컨테이너화된 웹 애플리케이션을 호스팅합니다. 요청 수가 빠르게 증가하고 있습니다. 온프레미스 서버는 증가된 요청 수를 처리할 수 없습니다. 회사는 최소한의 코드 변경과 최소한의 개발 노력으로 애플리케이션을 AWS로 옮기기를 원합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>A. Amazon Elastic Container Service(Amazon ECS)에서 AWS Fargate 를 사용하여 Service Auto Scaling 으로 컨테이너화된 웹 애플리케이션을 실행합니다. Application Load Balancer 를 사용하여 수신 요청을 배포합니다.</strong> </p>
<ul>
<li>Fargate를 사용하면 서버 걱정 없이 컨테이너를 손쉽게 운영할 수 있고, Auto Scaling으로 트래픽 변화에 자동으로 대응할 수 있어 가장 이상적인 선택</li>
</ul>
<p><strong>B, C, D가 적절하지않은이유</strong></p>
<p><strong>B. 두 개의 Amazon EC2 인스턴스를 사용하여 컨테이너화된 웹 애플리케이션을 호스팅합니다. Application Load Balancer 를 사용하여 수신 요청을 배포합니다.</strong> </p>
<ul>
<li>'두 개의 EC2 인스턴스'는 고정된 용량을 의미합니다.</li>
<li>요청이 급증할 때 자동으로 확장되지 않아 병목 현상이 발생할 수 있습니다.</li>
</ul>
<p><strong>C. 지원되는 언어 중 하나를 사용하는 새 코드와 함께 AWS Lambda를 사용합니다. 로드를 지원하기 위해 여러 Lambda 함수를 생성합니다. Amazon API Gateway 를 Lambda 함수에 대한 진입점으로 사용합니다.</strong> </p>
<ul>
<li>Lambda는 서버리스 함수 실행 환경입니다. 기존의 웹 애플리케이션(컨테이너 기반)을 Lambda에서 실행하려면 애플리케이션 아키텍처를 이벤트 기반의 작은 함수 단위로 완전히 재설계하고 코드를 수정해야 합니다. 이는 '최소한의 코드 변경 및 개발 노력' 요구사항에 정면으로 위배됩니다.</li>
</ul>
<p><strong>D. AWS ParallelCluster 와 같은 고성능 컴퓨팅(HPC) 솔루션을 사용하여 적절한 규모로 들어오는 요청을 처리할 수 있는 HPC 클러스터를 설정합니다.</strong></p>
<ul>
<li>AWS ParallelCluster는 대규모 과학 계산, 시뮬레이션, 렌더링과 같은 고성능 컴퓨팅(HPC) 워크로드를 위해 설계된 도구입니다. 실시간으로 들어오는 웹 요청을 처리하는 웹 애플리케이션과는 사용 목적이 완전히 다릅니다. 이 솔루션은 웹 트래픽 처리에 비효율적이고 복잡합니다.</li>
</ul>
<h1 id="113">113</h1>
<p>회사는 보고를 위해 50TB 의 데이터를 사용합니다. 회사는 이 데이터를 온프레미스에서 AWS 로 이동하려고 합니다. 회사 데이터 센터의 사용자 지정 응용 프로그램은 매주 데이터 변환 작업을 실행합니다. 회사는 데이터 이전이 완료되고 가능한 한 빨리 이전 프로세스를 시작해야 할 때까지 응용 프로그램을 일시 중지할 계획입니다. 데이터 센터에는 추가 워크로드에 사용할 수 있는 네트워크 대역폭이 없습니다. 솔루션 설계자는 데이터를 전송하고 AWS 클라우드에서 계속 실행되도록 변환 작업을 구성해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>C. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 데이터를 장치에 복사합니다. AWS Glue를 사용하여 사용자 지정 변환 작업을 생성합니다.</strong> </p>
<ul>
<li><strong>데이터 전송</strong>: <code>AWS Snowball Edge Storage Optimized</code>는 최대 80TB의 사용 가능한 스토리지 용량을 제공합니다.  &quot;네트워크 대역폭 없음&quot;이라는 제약 조건을 완벽하게 해결합니다.</li>
<li><strong>변환 작업</strong>: <code>AWS Glue</code>는 서버리스(Serverless) 데이터 통합 서비스입니다. 사용자는 서버를 프로비저닝하거나 관리할 필요 없이 ETL(추출, 변환, 로드) 작업을 실행할 수 있습니다.</li>
</ul>
<p><strong>A, B, D가 적절하지않은이유</strong></p>
<p><strong>A. AWS DataSync 를 사용하여 데이터를 이동합니다. AWS Glue 를 사용하여 사용자 지정 변환 작업을 생성합니다.</strong> </p>
<ul>
<li><code>AWS DataSync</code>는 네트워크를 통해 온프레미스 스토리지와 AWS 스토리지 서비스 간의 데이터 전송을 가속화하는 서비스입니다.</li>
</ul>
<p><strong>B. AWS Snowcone 디바이스에 데이터를 이동하도록 주문합니다. 장치에 변환 응용 프로그램을 배포합니다.</strong> </p>
<ul>
<li><code>AWS Snowcone</code>은 휴대성이 높은 소형 디바이스로, HDD 모델 기준 약 8TB의 용량을 가집니다.</li>
</ul>
<p><strong>D. Amazon EC2 컴퓨팅이 포함된 AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 데이터를 장치에 복사합니다. AWS 에서 새 EC2 인스턴스를 생성하여 변환 애플리케이션을 실행합니다.</strong></p>
<ul>
<li>변환 애플리케이션을 <code>EC2 인스턴스</code>에 직접 설치하여 실행하는 것은 <strong>운영 오버헤드가 더 높습니다</strong>. EC2를 사용하면 인스턴스의 OS 패치, 보안 관리, 소프트웨어 설치 및 유지보수 등을 직접 관리해야 합니다.</li>
</ul>
<h1 id="114">114</h1>
<p>한 회사는 사용자가 사진을 업로드하고 이미지에 액자를 추가할 수 있는 이미지 분석 응용 프로그램을 만들었습니다. 사용자는 이미지와 메타데이터를 업로드하여 이미지에 추가할 사진 프레임을 나타냅니다. 애플리케이션은 단일 Amazon EC2 인스턴스와 Amazon DynamoDB를 사용하여 메타데이터를 저장합니다. 응용 프로그램이 대중화되고 사용자 수가 증가하고 있습니다. 회사는 동시 접속자 수가 시간과 요일에 따라 크게 달라질 것으로 예상하고 있습니다. 회사는 증가하는 사용자 기반의 요구 사항을 충족하도록 애플리케이션을 확장할 수 있는지 확인해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? </p>
<p><strong>C. AWS Lambda 를 사용하여 사진을 처리합 니다. Amazon S3 에 사진을 저장합니다.  DynamoDB를 유지하여 메타데이터를 저장합니다.</strong> </p>
<p><strong>A, B, D가 적절하지않은이유</strong></p>
<p><strong>A. AWS Lambda 를 사용하여 사진을 처리합니다. 사진과 메타데이터를 DynamoDB 에 저장합니다.</strong> </p>
<ul>
<li>DynamoDB는 항목(Item) 당 크기 제한이 <strong>400KB</strong>입니다. 대부분의 사진 파일은 이보다 훨씬 큽니다.</li>
</ul>
<p><strong>B. Amazon Kinesis Data Firehose 를 사용하여 사진을 처리하고 사진과 메타데이터를 저장합니다.</strong></p>
<ul>
<li>Kinesis Data Firehose는 IoT 센서 데이터나 로그와 같은 <strong>대규모 스트리밍 데이터를 수집하여 S3나 Redshift 같은 데이터 스토어로 전송하는 서비스</strong>입니다.</li>
</ul>
<p><strong>D. EC2 인스턴스 수를 3개로 늘립니다. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store (Amazon EBS) 볼륨을 사용하여 사진과 메타데이터를 저장합니다.</strong></p>
<ul>
<li><strong>고정된 EC2 인스턴스 수</strong>: EC2 인스턴스를 3개로 늘리는 것은 어느 정도 확장성이 확보되지만, 트래픽 변동에 자동으로 대응하지 못합니다.</li>
<li><strong>부적절한 스토리지</strong>: EBS는 EC2 인스턴스에 연결되는 블록 스토리지로, S3처럼 웹에서 직접 파일을 서빙하거나 무한히 확장하기에 적합하지 않습니다. 특히 <strong>io2 EBS 볼륨</strong>은 초당 수만 번의 입출력(IOPS)이 필요한 데이터베이스 워크로드에 사용되는 고성능/고비용 스토리지입니다. 단순히 사진 파일을 저장하는 용도로는 매우 비효율적이고 불필요한 선택입니다.</li>
</ul>
<h1 id="115">115</h1>
<p>의료 기록 회사는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 애플리케이션은 Amazon S3 에 저장된 고객 데이터 파일을 처리합니다. EC2 인스턴스는 퍼블릭 서브넷에서 호스팅됩니다. EC2 인스턴스는 인터넷을 통해 Amazon S3 에 액세스하지만 다른 네트워크 액세스는 필요하지 않습니다. 새로운 요구 사항은 파일 전송을 위한 네트워크 트래픽이 인터넷을 통해 전송되지 않고 개인 경로를 사용하도록 규정하고 있습니다. 솔루션 설계자가 이 요구 사항을 충족하기 위해 권장해야 하는 네트워크 아키텍처 변경 사항은 무엇입니까? </p>
<p><strong>C. EC2 인스턴스를 프라이빗 서브넷으로 이동합니다. Amazon S3 용 VPC 엔드포인트를 생성하고 엔드포인트를 프라이빗 서브넷의 라우팅 테이블에 연결합니다.</strong> </p>
<ul>
<li>이 아키텍처는 &quot;파일 전송을 위한 네트워크 트래픽이 인터넷을 통해 전송되지 않고 개인 경로를 사용하도록 한다&quot;는 새로운 요구 사항을 완벽하게 충족합니다.</li>
<li><strong>EC2 인스턴스를 프라이빗 서브넷으로 이동</strong>: 인스턴스에 공인 IP 주소가 할당되지 않도록 하여 인터넷 게이트웨이를 통한 직접적인 인터넷 접근을 차단합니다. 이것이 보안의 첫걸음입니다.</li>
<li><strong>Amazon S3용 VPC 엔드포인트 생성</strong>: VPC 엔드포인트(구체적으로 게이트웨이 엔드포인트)는 VPC와 S3 간의 <strong>비공개 연결</strong>을 설정합니다. VPC 엔드포인트를 생성하고 프라이빗 서브넷의 라우팅 테이블에 연결하면, 해당 서브넷의 EC2 인스턴스에서 S3로 향하는 모든 트래픽은 인터넷 게이트웨이나 NAT 게이트웨이를 거치지 않고 AWS 내부 네트워크를 통해 안전하게 라우팅됩니다.</li>
</ul>
<p><strong>A, B, D가 적절하지않은이유</strong></p>
<p><strong>A. NAT 게이트웨이를 생성합니다. NAT 게이트웨이를 통해 Amazon S3 로 트래픽을 전송하도록 퍼블릭 서브넷에 대한 라우팅 테이블을 구성합니다.</strong> </p>
<ul>
<li><strong>NAT 게이트웨이</strong>는 <strong>프라이빗 서브넷</strong>에 있는 인스턴스가 외부 인터넷(예: 소프트웨어 업데이트)에 접근해야 할 때 사용합니다.</li>
</ul>
<p><strong>B. S3 접두사 목록에 대한 트래픽만 허용되도록 아웃바운드 트래픽을 제한하도록 EC2 인스턴스에 대한 보안 그룹을 구성합니다.</strong> </p>
<ul>
<li><strong>보안 그룹(Security Group)</strong>은 EC2 인스턴스 수준에서 작동하는 <strong>가상 방화벽</strong>입니다. 인바운드 및 아웃바운드 트래픽을 제어할 수 있습니다. S3 접두사 목록(prefix list)으로 아웃바운드 트래픽을 제한하는 것은 좋은 보안 조치이지만, 트래픽이 어떤 <strong>경로</strong>로 나가는지는 제어하지 못합니다.</li>
</ul>
<p><strong>D. VPC에서 인터넷 게이트웨이를 제거합니다. AWS Direct Connect 연결을 설정하고 Direct Connect 연결을 통해 Amazon S3로 트래픽을 라우팅합니다.</strong></p>
<ul>
<li><strong>AWS Direct Connect</strong>는 온프레미스 데이터 센터와 AWS 간의 전용 프라이빗 네트워크 연결을 설정하는 서비스입니다.</li>
</ul>
<h1 id="116">116</h1>
<p>회사는 회사 웹 사이트에 널리 사용되는 CMS(콘텐츠 관리 시스템)를 사용합니다. 그러나 필요한 패치 및 유지 관리가 부담됩니다. 회사는 웹사이트를 재설계하고 있으며 새로운 솔루션을 원합니다. 웹사이트는 1 년에 4 번 업데이트되며 사용 가능한 동적 콘텐츠가 필요하지 않습니다. 솔루션은 높은 확장성과 향상된 보안을 제공해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 변경 조합은 무엇입니까? </p>
<p><strong>A. HTTPS 기능을 사용하도록 웹 사이트 앞에 Amazon CloudFront를 구성합니다.</strong> </p>
<p><strong>D. 새 웹 사이트와 Amazon S3 버킷을 생성합니다. 정적 웹 사이트 호스팅이 활성화된 S3 버킷에 웹 사이트를 배포합니다.</strong> </p>
<ul>
<li>지문은 정적 웹 사이트 호스팅에 대해서 설명하고 있음.</li>
</ul>
<h1 id="117">117</h1>
<p>회사는 Amazon CloudWatch Logs 로그 그룹에 애플리케이션 로그를 저장합니다. 새로운 정책에 따라 회사는 거의 실시간으로 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 모든 애플리케이션 로그를 저장해야 합니다. 최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>A. 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)로 스트리밍하도록 CloudWatch Logs 구독을 구성합니다.</strong> </p>
<ul>
<li><strong>CloudWatch Logs 구독 필터(Subscription Filter)</strong>는 CloudWatch Logs의 핵심 기능 중 하나입니다. 이 기능을 사용하면 로그 그룹에 들어오는 로그 이벤트를 거의 실시간으로 Amazon Kinesis, AWS Lambda, 그리고 <strong>Amazon OpenSearch Service</strong>로 직접 스트리밍할 수 있습니다.</li>
<li><strong>최소한의 운영 오버헤드:</strong> 이 방법은 AWS가 완전히 관리하는 네이티브 통합 기능입니다. 별도의 컴퓨팅 리소스(Lambda 등)를 프로비저닝하거나 코드를 작성하고 관리할 필요가 없습니다. 콘솔에서 몇 번의 클릭 또는 간단한 CLI/IaC 명령으로 설정을 완료하면 그 이후에는 AWS가 모든 데이터 전송을 알아서 처리합니다.</li>
<li><strong>실시간 처리:</strong> 로그가 CloudWatch에 도착하는 즉시 OpenSearch로 전송되므로 '거의 실시간'이라는 요구사항을 완벽하게 만족합니다.</li>
</ul>
<p><strong>B, C, D가 적절하지 않은이유</strong></p>
<p><strong>B. AWS Lambda 함수를 생성합니다. 로그 그룹을 사용하여 함수를 호출하여 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 로그를 기록합니다.</strong> </p>
<ul>
<li><strong>추가적인 관리 포인트:</strong> Lambda 함수 코드를 직접 작성하고, 테스트하고, 배포하고, 유지보수해야 합니다. 또한, Lambda 함수가 OpenSearch에 접근할 수 있도록 IAM 역할과 권한을 별도로 관리해야 하며, 에러 처리나 재시도 로직도 코드에 포함해야 할 수 있습니다. 운영 오버헤드가 더 높습니다.</li>
</ul>
<p><strong>C. Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. 전송 스트림 소스로 로그 그룹을 구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 전송 스트림의 대상으로 구성합니다.</strong> </p>
<ul>
<li><strong>중간 서비스 추가:</strong> 이 아키텍처는 <code>CloudWatch Logs → Kinesis Data Firehose → OpenSearch</code>의 흐름을 가집니다. Firehose라는 강력하고 유용한 중간 서비스가 추가됩니다. Firehose는 데이터 버퍼링, 형식 변환, 압축 등의 추가 기능을 제공하지만, 문제에서 요구하는 단순한 로그 전송에는 <strong>필수적이지 않은 추가 구성 요소</strong>입니다.</li>
</ul>
<p><strong>D. 각 애플리케이션 서버에 Amazon Kinesis Agent 를 설치하고 구성하여 Amazon Kinesis Data Streams 에 로그를 전달합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)에 로그를 전달하도록 Kinesis Data Streams를 구성합니다.</strong></p>
<ul>
<li><strong>에이전트 관리 부담:</strong> 모든 애플리케이션 서버에 직접 <strong>Kinesis Agent를 설치, 구성, 업데이트, 모니터링</strong>해야 합니다. 서버 수가 많아질수록 이 작업은 엄청난 운영 부담으로 이어집니다.</li>
</ul>
<h1 id="118">118</h1>
<p>회사는 여러 가용 영역의 Amazon EC2 인스턴스에서 실행되는 웹 기반 애플리케이션을 구축하고 있습니다. 웹 애플리케이션은 약 900TB 크기의 텍스트 문서 저장소에 대한 액세스를 제공합니다. 회사는 웹 응용 프로그램이 수요가 많은 기간을 경험할 것으로 예상합니다. 솔루션 설계자는 텍스트 문서의 스토리지 구성 요소가 애플리케이션의 요구 사항을 항상 충족할 수 있도록 확장할 수 있는지 확인해야 합니다. 회사는 솔루션의 전체 비용에 대해 우려하고 있습니다. 어떤 스토리지 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? </p>
<ul>
<li>900TB라는 어마어마한 양의 '텍스트 문서'라는 짐을 창고에 보관하고, 필요할 때마다 꺼내 보기만 하면 됩니다.</li>
</ul>
<p><strong>D. Amazon S3</strong></p>
<ul>
<li><strong>압도적인 비용 효율성</strong>: S3는 GB당 스토리지 비용이 다른 옵션(특히 EFS, EBS)에 비해 매우 저렴합니다.</li>
<li><strong>뛰어난 확장성</strong>: S3는 사실상 무제한의 저장 공간을 제공하며, 수요가 급증할 때에도 성능 저하 없이 수많은 동시 요청을 처리하도록 설계되었습니다.</li>
</ul>
<p><strong>A, B, C가 적절하지 않은이유</strong></p>
<p><strong>A. Amazon Elastic Block Store(Amazon EBS)</strong> </p>
<ul>
<li><strong>사용 목적의 불일치</strong>: EBS는 단일 EC2 인스턴스에 연결하여 사용하는 <strong>블록 스토리지</strong>입니다. 마치 가상 하드 드라이브와 같습니다.</li>
</ul>
<p><strong>B. Amazon Elastic File System(Amazon EFS)</strong> </p>
<ul>
<li><strong>기술적으로는 가능하지만 비용이 문제</strong>: EFS는 여러 가용 영역의 EC2 인스턴스에서 동시에 마운트하여 사용할 수 있는 <strong>공유 파일 시스템</strong>입니다. 기술적으로는 요구사항을 충족할 수 있습니다.</li>
<li><strong>높은 비용</strong>: EFS의 가장 큰 단점은 S3에 비해 GB당 스토리지 비용이 <strong>훨씬 비싸다</strong>는 점입니다.</li>
</ul>
<p><strong>C. Amazon OpenSearch Service(Amazon Elasticsearch Service)</strong> </p>
<ul>
<li><strong>근본적인 용도 차이</strong>: OpenSearch는 <strong>검색 및 분석</strong>을 위한 서비스이지, 900TB에 달하는 원본 문서를 저장하는 기본 스토리지 솔루션이 아닙니다.</li>
</ul>
<h1 id="119">119</h1>
<p>글로벌 회사는 Amazon API Gateway 를 사용하여 us-east-1 리전 및 ap-southeast-2 리전의 로열티 클럽 사용자를 위한 REST API 를 설계하고 있습니다. 솔루션 설계자는 SQL 주입 및 교차 사이트 스크립팅 공격으로부터 여러 계정에서 이러한 API Gateway 관리 REST API 를 보호하는 솔루션을 설계해야 합니다. 최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? </p>
<p><strong>B. 두 리전에 AWS Firewall Manager 를 설정합니다. AWS WAF 규칙을 중앙에서 구성합니다.</strong> </p>
<p><strong>A. 두 리전에 AWS WAF를 설정합니다. 리전 웹 ACL을 API 단계와 연결합니다.</strong> </p>
<ul>
<li>웹 ACL(Web Access Control List)</li>
</ul>
<p><strong>C. 목욕 리전에서 AWS Shield를 설정합니다. 리전 웹 ACL을 API 단계와 연결합니다.</strong> </p>
<p><strong>D. 한 리전에서 AWS Shield를 설정합니다. 리전 웹 ACL을 API 단계와 연결합니다.</strong></p>
<ul>
<li>AWS Shield는 DDoS 방어용</li>
</ul>
<h1 id="120">120</h1>
<p>한 회사는 us-west-2 리전의 NLB(Network Load Balancer) 뒤에 있는 3개의 Amazon EC2 인스턴스에 자체 관리형 DNS 솔루션을 구현했습니다. 회사 사용자의 대부분은 미국과 유럽에 있습니다. 회사는 솔루션의 성능과 가용성을 개선하기를 원합니다. 회사는 eu-west-1 리전에서 3 개의 EC2 인스턴스를 시작 및 구성하고 EC2 인스턴스를 새 NLB의 대상으로 추가합니다. 회사에서 트래픽을 모든 EC2 인스턴스로 라우팅하는 데 사용할 수 있는 솔루션은 무엇입니까? </p>
<p><strong>B. AWS Global Accelerator 에서 표준 액셀러레이터를 생성합니다. us-west-2 및 eu-west-1 에서 엔드포인트 그룹을 생성합니다. 엔드포인트 그룹에 대한 엔드포인트로 두 개의 NLB를 추가하십시오.</strong> </p>
<ul>
<li><strong>성능 최적화:</strong> Global Accelerator는 AWS의 잘 관리된 글로벌 네트워크 백본을 통해 사용자의 트래픽을 가장 가까운 AWS 엣지 로케이션으로 보냅니다. 거기서부터 최적화된 경로를 통해 애플리케이션 엔드포인트(이 경우 각 리전의 NLB)로 트래픽을 라우팅합니다. 이는 일반적인 공용 인터넷을 통하는 것보다 훨씬 빠르고 안정적인 연결을 제공합니다.</li>
<li><strong>고가용성 및 장애 조치:</strong> Global Accelerator는 엔드포인트(NLB)의 상태를 지속적으로 확인합니다. 만약 한쪽 리전(예: us-west-2)의 NLB나 EC2 인스턴스에 문제가 생기면, Global Accelerator가 이를 감지하고 자동으로 모든 트래픽을 다른 정상적인 리전(eu-west-1)의 NLB로 즉시 라우팅합니다. 이를 통해 서비스 중단을 최소화하고 가용성을 크게 높일 수 있습니다.</li>
<li><strong>간편한 관리:</strong> Global Accelerator는 두 개의 고정된 애니캐스트(Anycast) IP 주소를 제공합니다. 사용자는 이 고정 IP 주소로만 접속하면 되므로, DNS 설정이 매우 간단해집니다. 리전별로 다른 엔드포인트를 관리할 필요가 없습니다.</li>
<li><strong>애니캐스트(Anycast)</strong>: <strong>가장 가까운 곳으로 자동 연결해주는 시스템</strong>이 <strong>인터넷 라우팅 프로토콜(BGP)</strong>입니다</li>
</ul>
<p><strong>A, C, D가 적절하지않은이유</strong></p>
<p><strong>A. 두 NLB 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다.</strong> </p>
<ul>
<li><strong>부적절한 서비스 사용 (CloudFront):</strong> <strong>Amazon CloudFront</strong>는 주로 정적/동적 콘텐츠(웹사이트, 동영상 등)를 캐싱하여 사용자에게 더 빨리 전송하는 CDN 서비스입니다. 자체 관리형 DNS 쿼리(주로 UDP/53 포트 사용)를 처리하고 라우팅하는 데 적합한 솔루션이 아닙니다.</li>
<li><strong>라우팅의 한계:</strong> <strong>지리적 위치 라우팅</strong>은 사용자의 DNS 쿼리가 발생하는 위치(DNS 리졸버의 위치)를 기반으로 트래픽을 라우팅합니다. 이는 실제 사용자의 위치나 네트워크 지연 시간(latency)을 정확하게 반영하지 못할 수 있어 최적의 성능을 보장하기 어렵습니다.</li>
</ul>
<p><strong>C. 탄력적 IP 주소를 6 개의 EC2 인스턴스에 연결합니다. 6 개의 EC2 인스턴스 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다.</strong></p>
<ul>
<li><strong>로드 밸런서(NLB) 무력화:</strong> 6개의 모든 EC2 인스턴스에 직접 탄력적 IP(EIP)를 할당하면, 각 리전에서 트래픽을 분산하고 상태를 확인하는 <strong>NLB의 역할을 완전히 무시</strong>하게 됩니다.</li>
</ul>
<p><strong>D. 2개의 NLB를 2개의 ALB(Application Load Balancer)로 교체합니다. 두 ALB 중 하나로 요청을 라우팅하는 Amazon Route 53 지연 시간 라우팅 정책을 생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다.</strong></p>
<ul>
<li><strong>잘못된 로드 밸런서 유형:</strong> <strong>ALB(Application Load Balancer)</strong>는 HTTP/HTTPS와 같은 L7(애플리케이션 계층) 트래픽을 위해 설계되었습니다. 반면, DNS 서비스는 주로 TCP/UDP와 같은 L4(전송 계층)에서 작동합니다. 따라서 L4 트래픽 처리에 최적화된 <strong>NLB(Network Load Balancer)</strong>를 사용하는 것이 올바르며, ALB로 교체하는 것은 적절하지 않습니다.</li>
</ul>